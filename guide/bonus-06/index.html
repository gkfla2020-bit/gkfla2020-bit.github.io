<!DOCTYPE html>
<html lang="ko">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Bonus 6 - ìµœì í™” ì´ë¡  ì˜¬ì¸ì› (Optimization Theory All-in-One)</title>
<script>
MathJax = {
  tex: {
    inlineMath: [['\\(','\\)'],['$','$']],
    displayMath: [['\\[','\\]'],['$$','$$']]
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:wght@300;400;500&family=Space+Mono:wght@400&family=Inter:wght@300;400&display=swap" rel="stylesheet">
<script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
<style>
*{margin:0;padding:0;box-sizing:border-box}
body{font-family:'Inter',sans-serif;background:#fafaf8;color:#1a1a1a;line-height:1.7;overflow-x:hidden}
.sidebar{position:fixed;left:0;top:0;width:260px;height:100vh;background:rgba(255,255,255,.97);border-right:1px solid rgba(0,0,0,.06);padding:32px 24px;z-index:100;overflow-y:auto;display:flex;flex-direction:column}
.sidebar-profile{text-align:center;margin-bottom:28px;padding-bottom:24px;border-bottom:1px solid rgba(0,0,0,.08)}
.profile-icon{font-size:48px;margin-bottom:8px}
.profile-name{font-family:'Cormorant Garamond',serif;font-size:1.3rem;font-weight:500;margin-bottom:4px}
.profile-title{font-size:.68rem;color:#888;letter-spacing:.08em;text-transform:uppercase;margin-bottom:8px}
.profile-bio{font-size:.78rem;color:#666;line-height:1.5}
.sidebar-nav{flex:1;margin-top:16px}
.nav-section{margin-bottom:20px}
.nav-section-title{font-size:.6rem;font-weight:600;color:#aaa;letter-spacing:.15em;text-transform:uppercase;margin-bottom:10px}
.nav-list{list-style:none}
.nav-list li{margin-bottom:5px}
.nav-list a{font-size:.78rem;color:#555;text-decoration:none;transition:all .2s;display:block;padding:3px 0}
.nav-list a:hover{color:#0080c6;padding-left:4px}
.nav-list a.active{color:#0080c6;font-weight:500}
.nav-list a.done{color:#28a745}
.badge{display:inline-block;font-size:.5rem;background:#0080c6;color:#fff;padding:1px 5px;border-radius:8px;margin-left:3px;vertical-align:middle}
.badge-done{background:#28a745}
.badge-bonus{background:#9c27b0}
.sidebar-footer{padding-top:16px;border-top:1px solid rgba(0,0,0,.06);font-size:.65rem;color:#aaa;text-align:center}
.main-wrapper{margin-left:260px;min-height:100vh}
.container{max-width:1100px;margin:0 auto;padding:50px 40px 80px}
.paper-content{font-family:'Times New Roman','Nanum Myeongjo',serif;line-height:1.8;background:#fff;padding:40px;border-radius:8px;box-shadow:0 2px 20px rgba(0,0,0,.05)}
.paper-header{text-align:center;margin-bottom:40px;padding-bottom:30px;border-bottom:2px solid #333}
.paper-category{font-size:14px;color:#666;margin-bottom:10px}
.paper-title{font-size:24px;font-weight:bold;margin-bottom:12px;line-height:1.4}
.paper-subtitle{font-size:14px;color:#555;margin-bottom:8px}
.paper-team{font-size:13px;color:#444}
.abstract{background:#f8f9fa;padding:25px;margin:30px 0;border-left:4px solid #2c3e50}
.abstract-title{font-weight:bold;font-size:16px;margin-bottom:15px}
h2{font-size:18px;margin:35px 0 20px;padding-bottom:8px;border-bottom:1px solid #ddd;color:#2c3e50}
h3{font-size:15px;margin:25px 0 15px;color:#34495e}
h4{font-size:14px;margin:20px 0 12px;color:#34495e}
p{text-align:justify;margin-bottom:15px;text-indent:2em}
p.ni{text-indent:0}
table{width:100%;border-collapse:collapse;margin:20px 0;font-size:12px}
th,td{border:1px solid #ddd;padding:10px 8px;text-align:center}
th{background:#2c3e50;color:white;font-weight:bold}
tr:nth-child(even){background:#f8f9fa}
tr:hover{background:#e8f4f8}
.tc{font-size:13px;font-weight:bold;margin:15px 0 10px;text-align:center}
.eq{text-align:center;margin:20px 0;padding:15px;background:#f8f9fa;border-radius:4px;overflow-x:auto}
ul,ol{margin-left:2em;margin-bottom:15px}
li{margin-bottom:6px}
.def{background:#fff9e6;border:1px solid #ffc107;border-radius:4px;padding:20px;margin:20px 0}
.info{background:#e8f4f8;border-left:4px solid #3498db;padding:20px;margin:20px 0}
.warn{background:#fff3cd;border-left:4px solid #f39c12;padding:20px;margin:20px 0}
.ok{background:#d4edda;border-left:4px solid #28a745;padding:20px;margin:20px 0}
pre{background:#1e1e1e;color:#d4d4d4;padding:20px;border-radius:6px;overflow-x:auto;margin:20px 0;font-family:'Space Mono','Consolas',monospace;font-size:13px;line-height:1.6}
code{font-family:'Space Mono','Consolas',monospace;font-size:13px}
p code,li code,td code{background:#f0f0f0;padding:2px 6px;border-radius:3px;color:#c7254e;font-size:12px}
.cm{color:#6a9955}.kw{color:#569cd6}.st{color:#ce9178}.fn{color:#dcdcaa}.nb{color:#4ec9b0}.nu{color:#b5cea8}
.progress-bar{width:100%;height:6px;background:#e0e0e0;border-radius:3px;margin-top:16px}
.progress-fill{height:100%;background:linear-gradient(90deg,#9c27b0,#e040fb);border-radius:3px;width:100%}
.progress-label{font-size:11px;color:#888;margin-top:4px;text-align:center}
details{margin:20px 0;border:1px solid #ddd;border-radius:6px;overflow:hidden}
details summary{padding:14px 20px;background:#f0f4f8;cursor:pointer;font-weight:bold;font-size:14px;color:#2c3e50;user-select:none;transition:background .2s}
details summary:hover{background:#e0e8f0}
details[open] summary{background:#d0dce8;border-bottom:1px solid #ddd}
details .answer-content{padding:20px;background:#fff}
.problem-box{background:#f0f4ff;border:2px solid #5c6bc0;border-radius:8px;padding:20px;margin:20px 0}
.problem-box .problem-title{font-weight:bold;color:#283593;font-size:15px;margin-bottom:12px}
@media(max-width:1024px){
.sidebar{width:100%;height:auto;position:relative;border-right:none;border-bottom:1px solid rgba(0,0,0,.08);padding:16px}
.sidebar-profile{margin-bottom:10px;padding-bottom:10px;display:flex;align-items:center;gap:12px;text-align:left}
.profile-icon{font-size:32px;margin-bottom:0}.profile-bio{display:none}
.nav-section{display:inline-block;margin-right:16px;margin-bottom:8px}
.nav-list{display:flex;gap:10px;flex-wrap:wrap}.nav-list li{margin-bottom:0}
.sidebar-footer{display:none}
.main-wrapper{margin-left:0}
.container{padding:0}.paper-content{padding:20px 16px;border-radius:0;box-shadow:none}
.paper-title{font-size:18px}p{font-size:14px;text-indent:1.5em;text-align:left}
pre{font-size:11px;padding:14px}table{font-size:10px;display:block;overflow-x:auto}
}
.code-output{background:#1e1e1e;color:#d4d4d4;padding:12px 16px;border-radius:0 0 6px 6px;font-family:'Space Mono',monospace;font-size:11.5px;line-height:1.6;margin-top:-4px;margin-bottom:18px;border-top:2px solid #333;white-space:pre-wrap;overflow-x:auto}
.code-output .out-label{color:#888;font-size:10px;margin-bottom:4px;display:block}
</style>
</head>
<body>

<div class="sidebar">
<div class="sidebar-profile">
<div class="profile-icon">ğŸ¯</div>
<div class="profile-name">HFT ML Master Plan</div>
<div class="profile-title">Convex Opt + DL + HFT</div>
<div class="profile-bio">Bonus Rounds: ìˆ˜í•™ ê¸°ì´ˆ ì˜¬ì¸ì›</div>
</div>
<div class="sidebar-nav">
<div class="nav-section">
<div class="nav-section-title">Curriculum</div>
<ul class="nav-list">
<li><a class="done" href="../round-01/">R1. Python + Finance <span class="badge badge-done">DONE</span></a></li>
<li><a class="done" href="../bonus-01/">B1. ì„ í˜•ëŒ€ìˆ˜ ì˜¬ì¸ì› <span class="badge badge-done">DONE</span></a></li>
<li><a class="done" href="../round-02/">R2. Linear Algebra + Stats <span class="badge badge-done">DONE</span></a></li>
<li><a class="done" href="../bonus-02/">B2. ë¯¸ì ë¶„ ì˜¬ì¸ì› <span class="badge badge-done">DONE</span></a></li>
<li><a class="done" href="../round-03/">R3. Data / Feature Eng. <span class="badge badge-done">DONE</span></a></li>
<li><a class="done" href="../bonus-04/">B4. ì¬ë¬´ê´€ë¦¬ ì˜¬ì¸ì› <span class="badge badge-done">DONE</span></a></li>
<li><a class="done" href="../round-04/">R4. Supervised Learning <span class="badge badge-done">DONE</span></a></li>
<li><a class="done" href="../bonus-03/">B3. í™•ë¥ Â·í†µê³„ ì˜¬ì¸ì› <span class="badge badge-done">DONE</span></a></li>
<li><a class="done" href="../round-05/">R5. Unsupervised + TS <span class="badge badge-done">DONE</span></a></li>
<li><a class="done" href="../bonus-05/">B5. ê¸ˆìœµê³µí•™ ì˜¬ì¸ì› <span class="badge badge-done">DONE</span></a></li>
<li><a class="done" href="../round-06/">R6. NLP + Sentiment <span class="badge badge-done">DONE</span></a></li>
<li><a class="done" href="../round-07/">R7. Deep Learning <span class="badge badge-done">DONE</span></a></li>
<li><a class="active" href="#">B6. ìµœì í™” ì´ë¡  ì˜¬ì¸ì› <span class="badge badge-bonus">BONUS</span></a></li>
<li><a href="../round-08/">R8. Convex Opt + Transformer</a></li>
<li><a href="../round-09/">R9. HFT + RL</a></li>
<li><a href="../round-10/">R10. Final Project</a></li>
</ul>
</div>
</div>
<div class="sidebar-footer">
<div class="progress-bar"><div class="progress-fill" style="width:87%"></div></div>
<div class="progress-label">87 % Complete</div>
</div>
</div>

<div class="main-wrapper">
<div class="container">
<div class="paper-content">

<div class="paper-header">
<div class="paper-category">BONUS ROUND 6 â€” ìµœì í™” ì´ë¡  ì˜¬ì¸ì›</div>
<div class="paper-title">Optimization Theory All-in-One:<br>ë³¼ë¡ ìµœì í™”ì—ì„œ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”ê¹Œì§€</div>
<div class="paper-subtitle">From Gradient Descent to Convex Portfolio Optimization for HFT</div>
<div class="paper-team">HFT ML Master Plan Â· Bonus Series</div>
</div>

<div class="abstract">
<div class="abstract-title">Abstract</div>
<p class="ni">ë³¸ êµì¬ëŠ” ìµœì í™” ì´ë¡ (Optimization Theory)ì˜ í•µì‹¬ì„ 10ê°œ ì±•í„°ë¡œ ì••ì¶•í•œ ì˜¬ì¸ì› ê°•ì˜ì´ë‹¤. 
ê¸°ì´ˆì ì¸ ë¯¸ë¶„ ê¸°ë°˜ ìµœì í™”ì—ì„œ ì¶œë°œí•˜ì—¬, ë³¼ë¡ ìµœì í™”(Convex Optimization), ë¼ê·¸ë‘ì£¼ ìŠ¹ìˆ˜ë²•, 
KKT ì¡°ê±´, ì´ì°¨ê³„íšë²•(QP), ê²½ì‚¬í•˜ê°•ë²•ê³¼ ê·¸ ë³€í˜•ë“¤, í™•ë¥ ì  ìµœì í™”, ê·¸ë¦¬ê³  ê¸ˆìœµì—ì„œì˜ 
í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”ê¹Œì§€ ì²´ê³„ì ìœ¼ë¡œ ë‹¤ë£¬ë‹¤. ëª¨ë“  ì´ë¡ ì€ Python ì½”ë“œì™€ Plotly ì‹œê°í™”ë¥¼ í†µí•´ 
ì§ê´€ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìœ¼ë©°, ê° ì±•í„° ë§ë¯¸ì— ì—°ìŠµë¬¸ì œë¥¼ í¬í•¨í•œë‹¤. 
R8(Convex Optimization + Transformer)ì˜ ì„ ìˆ˜ ì§€ì‹ìœ¼ë¡œì„œ, ML/DL í•™ìŠµê³¼ HFT ì „ëµ ìµœì í™”ì— 
í•„ìˆ˜ì ì¸ ìˆ˜í•™ì  ê¸°ë°˜ì„ ì œê³µí•œë‹¤.</p>
</div>

<p class="ni"><strong>ëª©ì°¨:</strong></p>
<ol>
<li>ìµœì í™”ë€ ë¬´ì—‡ì¸ê°€? â€” ê¸°ë³¸ ê°œë…ê³¼ ë¶„ë¥˜</li>
<li>ë¯¸ë¶„ê³¼ ìµœì í™” â€” 1ì°¨Â·2ì°¨ ì¡°ê±´, ë‹¤ë³€ìˆ˜ ìµœì í™”</li>
<li>ë³¼ë¡ ì§‘í•©ê³¼ ë³¼ë¡ í•¨ìˆ˜ â€” Convexityì˜ ëª¨ë“  ê²ƒ</li>
<li>ë¼ê·¸ë‘ì£¼ ìŠ¹ìˆ˜ë²• â€” ë“±ì‹ ì œì•½ ìµœì í™”</li>
<li>KKT ì¡°ê±´ â€” ë¶€ë“±ì‹ ì œì•½ê³¼ ìŒëŒ€ì„±</li>
<li>ì´ì°¨ê³„íšë²•(QP) â€” Markowitz í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”</li>
<li>ê²½ì‚¬í•˜ê°•ë²•ê³¼ ë³€í˜• â€” GD, SGD, Adam</li>
<li>í™•ë¥ ì  ìµœì í™”ì™€ ì •ê·œí™” â€” Regularization, Dropout, Early Stopping</li>
<li>ê¸ˆìœµ ìµœì í™” ì‘ìš© â€” Risk Parity, Black-Litterman, Transaction Cost</li>
<li>ì¢…í•© ë¬¸ì œ â€” í†µí•© ì—°ìŠµ</li>
</ol>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2>Chapter 1. ìµœì í™”ë€ ë¬´ì—‡ì¸ê°€?</h2>

<h3>1.1 ìµœì í™” ë¬¸ì œì˜ í‘œì¤€í˜•</h3>

<p>ìµœì í™”(Optimization)ë€ ì£¼ì–´ì§„ ì œì•½ ì¡°ê±´ í•˜ì—ì„œ ëª©ì í•¨ìˆ˜(Objective Function)ë¥¼ ìµœì†Œí™” ë˜ëŠ” ìµœëŒ€í™”í•˜ëŠ” ê²°ì •ë³€ìˆ˜(Decision Variable)ë¥¼ ì°¾ëŠ” ê³¼ì •ì´ë‹¤. ìˆ˜í•™ì ìœ¼ë¡œ í‘œì¤€í˜•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤:</p>

<div class="eq">
\[\min_{x \in \mathbb{R}^n} f(x) \quad \text{subject to} \quad g_i(x) \le 0,\; i=1,\dots,m, \quad h_j(x) = 0,\; j=1,\dots,p\]
</div>

<p class="ni">ì—¬ê¸°ì„œ:</p>
<ul>
<li>\(f(x)\): ëª©ì í•¨ìˆ˜ (objective function)</li>
<li>\(g_i(x) \le 0\): ë¶€ë“±ì‹ ì œì•½ (inequality constraints)</li>
<li>\(h_j(x) = 0\): ë“±ì‹ ì œì•½ (equality constraints)</li>
<li>\(x \in \mathbb{R}^n\): ê²°ì •ë³€ìˆ˜ ë²¡í„°</li>
</ul>

<div class="def">
<p class="ni"><strong>ì •ì˜ 1.1 (ì‹¤í–‰ê°€ëŠ¥ ì˜ì—­, Feasible Set):</strong> ëª¨ë“  ì œì•½ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì ë“¤ì˜ ì§‘í•©ì„ ì‹¤í–‰ê°€ëŠ¥ ì˜ì—­ì´ë¼ í•œë‹¤:
\[\mathcal{F} = \{x \in \mathbb{R}^n \mid g_i(x) \le 0,\; h_j(x) = 0,\; \forall i,j\}\]
</p>
</div>

<h3>1.2 ìµœì í™” ë¬¸ì œì˜ ë¶„ë¥˜</h3>

<p class="tc">Table 1. ìµœì í™” ë¬¸ì œ ë¶„ë¥˜ ì²´ê³„</p>
<table>
<tr><th>ë¶„ë¥˜ ê¸°ì¤€</th><th>ìœ í˜•</th><th>íŠ¹ì§•</th><th>ì˜ˆì‹œ</th></tr>
<tr><td rowspan="2">ëª©ì í•¨ìˆ˜</td><td>ì„ í˜•(LP)</td><td>\(f(x) = c^T x\)</td><td>ìì› ë°°ë¶„, ìš´ì†¡ ë¬¸ì œ</td></tr>
<tr><td>ë¹„ì„ í˜•(NLP)</td><td>ì¼ë°˜ \(f(x)\)</td><td>í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”</td></tr>
<tr><td rowspan="2">ë³¼ë¡ì„±</td><td>ë³¼ë¡(Convex)</td><td>ì „ì—­ ìµœì í•´ ë³´ì¥</td><td>QP, SDP, SOCP</td></tr>
<tr><td>ë¹„ë³¼ë¡(Non-convex)</td><td>ì§€ì—­ ìµœì í•´ë§Œ ë³´ì¥</td><td>ì‹ ê²½ë§ í•™ìŠµ</td></tr>
<tr><td rowspan="2">ë³€ìˆ˜ ìœ í˜•</td><td>ì—°ì†(Continuous)</td><td>\(x \in \mathbb{R}^n\)</td><td>ê°€ì¤‘ì¹˜ ìµœì í™”</td></tr>
<tr><td>ì •ìˆ˜(Integer)</td><td>\(x \in \mathbb{Z}^n\)</td><td>ì£¼ë¬¸ ìˆ˜ëŸ‰ ê²°ì •</td></tr>
<tr><td rowspan="2">ì œì•½ ì¡°ê±´</td><td>ë¬´ì œì•½(Unconstrained)</td><td>ì œì•½ ì—†ìŒ</td><td>íšŒê·€ ë¶„ì„</td></tr>
<tr><td>ì œì•½(Constrained)</td><td>ë“±ì‹/ë¶€ë“±ì‹ ì œì•½</td><td>Markowitz MVO</td></tr>
<tr><td rowspan="2">ì •ë³´</td><td>ê²°ì •ì (Deterministic)</td><td>íŒŒë¼ë¯¸í„° í™•ì •</td><td>ê³ ì „ LP</td></tr>
<tr><td>í™•ë¥ ì (Stochastic)</td><td>íŒŒë¼ë¯¸í„° ë¶ˆí™•ì‹¤</td><td>ë¡œë²„ìŠ¤íŠ¸ ìµœì í™”</td></tr>
</table>

<h3>1.3 ML/HFTì—ì„œì˜ ìµœì í™”</h3>

<p>ë¨¸ì‹ ëŸ¬ë‹ì˜ ê±°ì˜ ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ì€ ìµœì í™” ë¬¸ì œë¡œ ê·€ê²°ëœë‹¤. ì„ í˜•íšŒê·€ëŠ” ìµœì†Œì œê³±ë²•(OLS), ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ìµœëŒ€ìš°ë„ì¶”ì •(MLE), ì‹ ê²½ë§ì€ ì—­ì „íŒŒë¥¼ í†µí•œ ì†ì‹¤í•¨ìˆ˜ ìµœì†Œí™”ì´ë‹¤. HFTì—ì„œëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ê³ , ì£¼ë¬¸ ì‹¤í–‰ ë¹„ìš©ì„ ìµœì†Œí™”í•˜ë©°, ë¦¬ìŠ¤í¬ í•œë„ ë‚´ì—ì„œ ìˆ˜ìµì„ ê·¹ëŒ€í™”í•´ì•¼ í•œë‹¤.</p>

<div class="info">
<p class="ni"><strong>ML í•™ìŠµ = ìµœì í™”:</strong> ì‹ ê²½ë§ í•™ìŠµì€ ë³¸ì§ˆì ìœ¼ë¡œ ë‹¤ìŒ ë¬¸ì œë¥¼ í‘¸ëŠ” ê²ƒì´ë‹¤:
\[\min_{\theta} \frac{1}{N}\sum_{i=1}^{N} \mathcal{L}(f_\theta(x_i), y_i) + \lambda \Omega(\theta)\]
ì—¬ê¸°ì„œ \(\mathcal{L}\)ì€ ì†ì‹¤í•¨ìˆ˜, \(\Omega(\theta)\)ëŠ” ì •ê·œí™” í•­ì´ë‹¤. ì´ ë¬¸ì œì˜ êµ¬ì¡°(ë³¼ë¡/ë¹„ë³¼ë¡, ì œì•½ ìœ ë¬´)ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì´ íš¨ìœ¨ì  í•™ìŠµì˜ í•µì‹¬ì´ë‹¤.</p>
</div>

<h3>1.4 ì „ì—­ ìµœì í•´ vs ì§€ì—­ ìµœì í•´</h3>

<p>ë¹„ë³¼ë¡ í•¨ìˆ˜ì—ì„œëŠ” ì—¬ëŸ¬ ê°œì˜ ì§€ì—­ ìµœì†Ÿê°’(local minimum)ì´ ì¡´ì¬í•  ìˆ˜ ìˆë‹¤. ì „ì—­ ìµœì†Ÿê°’(global minimum)ì€ ì‹¤í–‰ê°€ëŠ¥ ì˜ì—­ ì „ì²´ì—ì„œ ê°€ì¥ ì‘ì€ í•¨ìˆ˜ê°’ì„ ê°–ëŠ” ì ì´ë‹¤.</p>

<div class="eq">
\[\text{Global: } f(x^*) \le f(x),\; \forall x \in \mathcal{F} \qquad \text{Local: } f(x^*) \le f(x),\; \forall x \in \mathcal{N}(x^*) \cap \mathcal{F}\]
</div>

<div id="chart-local-global" style="width:100%;height:350px;margin:20px 0"></div>
<script>
(function(){
  var x = [], y = [];
  for(var i = -3; i <= 3; i += 0.02){
    x.push(i);
    y.push(Math.sin(3*i) + 0.5*i*i - 1);
  }
  var trace = {x:x, y:y, type:'scatter', mode:'lines', line:{color:'#2c3e50',width:2}, name:'f(x)'};
  // Mark local and global minima
  var mins_x = [-1.88, -0.34, 1.22];
  var mins_y = mins_x.map(function(v){return Math.sin(3*v)+0.5*v*v-1;});
  var labels = ['Local Min','Global Min','Local Min'];
  var colors = ['#e74c3c','#27ae60','#e74c3c'];
  var pts = {x:mins_x, y:mins_y, type:'scatter', mode:'markers+text', text:labels,
    textposition:'top center', marker:{size:12, color:colors, symbol:'diamond'},
    textfont:{size:11}, showlegend:false};
  Plotly.newPlot('chart-local-global',[trace,pts],{
    title:{text:'ì „ì—­ ìµœì í•´ vs ì§€ì—­ ìµœì í•´',font:{size:14}},
    xaxis:{title:'x'},yaxis:{title:'f(x)'},
    margin:{t:50,b:50,l:50,r:30},
    paper_bgcolor:'#f8f9fa',plot_bgcolor:'#fff'
  },{responsive:true});
})();
</script>

<div class="problem-box">
<div class="problem-title">ì—°ìŠµë¬¸ì œ 1.1</div>
<p class="ni">\(f(x) = x^4 - 4x^2 + 3\)ì˜ ëª¨ë“  ê·¹ê°’ì„ êµ¬í•˜ê³ , ì „ì—­ ìµœì†Ÿê°’ê³¼ ì§€ì—­ ìµœì†Ÿê°’ì„ ë¶„ë¥˜í•˜ë¼.</p>
</div>
<details><summary>ğŸ”‘ í’€ì´ ë³´ê¸°</summary><div class="answer-content">
<p class="ni">\(f'(x) = 4x^3 - 8x = 4x(x^2 - 2) = 0\)ì—ì„œ \(x = 0, \pm\sqrt{2}\).</p>
<p class="ni">\(f''(x) = 12x^2 - 8\)ì´ë¯€ë¡œ:</p>
<ul>
<li>\(x = 0\): \(f''(0) = -8 < 0\) â†’ ê·¹ëŒ€, \(f(0) = 3\)</li>
<li>\(x = \pm\sqrt{2}\): \(f''(\pm\sqrt{2}) = 16 > 0\) â†’ ê·¹ì†Œ, \(f(\pm\sqrt{2}) = 4 - 8 + 3 = -1\)</li>
</ul>
<p class="ni">ë‘ ê·¹ì†Œ \(f(\pm\sqrt{2}) = -1\)ì´ ë™ì¼í•˜ë¯€ë¡œ ë‘˜ ë‹¤ ì „ì—­ ìµœì†Ÿê°’ì´ë‹¤.</p>
</div></details>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2>Chapter 2. ë¯¸ë¶„ê³¼ ìµœì í™”</h2>

<h3>2.1 1ì°¨ í•„ìš”ì¡°ê±´ (First-Order Necessary Condition)</h3>

<p>ë¬´ì œì•½ ìµœì í™”ì—ì„œ \(x^*\)ê°€ ì§€ì—­ ìµœì†Ÿê°’ì´ë©´ ë°˜ë“œì‹œ ê·¸ë˜ë””ì–¸íŠ¸ê°€ 0ì´ì–´ì•¼ í•œë‹¤:</p>

<div class="eq">
\[\nabla f(x^*) = \mathbf{0}\]
</div>

<p>ì´ë¥¼ ë§Œì¡±í•˜ëŠ” ì ì„ ì •ë¥˜ì (stationary point)ì´ë¼ í•˜ë©°, ê·¹ëŒ€Â·ê·¹ì†ŒÂ·ì•ˆì¥ì (saddle point) ì¤‘ í•˜ë‚˜ì´ë‹¤.</p>

<h3>2.2 2ì°¨ ì¶©ë¶„ì¡°ê±´ (Second-Order Sufficient Condition)</h3>

<p>ì •ë¥˜ì  \(x^*\)ì—ì„œ í—¤ì‹œì•ˆ(Hessian) í–‰ë ¬ \(H = \nabla^2 f(x^*)\)ì˜ ì„±ì§ˆë¡œ ê·¹ê°’ì˜ ì¢…ë¥˜ë¥¼ íŒë³„í•œë‹¤:</p>

<div class="eq">
\[H = \nabla^2 f(x^*) = \begin{bmatrix} \frac{\partial^2 f}{\partial x_1^2} & \cdots & \frac{\partial^2 f}{\partial x_1 \partial x_n} \\ \vdots & \ddots & \vdots \\ \frac{\partial^2 f}{\partial x_n \partial x_1} & \cdots & \frac{\partial^2 f}{\partial x_n^2} \end{bmatrix}\]
</div>

<p class="tc">Table 2. í—¤ì‹œì•ˆ íŒë³„ë²•</p>
<table>
<tr><th>í—¤ì‹œì•ˆ ì¡°ê±´</th><th>íŒë³„ ê²°ê³¼</th><th>ê¸°í•˜í•™ì  ì˜ë¯¸</th></tr>
<tr><td>\(H \succ 0\) (ì–‘ì •ì¹˜)</td><td>ê·¹ì†Œ (local min)</td><td>ëª¨ë“  ë°©í–¥ìœ¼ë¡œ ìœ„ë¡œ ë³¼ë¡</td></tr>
<tr><td>\(H \prec 0\) (ìŒì •ì¹˜)</td><td>ê·¹ëŒ€ (local max)</td><td>ëª¨ë“  ë°©í–¥ìœ¼ë¡œ ì•„ë˜ë¡œ ë³¼ë¡</td></tr>
<tr><td>\(H\) ë¶€ì •ì¹˜ (indefinite)</td><td>ì•ˆì¥ì  (saddle)</td><td>ë°©í–¥ì— ë”°ë¼ ë‹¤ë¦„</td></tr>
<tr><td>\(H \succeq 0\) (ì–‘ë°˜ì •ì¹˜)</td><td>íŒë³„ ë¶ˆê°€</td><td>ê³ ì°¨ ë¯¸ë¶„ í•„ìš”</td></tr>
</table>

<h3>2.3 ë‹¤ë³€ìˆ˜ ìµœì í™” ì˜ˆì œ: ë¡œì  ë¸Œë¡ í•¨ìˆ˜</h3>

<p>ë¡œì  ë¸Œë¡ í•¨ìˆ˜(Rosenbrock function)ëŠ” ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì˜ ë²¤ì¹˜ë§ˆí¬ë¡œ ìœ ëª…í•˜ë‹¤:</p>

<div class="eq">
\[f(x,y) = (1-x)^2 + 100(y - x^2)^2\]
</div>

<p>ì „ì—­ ìµœì†Ÿê°’ì€ \((x^*, y^*) = (1, 1)\)ì´ë©° \(f(1,1) = 0\)ì´ë‹¤. ì¢ê³  ê¸´ "ë°”ë‚˜ë‚˜ ëª¨ì–‘" ê³¨ì§œê¸° ë•Œë¬¸ì— ê²½ì‚¬í•˜ê°•ë²•ì´ ìˆ˜ë ´í•˜ê¸° ì–´ë µë‹¤.</p>

<div id="chart-rosenbrock" style="width:100%;height:400px;margin:20px 0"></div>
<script>
(function(){
  var N = 80, xs = [], ys = [], zs = [];
  for(var i = 0; i < N; i++){
    var row_y = [], row_z = [];
    var xi = -2 + 4*i/(N-1);
    xs.push(xi);
    for(var j = 0; j < N; j++){
      var yj = -1 + 3*j/(N-1);
      if(i===0) ys.push(yj);
      var val = Math.pow(1-xi,2) + 100*Math.pow(yj - xi*xi,2);
      row_z.push(Math.log10(1+val));
    }
    zs.push(row_z);
  }
  Plotly.newPlot('chart-rosenbrock',[{x:xs,y:ys,z:zs,type:'contour',
    colorscale:'YlOrRd',contours:{coloring:'heatmap',showlabels:true},
    colorbar:{title:'logâ‚â‚€(1+f)'}}],{
    title:{text:'Rosenbrock Function (log scale contour)',font:{size:14}},
    xaxis:{title:'x'},yaxis:{title:'y'},
    annotations:[{x:1,y:1,text:'Global Min (1,1)',showarrow:true,arrowhead:2,ax:-60,ay:-40,
      font:{size:12,color:'#27ae60'}}],
    margin:{t:50,b:50,l:60,r:30},
    paper_bgcolor:'#f8f9fa',plot_bgcolor:'#fff'
  },{responsive:true});
})();
</script>

<h3>2.4 ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°: ìë™ ë¯¸ë¶„ vs ìˆ˜ì¹˜ ë¯¸ë¶„</h3>

<p>ì‹¤ë¬´ì—ì„œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ êµ¬í•˜ëŠ” ë°©ë²•ì€ ì„¸ ê°€ì§€ì´ë‹¤:</p>

<p class="tc">Table 3. ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë°©ë²• ë¹„êµ</p>
<table>
<tr><th>ë°©ë²•</th><th>ì •í™•ë„</th><th>ê³„ì‚° ë¹„ìš©</th><th>êµ¬í˜„</th><th>ì‚¬ìš©ì²˜</th></tr>
<tr><td>í•´ì„ì  ë¯¸ë¶„</td><td>ì •í™•</td><td>ìˆ˜ì‹ ìœ ë„ í•„ìš”</td><td>ìˆ˜ì‘ì—…</td><td>ì´ë¡  ì¦ëª…</td></tr>
<tr><td>ìˆ˜ì¹˜ ë¯¸ë¶„ (finite diff)</td><td>\(O(h)\) ~ \(O(h^2)\)</td><td>\(O(n)\) í•¨ìˆ˜ í‰ê°€</td><td>ê°„ë‹¨</td><td>ê²€ì¦ìš©</td></tr>
<tr><td>ìë™ ë¯¸ë¶„ (autodiff)</td><td>ê¸°ê³„ ì •ë°€ë„</td><td>\(O(1)\) ë°° forward</td><td>PyTorch/JAX</td><td>ML í•™ìŠµ</td></tr>
</table>

<pre>
<span class="cm"># ìˆ˜ì¹˜ ë¯¸ë¶„ vs ìë™ ë¯¸ë¶„ ë¹„êµ</span>
<span class="kw">import</span> numpy <span class="kw">as</span> np

<span class="kw">def</span> <span class="fn">rosenbrock</span>(x, y):
    <span class="kw">return</span> (<span class="nu">1</span> - x)**<span class="nu">2</span> + <span class="nu">100</span> * (y - x**<span class="nu">2</span>)**<span class="nu">2</span>

<span class="cm"># í•´ì„ì  ê·¸ë˜ë””ì–¸íŠ¸</span>
<span class="kw">def</span> <span class="fn">grad_analytic</span>(x, y):
    dfdx = -<span class="nu">2</span>*(<span class="nu">1</span>-x) - <span class="nu">400</span>*x*(y - x**<span class="nu">2</span>)
    dfdy = <span class="nu">200</span>*(y - x**<span class="nu">2</span>)
    <span class="kw">return</span> np.array([dfdx, dfdy])

<span class="cm"># ìˆ˜ì¹˜ ë¯¸ë¶„ (ì¤‘ì•™ì°¨ë¶„)</span>
<span class="kw">def</span> <span class="fn">grad_numerical</span>(x, y, h=<span class="nu">1e-7</span>):
    dfdx = (rosenbrock(x+h,y) - rosenbrock(x-h,y)) / (<span class="nu">2</span>*h)
    dfdy = (rosenbrock(x,y+h) - rosenbrock(x,y-h)) / (<span class="nu">2</span>*h)
    <span class="kw">return</span> np.array([dfdx, dfdy])

pt = (<span class="nu">0.5</span>, <span class="nu">0.5</span>)
<span class="nb">print</span>(<span class="st">"í•´ì„ì :"</span>, grad_analytic(*pt))
<span class="nb">print</span>(<span class="st">"ìˆ˜ì¹˜ì :"</span>, grad_numerical(*pt))
<span class="nb">print</span>(<span class="st">"ì°¨ì´:  "</span>, np.<span class="fn">abs</span>(grad_analytic(*pt) - grad_numerical(*pt)))
</pre>
<div class="code-output"><span class="out-label">Output:</span>
í•´ì„ì : [ 51.  -50.]
ìˆ˜ì¹˜ì : [ 51.  -50.]
ì°¨ì´:   [3.55e-08 7.11e-09]</div>

<div class="problem-box">
<div class="problem-title">ì—°ìŠµë¬¸ì œ 2.1</div>
<p class="ni">\(f(x,y) = x^2 + xy + y^2 - 6x - 9y + 20\)ì˜ ì •ë¥˜ì ì„ êµ¬í•˜ê³ , í—¤ì‹œì•ˆì„ ì´ìš©í•˜ì—¬ ê·¹ê°’ì˜ ì¢…ë¥˜ë¥¼ íŒë³„í•˜ë¼.</p>
</div>
<details><summary>ğŸ”‘ í’€ì´ ë³´ê¸°</summary><div class="answer-content">
<p class="ni">\(\nabla f = (2x + y - 6,\; x + 2y - 9) = (0, 0)\)ì„ í’€ë©´ \(x = 1, y = 4\).</p>
<p class="ni">í—¤ì‹œì•ˆ: \(H = \begin{pmatrix} 2 & 1 \\ 1 & 2 \end{pmatrix}\). ê³ ìœ ê°’ \(\lambda_1 = 3, \lambda_2 = 1\) ëª¨ë‘ ì–‘ìˆ˜ì´ë¯€ë¡œ \(H \succ 0\) â†’ ê·¹ì†Œ.</p>
<p class="ni">\(f(1, 4) = 1 + 4 + 16 - 6 - 36 + 20 = -1\).</p>
</div></details>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2>Chapter 3. ë³¼ë¡ ì§‘í•©ê³¼ ë³¼ë¡ í•¨ìˆ˜</h2>

<h3>3.1 ë³¼ë¡ ì§‘í•© (Convex Set)</h3>

<div class="def">
<p class="ni"><strong>ì •ì˜ 3.1 (ë³¼ë¡ ì§‘í•©):</strong> ì§‘í•© \(C \subseteq \mathbb{R}^n\)ì´ ë³¼ë¡(convex)ì´ë€, ì„ì˜ì˜ ë‘ ì  \(x, y \in C\)ì™€ \(\theta \in [0,1]\)ì— ëŒ€í•´
\[\theta x + (1-\theta)y \in C\]
ê°€ ì„±ë¦½í•˜ëŠ” ê²ƒì´ë‹¤. ì¦‰, ë‘ ì ì„ ì‡ëŠ” ì„ ë¶„ì´ í•­ìƒ ì§‘í•© ì•ˆì— í¬í•¨ëœë‹¤.</p>
</div>

<p class="tc">Table 4. ë³¼ë¡ ì§‘í•©ì˜ ì˜ˆ</p>
<table>
<tr><th>ì§‘í•©</th><th>ë³¼ë¡?</th><th>ì„¤ëª…</th></tr>
<tr><td>ì´ˆí‰ë©´ \(\{x \mid a^T x = b\}\)</td><td>âœ…</td><td>ì•„í•€ ì§‘í•© (ë³¼ë¡ì˜ íŠ¹ìˆ˜ ê²½ìš°)</td></tr>
<tr><td>ë°˜ê³µê°„ \(\{x \mid a^T x \le b\}\)</td><td>âœ…</td><td>LP ì œì•½ì˜ ê¸°ë³¸ ë‹¨ìœ„</td></tr>
<tr><td>ë‹¤ë©´ì²´ \(\{x \mid Ax \le b\}\)</td><td>âœ…</td><td>ë°˜ê³µê°„ì˜ êµì§‘í•©</td></tr>
<tr><td>íƒ€ì›ì²´ \(\{x \mid (x-c)^T P^{-1}(x-c) \le 1\}\)</td><td>âœ…</td><td>ê³µë¶„ì‚° íƒ€ì›ì²´</td></tr>
<tr><td>ë…¸ë¦„ ë³¼ \(\{x \mid \|x - c\| \le r\}\)</td><td>âœ…</td><td>ì„ì˜ì˜ ë…¸ë¦„ì— ëŒ€í•´ ì„±ë¦½</td></tr>
<tr><td>ì–‘ë°˜ì •ì¹˜ ì›ë¿” \(\mathbb{S}^n_+\)</td><td>âœ…</td><td>SDPì˜ ê¸°ë³¸ ì œì•½</td></tr>
<tr><td>ë„ë„› ëª¨ì–‘ (torus)</td><td>âŒ</td><td>ê°€ìš´ë° êµ¬ë©</td></tr>
</table>

<h3>3.2 ë³¼ë¡ í•¨ìˆ˜ (Convex Function)</h3>

<div class="def">
<p class="ni"><strong>ì •ì˜ 3.2 (ë³¼ë¡ í•¨ìˆ˜):</strong> í•¨ìˆ˜ \(f: \mathbb{R}^n \to \mathbb{R}\)ì´ ë³¼ë¡ì´ë€, ì •ì˜ì—­ì´ ë³¼ë¡ ì§‘í•©ì´ê³ , ì„ì˜ì˜ \(x, y\)ì™€ \(\theta \in [0,1]\)ì— ëŒ€í•´
\[f(\theta x + (1-\theta)y) \le \theta f(x) + (1-\theta) f(y)\]
ê°€ ì„±ë¦½í•˜ëŠ” ê²ƒì´ë‹¤. (Jensen's inequalityì˜ ì¼ë°˜í™”)</p>
</div>

<h3>3.3 ë³¼ë¡ í•¨ìˆ˜ì˜ íŒë³„ë²•</h3>

<p>ë³¼ë¡ í•¨ìˆ˜ë¥¼ íŒë³„í•˜ëŠ” ì„¸ ê°€ì§€ ë™ì¹˜ ì¡°ê±´:</p>

<ol>
<li><strong>0ì°¨ ì¡°ê±´:</strong> ì •ì˜ ê·¸ ìì²´ (ìœ„ì˜ ë¶€ë“±ì‹)</li>
<li><strong>1ì°¨ ì¡°ê±´:</strong> \(f(y) \ge f(x) + \nabla f(x)^T(y - x)\) â€” ì ‘ì„ ì´ í•­ìƒ í•¨ìˆ˜ ì•„ë˜ì— ìœ„ì¹˜</li>
<li><strong>2ì°¨ ì¡°ê±´:</strong> \(\nabla^2 f(x) \succeq 0\) â€” í—¤ì‹œì•ˆì´ ì–‘ë°˜ì •ì¹˜</li>
</ol>

<div class="warn">
<p class="ni"><strong>í•µì‹¬ ì •ë¦¬:</strong> ë³¼ë¡ í•¨ìˆ˜ì˜ ëª¨ë“  ì§€ì—­ ìµœì†Ÿê°’ì€ ì „ì—­ ìµœì†Ÿê°’ì´ë‹¤. ì´ê²ƒì´ ë³¼ë¡ ìµœì í™”ê°€ ê°•ë ¥í•œ ì´ìœ ì´ë‹¤. ë¹„ë³¼ë¡ ë¬¸ì œ(ì˜ˆ: ì‹ ê²½ë§)ì—ì„œëŠ” ì´ ë³´ì¥ì´ ì—†ìœ¼ë¯€ë¡œ ì´ˆê¸°ê°’, í•™ìŠµë¥  ë“±ì— ë¯¼ê°í•˜ë‹¤.</p>
</div>

<h3>3.4 ë³¼ë¡ í•¨ìˆ˜ì˜ ì—°ì‚° ë³´ì¡´ ê·œì¹™</h3>

<p class="tc">Table 5. ë³¼ë¡ì„± ë³´ì¡´ ì—°ì‚°</p>
<table>
<tr><th>ì—°ì‚°</th><th>ì¡°ê±´</th><th>ê²°ê³¼</th><th>ì˜ˆì‹œ</th></tr>
<tr><td>ë¹„ìŒìˆ˜ ê°€ì¤‘í•©</td><td>\(\alpha_i \ge 0\), \(f_i\) ë³¼ë¡</td><td>\(\sum \alpha_i f_i\) ë³¼ë¡</td><td>ì•™ìƒë¸” ì†ì‹¤</td></tr>
<tr><td>ì•„í•€ í•©ì„±</td><td>\(f\) ë³¼ë¡</td><td>\(f(Ax+b)\) ë³¼ë¡</td><td>ì„ í˜• ë³€í™˜ í›„ ì†ì‹¤</td></tr>
<tr><td>ì ë³„ ìµœëŒ€</td><td>\(f_i\) ë³¼ë¡</td><td>\(\max_i f_i(x)\) ë³¼ë¡</td><td>íŒì§€ ì†ì‹¤</td></tr>
<tr><td>ë¶€ë¶„ ìµœì†Œí™”</td><td>\(f(x,y)\) ë³¼ë¡</td><td>\(g(x) = \inf_y f(x,y)\) ë³¼ë¡</td><td>Schur complement</td></tr>
<tr><td>ì›ê·¼ í•¨ìˆ˜</td><td>\(f\) ë³¼ë¡</td><td>\(tf(x/t)\) ë³¼ë¡ (\(t>0\))</td><td>KL divergence</td></tr>
</table>

<div id="chart-convex-demo" style="width:100%;height:350px;margin:20px 0"></div>
<script>
(function(){
  var x = [], y_conv = [], y_nonconv = [];
  for(var i = -3; i <= 3; i += 0.05){
    x.push(i);
    y_conv.push(i*i);
    y_nonconv.push(Math.cos(2*i) + 0.3*i*i);
  }
  // Tangent line at x=1 for convex
  var tang_x = [], tang_y = [];
  for(var i = -2; i <= 3; i += 0.1){
    tang_x.push(i);
    tang_y.push(1 + 2*(i-1)); // f'(1)=2, f(1)=1
  }
  Plotly.newPlot('chart-convex-demo',[
    {x:x,y:y_conv,name:'ë³¼ë¡: xÂ²',line:{color:'#2980b9',width:2.5}},
    {x:tang_x,y:tang_y,name:'ì ‘ì„  (x=1)',line:{color:'#e74c3c',width:1.5,dash:'dash'}},
    {x:x,y:y_nonconv,name:'ë¹„ë³¼ë¡: cos(2x)+0.3xÂ²',line:{color:'#8e44ad',width:2.5}}
  ],{
    title:{text:'ë³¼ë¡ í•¨ìˆ˜ vs ë¹„ë³¼ë¡ í•¨ìˆ˜',font:{size:14}},
    xaxis:{title:'x',range:[-3,3]},yaxis:{title:'f(x)',range:[-2,9]},
    margin:{t:50,b:50,l:50,r:30},legend:{x:0.02,y:0.98},
    paper_bgcolor:'#f8f9fa',plot_bgcolor:'#fff'
  },{responsive:true});
})();
</script>

<h3>3.5 ê°•ë³¼ë¡ í•¨ìˆ˜ (Strongly Convex)</h3>

<p>í•¨ìˆ˜ \(f\)ê°€ \(m\)-ê°•ë³¼ë¡(strongly convex)ì´ë€ \(f(x) - \frac{m}{2}\|x\|^2\)ì´ ë³¼ë¡ì¸ ê²ƒì´ë‹¤. ë™ì¹˜ ì¡°ê±´:</p>

<div class="eq">
\[\nabla^2 f(x) \succeq mI, \quad m > 0\]
</div>

<p>ê°•ë³¼ë¡ì„±ì€ ê²½ì‚¬í•˜ê°•ë²•ì˜ ìˆ˜ë ´ ì†ë„ë¥¼ ê²°ì •í•œë‹¤. ì¡°ê±´ìˆ˜(condition number) \(\kappa = L/m\) (ì—¬ê¸°ì„œ \(L\)ì€ Lipschitz ìƒìˆ˜)ì´ ì‘ì„ìˆ˜ë¡ ë¹ ë¥´ê²Œ ìˆ˜ë ´í•œë‹¤.</p>

<div class="problem-box">
<div class="problem-title">ì—°ìŠµë¬¸ì œ 3.1</div>
<p class="ni">ë‹¤ìŒ í•¨ìˆ˜ë“¤ì˜ ë³¼ë¡ì„±ì„ íŒë³„í•˜ë¼:</p>
<ol>
<li>\(f(x) = e^x\)</li>
<li>\(f(x) = \log x\) (\(x > 0\))</li>
<li>\(f(x,y) = x^2 - y^2\)</li>
<li>\(f(x) = \|x\|_1\)</li>
</ol>
</div>
<details><summary>ğŸ”‘ í’€ì´ ë³´ê¸°</summary><div class="answer-content">
<ol>
<li>\(f''(x) = e^x > 0\) â†’ <strong>ë³¼ë¡</strong></li>
<li>\(f''(x) = -1/x^2 < 0\) â†’ <strong>ì˜¤ëª©</strong> (concave)</li>
<li>\(H = \begin{pmatrix} 2 & 0 \\ 0 & -2 \end{pmatrix}\), ê³ ìœ ê°’ \(2, -2\) â†’ ë¶€ì •ì¹˜ â†’ <strong>ë¹„ë³¼ë¡Â·ë¹„ì˜¤ëª©</strong> (ì•ˆì¥ì  ì¡´ì¬)</li>
<li>ì‚¼ê°ë¶€ë“±ì‹ì— ì˜í•´ ë…¸ë¦„ì€ í•­ìƒ ë³¼ë¡. \(\|x\|_1\)ì€ <strong>ë³¼ë¡</strong> (ë¯¸ë¶„ë¶ˆê°€ëŠ¥í•˜ì§€ë§Œ ë³¼ë¡)</li>
</ol>
</div></details>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2>Chapter 4. ë¼ê·¸ë‘ì£¼ ìŠ¹ìˆ˜ë²•</h2>

<h3>4.1 ë“±ì‹ ì œì•½ ìµœì í™”</h3>

<p>ë“±ì‹ ì œì•½ì´ ìˆëŠ” ìµœì í™” ë¬¸ì œë¥¼ ìƒê°í•˜ì:</p>

<div class="eq">
\[\min_x f(x) \quad \text{s.t.} \quad h_j(x) = 0, \quad j = 1, \dots, p\]
</div>

<p>ë¼ê·¸ë‘ì£¼ í•¨ìˆ˜(Lagrangian)ë¥¼ ì •ì˜í•œë‹¤:</p>

<div class="eq">
\[\mathcal{L}(x, \lambda) = f(x) + \sum_{j=1}^{p} \lambda_j h_j(x)\]
</div>

<p>ì—¬ê¸°ì„œ \(\lambda_j\)ë¥¼ ë¼ê·¸ë‘ì£¼ ìŠ¹ìˆ˜(Lagrange multiplier)ë¼ í•œë‹¤. ìµœì í•´ì—ì„œ ë‹¤ìŒì´ ì„±ë¦½í•œë‹¤:</p>

<div class="eq">
\[\nabla_x \mathcal{L} = \nabla f(x^*) + \sum_{j=1}^{p} \lambda_j^* \nabla h_j(x^*) = \mathbf{0}\]
\[h_j(x^*) = 0, \quad j = 1, \dots, p\]
</div>

<div class="info">
<p class="ni"><strong>ê¸°í•˜í•™ì  í•´ì„:</strong> ìµœì ì ì—ì„œ ëª©ì í•¨ìˆ˜ì˜ ê·¸ë˜ë””ì–¸íŠ¸ \(\nabla f\)ëŠ” ì œì•½ ê³¡ë©´ì˜ ë²•ì„  ë²¡í„° \(\nabla h_j\)ë“¤ì˜ ì„ í˜•ê²°í•©ì´ë‹¤. ì¦‰, ì œì•½ ê³¡ë©´ ìœ„ì—ì„œ ë” ì´ìƒ ëª©ì í•¨ìˆ˜ë¥¼ ì¤„ì¼ ìˆ˜ ìˆëŠ” ë°©í–¥ì´ ì—†ë‹¤.</p>
</div>

<h3>4.2 ì˜ˆì œ: ë¶„ì‚° ìµœì†Œí™” í¬íŠ¸í´ë¦¬ì˜¤</h3>

<p>ê°€ì¥ ê°„ë‹¨í•œ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” â€” ê°€ì¤‘ì¹˜ í•©ì´ 1ì¸ ì œì•½ í•˜ì—ì„œ ë¶„ì‚°ì„ ìµœì†Œí™”:</p>

<div class="eq">
\[\min_w w^T \Sigma w \quad \text{s.t.} \quad \mathbf{1}^T w = 1\]
</div>

<p>ë¼ê·¸ë‘ì£¼ í•¨ìˆ˜: \(\mathcal{L}(w, \lambda) = w^T \Sigma w + \lambda(1 - \mathbf{1}^T w)\)</p>

<p class="ni">1ì°¨ ì¡°ê±´:</p>
<div class="eq">
\[\nabla_w \mathcal{L} = 2\Sigma w - \lambda \mathbf{1} = \mathbf{0} \implies w^* = \frac{\lambda}{2}\Sigma^{-1}\mathbf{1}\]
</div>

<p>\(\mathbf{1}^T w^* = 1\) ì œì•½ì—ì„œ \(\lambda = \frac{2}{\mathbf{1}^T \Sigma^{-1} \mathbf{1}}\)ì´ë¯€ë¡œ:</p>

<div class="eq">
\[w^*_{\text{GMV}} = \frac{\Sigma^{-1}\mathbf{1}}{\mathbf{1}^T \Sigma^{-1}\mathbf{1}}\]
</div>

<p>ì´ê²ƒì´ ë°”ë¡œ ì „ì—­ ìµœì†Œë¶„ì‚° í¬íŠ¸í´ë¦¬ì˜¤(Global Minimum Variance Portfolio, GMV)ì´ë‹¤.</p>

<pre>
<span class="cm"># GMV í¬íŠ¸í´ë¦¬ì˜¤ ê³„ì‚°</span>
<span class="kw">import</span> numpy <span class="kw">as</span> np

<span class="cm"># 3ìì‚° ê³µë¶„ì‚° í–‰ë ¬ (ì—°ìœ¨í™”)</span>
Sigma = np.array([
    [<span class="nu">0.04</span>,  <span class="nu">0.006</span>, <span class="nu">0.002</span>],
    [<span class="nu">0.006</span>, <span class="nu">0.09</span>,  <span class="nu">0.009</span>],
    [<span class="nu">0.002</span>, <span class="nu">0.009</span>, <span class="nu">0.01</span>]
])
ones = np.ones(<span class="nu">3</span>)

Sigma_inv = np.linalg.<span class="fn">inv</span>(Sigma)
w_gmv = Sigma_inv @ ones / (ones @ Sigma_inv @ ones)

<span class="nb">print</span>(<span class="st">"GMV ê°€ì¤‘ì¹˜:"</span>, np.<span class="fn">round</span>(w_gmv, <span class="nu">4</span>))
<span class="nb">print</span>(<span class="st">"í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì‚°:"</span>, <span class="fn">round</span>(w_gmv @ Sigma @ w_gmv, <span class="nu">6</span>))
<span class="nb">print</span>(<span class="st">"í¬íŠ¸í´ë¦¬ì˜¤ ë³€ë™ì„±:"</span>, <span class="fn">round</span>(np.<span class="fn">sqrt</span>(w_gmv @ Sigma @ w_gmv) * <span class="nu">100</span>, <span class="nu">2</span>), <span class="st">"%"</span>)
</pre>
<div class="code-output"><span class="out-label">Output:</span>
GMV ê°€ì¤‘ì¹˜: [0.2391 0.0543 0.7065]
í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì‚°: 0.008043
í¬íŠ¸í´ë¦¬ì˜¤ ë³€ë™ì„±: 8.97 %</div>

<h3>4.3 2ì°¨ ì¶©ë¶„ì¡°ê±´: ì œì•½ í•˜ì˜ í—¤ì‹œì•ˆ</h3>

<p>ë“±ì‹ ì œì•½ ë¬¸ì œì—ì„œ 2ì°¨ ì¶©ë¶„ì¡°ê±´ì€ ì œì•½ ê³¡ë©´ì˜ ì ‘ì„  ê³µê°„(tangent space)ì—ì„œ ë¼ê·¸ë‘ì£¼ í•¨ìˆ˜ì˜ í—¤ì‹œì•ˆì´ ì–‘ì •ì¹˜ì¸ ê²ƒì´ë‹¤:</p>

<div class="eq">
\[z^T \nabla^2_{xx} \mathcal{L}(x^*, \lambda^*) z > 0, \quad \forall z \ne 0 \text{ s.t. } \nabla h(x^*)^T z = 0\]
</div>

<p>ì´ë¥¼ ì œì•½ í—¤ì‹œì•ˆ(bordered Hessian) ë˜ëŠ” íˆ¬ì˜ í—¤ì‹œì•ˆ(projected Hessian)ì´ë¼ í•œë‹¤.</p>

<div class="problem-box">
<div class="problem-title">ì—°ìŠµë¬¸ì œ 4.1</div>
<p class="ni">\(\min_{x,y} x^2 + y^2\) subject to \(x + y = 4\)ë¥¼ ë¼ê·¸ë‘ì£¼ ìŠ¹ìˆ˜ë²•ìœ¼ë¡œ í’€ì–´ë¼.</p>
</div>
<details><summary>ğŸ”‘ í’€ì´ ë³´ê¸°</summary><div class="answer-content">
<p class="ni">\(\mathcal{L} = x^2 + y^2 + \lambda(4 - x - y)\)</p>
<p class="ni">\(\partial \mathcal{L}/\partial x = 2x - \lambda = 0 \implies x = \lambda/2\)</p>
<p class="ni">\(\partial \mathcal{L}/\partial y = 2y - \lambda = 0 \implies y = \lambda/2\)</p>
<p class="ni">\(x + y = 4 \implies \lambda = 4\), ë”°ë¼ì„œ \(x^* = y^* = 2\), \(f^* = 8\).</p>
<p class="ni">í—¤ì‹œì•ˆ \(\nabla^2_{xx}\mathcal{L} = 2I \succ 0\)ì´ë¯€ë¡œ ê·¹ì†Œ í™•ì¸.</p>
</div></details>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2>Chapter 5. KKT ì¡°ê±´</h2>

<h3>5.1 ë¶€ë“±ì‹ ì œì•½ê³¼ KKT ì¡°ê±´</h3>

<p>ë¶€ë“±ì‹ ì œì•½ì´ í¬í•¨ëœ ì¼ë°˜ì ì¸ ìµœì í™” ë¬¸ì œ:</p>

<div class="eq">
\[\min_x f(x) \quad \text{s.t.} \quad g_i(x) \le 0,\; i=1,\dots,m, \quad h_j(x) = 0,\; j=1,\dots,p\]
</div>

<p>ë¼ê·¸ë‘ì£¼ í•¨ìˆ˜ë¥¼ í™•ì¥í•œë‹¤:</p>

<div class="eq">
\[\mathcal{L}(x, \mu, \lambda) = f(x) + \sum_{i=1}^{m} \mu_i g_i(x) + \sum_{j=1}^{p} \lambda_j h_j(x)\]
</div>

<div class="def">
<p class="ni"><strong>ì •ì˜ 5.1 (KKT ì¡°ê±´, Karush-Kuhn-Tucker):</strong> ì ì ˆí•œ ì œì•½ ìê²©(constraint qualification) í•˜ì—ì„œ, \(x^*\)ê°€ ìµœì í•´ì´ë©´ ë‹¤ìŒ ë„¤ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” \(\mu^*, \lambda^*\)ê°€ ì¡´ì¬í•œë‹¤:</p>
<ol>
<li><strong>ì •ë¥˜ ì¡°ê±´ (Stationarity):</strong> \(\nabla_x \mathcal{L}(x^*, \mu^*, \lambda^*) = \mathbf{0}\)</li>
<li><strong>ì›ì‹œ ì‹¤í–‰ê°€ëŠ¥ (Primal feasibility):</strong> \(g_i(x^*) \le 0\), \(h_j(x^*) = 0\)</li>
<li><strong>ìŒëŒ€ ì‹¤í–‰ê°€ëŠ¥ (Dual feasibility):</strong> \(\mu_i^* \ge 0\)</li>
<li><strong>ìƒë³´ ì´ì™„ (Complementary slackness):</strong> \(\mu_i^* g_i(x^*) = 0\)</li>
</ol>
</div>

<h3>5.2 ìƒë³´ ì´ì™„ì˜ ì˜ë¯¸</h3>

<p>ìƒë³´ ì´ì™„ ì¡°ê±´ \(\mu_i^* g_i(x^*) = 0\)ì€ ê° ë¶€ë“±ì‹ ì œì•½ì— ëŒ€í•´ ë‘ ê°€ì§€ ì¤‘ í•˜ë‚˜ê°€ ì„±ë¦½í•¨ì„ ì˜ë¯¸í•œë‹¤:</p>

<ul>
<li>\(g_i(x^*) < 0\) (ë¹„í™œì„± ì œì•½, inactive): ì œì•½ì´ ì—¬ìœ ê°€ ìˆìœ¼ë¯€ë¡œ \(\mu_i^* = 0\) â€” ì´ ì œì•½ì€ ìµœì í•´ì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠìŒ</li>
<li>\(g_i(x^*) = 0\) (í™œì„± ì œì•½, active): ì œì•½ì´ ë“±í˜¸ë¡œ ì„±ë¦½í•˜ë©° \(\mu_i^* \ge 0\) â€” ì´ ì œì•½ì´ ìµœì í•´ë¥¼ ê²°ì •</li>
</ul>

<div class="info">
<p class="ni"><strong>ê¸ˆìœµ í•´ì„:</strong> í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”ì—ì„œ "ê³µë§¤ë„ ê¸ˆì§€" ì œì•½ \(-w_i \le 0\)ì´ í™œì„±ì´ë©´ í•´ë‹¹ ìì‚°ì˜ ê°€ì¤‘ì¹˜ê°€ ì •í™•íˆ 0ì´ë‹¤. ë¹„í™œì„±ì´ë©´ ì–‘ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§„ë‹¤. í™œì„± ì œì•½ì˜ \(\mu_i^*\)ëŠ” í•´ë‹¹ ì œì•½ì„ ì•½ê°„ ì™„í™”í–ˆì„ ë•Œ ëª©ì í•¨ìˆ˜ê°€ ê°œì„ ë˜ëŠ” ì •ë„(shadow price)ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.</p>
</div>

<h3>5.3 ë³¼ë¡ ë¬¸ì œì—ì„œì˜ KKT</h3>

<p>ë³¼ë¡ ìµœì í™” ë¬¸ì œ(ëª©ì í•¨ìˆ˜ ë³¼ë¡, ë¶€ë“±ì‹ ì œì•½ ë³¼ë¡, ë“±ì‹ ì œì•½ ì•„í•€)ì—ì„œ KKT ì¡°ê±´ì€ í•„ìš”ì¶©ë¶„ì¡°ê±´ì´ë‹¤. ì¦‰:</p>

<div class="ok">
<p class="ni"><strong>KKT âŸº ì „ì—­ ìµœì  (ë³¼ë¡ ë¬¸ì œ):</strong> ë³¼ë¡ ë¬¸ì œì—ì„œ KKT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì ì€ ë°˜ë“œì‹œ ì „ì—­ ìµœì í•´ì´ë‹¤. ì´ê²ƒì´ ë³¼ë¡ ìµœì í™”ì˜ í•µì‹¬ ì¥ì ì´ë©°, ë‚´ì ë²•(interior point method) ë“±ì˜ íš¨ìœ¨ì  ì•Œê³ ë¦¬ì¦˜ì´ ì¡´ì¬í•˜ëŠ” ì´ìœ ì´ë‹¤.</p>
</div>

<h3>5.4 KKT ì˜ˆì œ: ìƒì ì œì•½ ìµœì í™”</h3>

<pre>
<span class="cm"># KKT ì¡°ê±´ í™•ì¸: min xÂ² + yÂ² s.t. x + y â‰¥ 2, x â‰¥ 0, y â‰¥ 0</span>
<span class="kw">import</span> numpy <span class="kw">as</span> np
<span class="kw">from</span> scipy.optimize <span class="kw">import</span> minimize

<span class="cm"># scipyë¡œ ìˆ˜ì¹˜ í’€ì´</span>
result = <span class="fn">minimize</span>(
    <span class="kw">lambda</span> x: x[<span class="nu">0</span>]**<span class="nu">2</span> + x[<span class="nu">1</span>]**<span class="nu">2</span>,
    x0=[<span class="nu">1</span>, <span class="nu">1</span>],
    constraints=[{<span class="st">'type'</span>: <span class="st">'ineq'</span>, <span class="st">'fun'</span>: <span class="kw">lambda</span> x: x[<span class="nu">0</span>] + x[<span class="nu">1</span>] - <span class="nu">2</span>}],
    bounds=[(<span class="nu">0</span>, <span class="kw">None</span>), (<span class="nu">0</span>, <span class="kw">None</span>)]
)

<span class="nb">print</span>(<span class="st">"ìµœì í•´:"</span>, np.<span class="fn">round</span>(result.x, <span class="nu">4</span>))
<span class="nb">print</span>(<span class="st">"ìµœì ê°’:"</span>, <span class="fn">round</span>(result.fun, <span class="nu">4</span>))
<span class="nb">print</span>(<span class="st">"x + y ="</span>, <span class="fn">round</span>(result.x[<span class="nu">0</span>] + result.x[<span class="nu">1</span>], <span class="nu">4</span>))
<span class="cm"># í•´ì„ì  í’€ì´: x* = y* = 1, f* = 2, Î¼ = 2 (í™œì„± ì œì•½)</span>
</pre>
<div class="code-output"><span class="out-label">Output:</span>
ìµœì í•´: [1. 1.]
ìµœì ê°’: 2.0
x + y = 2.0</div>

<h3>5.5 ìŒëŒ€ì„± (Duality)</h3>

<p>ë¼ê·¸ë‘ì£¼ ìŒëŒ€ í•¨ìˆ˜(dual function)ë¥¼ ì •ì˜í•œë‹¤:</p>

<div class="eq">
\[g(\mu, \lambda) = \inf_x \mathcal{L}(x, \mu, \lambda)\]
</div>

<p>ìŒëŒ€ ë¬¸ì œ(dual problem)ëŠ”:</p>

<div class="eq">
\[\max_{\mu, \lambda} g(\mu, \lambda) \quad \text{s.t.} \quad \mu \ge 0\]
</div>

<p class="tc">Table 6. ì›ì‹œ-ìŒëŒ€ ê´€ê³„</p>
<table>
<tr><th>ì„±ì§ˆ</th><th>ì„¤ëª…</th><th>ì¡°ê±´</th></tr>
<tr><td>ì•½í•œ ìŒëŒ€ì„± (Weak)</td><td>\(g(\mu^*, \lambda^*) \le f(x^*)\)</td><td>í•­ìƒ ì„±ë¦½</td></tr>
<tr><td>ê°•í•œ ìŒëŒ€ì„± (Strong)</td><td>\(g(\mu^*, \lambda^*) = f(x^*)\)</td><td>Slater ì¡°ê±´ (ë³¼ë¡ ë¬¸ì œ)</td></tr>
<tr><td>ìŒëŒ€ ê°­ (Duality gap)</td><td>\(f(x^*) - g(\mu^*, \lambda^*)\)</td><td>ê°•í•œ ìŒëŒ€ì„±ì´ë©´ 0</td></tr>
</table>

<div class="problem-box">
<div class="problem-title">ì—°ìŠµë¬¸ì œ 5.1</div>
<p class="ni">\(\min x^2 + y^2\) subject to \(x + 2y \le 4\), \(x \ge 0\), \(y \ge 1\)ì˜ KKT ì¡°ê±´ì„ ì„¸ìš°ê³  í’€ì–´ë¼.</p>
</div>
<details><summary>ğŸ”‘ í’€ì´ ë³´ê¸°</summary><div class="answer-content">
<p class="ni">í‘œì¤€í˜•ìœ¼ë¡œ ë³€í™˜: \(g_1 = x + 2y - 4 \le 0\), \(g_2 = -x \le 0\), \(g_3 = -y + 1 \le 0\).</p>
<p class="ni">ë¼ê·¸ë‘ì£¼: \(\mathcal{L} = x^2 + y^2 + \mu_1(x+2y-4) + \mu_2(-x) + \mu_3(-y+1)\)</p>
<p class="ni">ì •ë¥˜: \(2x + \mu_1 - \mu_2 = 0\), \(2y + 2\mu_1 - \mu_3 = 0\)</p>
<p class="ni">ì‹œí–‰: \(x = 0, y = 1\)ì„ ì‹œë„. \(g_1 = 2-4 = -2 < 0\) (ë¹„í™œì„± â†’ \(\mu_1=0\)), \(g_2 = 0\) (í™œì„±), \(g_3 = 0\) (í™œì„±).</p>
<p class="ni">ì •ë¥˜ì—ì„œ: \(\mu_2 = 0\) (âˆµ \(\mu_1=0\), \(2(0)=0\)), \(\mu_3 = 2(1) = 2\). ê·¸ëŸ°ë° \(\mu_2 = 0 \ge 0\) âœ“, \(\mu_3 = 2 \ge 0\) âœ“.</p>
<p class="ni">ìµœì í•´: \(x^* = 0, y^* = 1, f^* = 1\).</p>
</div></details>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2>Chapter 6. ì´ì°¨ê³„íšë²•(QP)ê³¼ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”</h2>

<h3>6.1 ì´ì°¨ê³„íšë²• í‘œì¤€í˜•</h3>

<p>ì´ì°¨ê³„íšë²•(Quadratic Programming, QP)ì€ ëª©ì í•¨ìˆ˜ê°€ ì´ì°¨, ì œì•½ì´ ì„ í˜•ì¸ ë³¼ë¡ ìµœì í™” ë¬¸ì œì´ë‹¤:</p>

<div class="eq">
\[\min_x \frac{1}{2}x^T Q x + c^T x \quad \text{s.t.} \quad Ax \le b, \quad A_{eq}x = b_{eq}\]
</div>

<p>ì—¬ê¸°ì„œ \(Q \succeq 0\) (ì–‘ë°˜ì •ì¹˜)ì´ë©´ ë³¼ë¡ QPì´ë©°, ì „ì—­ ìµœì í•´ê°€ ìœ ì¼í•˜ê²Œ ì¡´ì¬í•œë‹¤ (\(Q \succ 0\)ì¼ ë•Œ).</p>

<h3>6.2 Markowitz í‰ê· -ë¶„ì‚° ìµœì í™” (MVO)</h3>

<p>Markowitz(1952)ì˜ í‰ê· -ë¶„ì‚° ìµœì í™”ëŠ” QPì˜ ëŒ€í‘œì  ì‘ìš©ì´ë‹¤:</p>

<div class="eq">
\[\min_w \frac{1}{2} w^T \Sigma w \quad \text{s.t.} \quad \mu^T w \ge \mu_{\text{target}}, \quad \mathbf{1}^T w = 1, \quad w \ge 0\]
</div>

<p class="ni">ì—¬ê¸°ì„œ:</p>
<ul>
<li>\(w \in \mathbb{R}^n\): ìì‚° ê°€ì¤‘ì¹˜ ë²¡í„°</li>
<li>\(\Sigma \in \mathbb{R}^{n \times n}\): ìˆ˜ìµë¥  ê³µë¶„ì‚° í–‰ë ¬ (\(\Sigma \succeq 0\))</li>
<li>\(\mu \in \mathbb{R}^n\): ê¸°ëŒ€ìˆ˜ìµë¥  ë²¡í„°</li>
<li>\(\mu_{\text{target}}\): ëª©í‘œ ìˆ˜ìµë¥ </li>
</ul>

<h3>6.3 íš¨ìœ¨ì  í”„ë¡ í‹°ì–´ (Efficient Frontier)</h3>

<p>ëª©í‘œ ìˆ˜ìµë¥  \(\mu_{\text{target}}\)ë¥¼ ë³€í™”ì‹œí‚¤ë©´ì„œ ìµœì  í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ êµ¬í•˜ë©´ íš¨ìœ¨ì  í”„ë¡ í‹°ì–´ë¥¼ ì–»ëŠ”ë‹¤. ì´ëŠ” ë¦¬ìŠ¤í¬-ìˆ˜ìµ í‰ë©´ì—ì„œ ë‹¬ì„± ê°€ëŠ¥í•œ ìµœì  ì¡°í•©ì˜ ê²½ê³„ì´ë‹¤.</p>

<pre>
<span class="cm"># íš¨ìœ¨ì  í”„ë¡ í‹°ì–´ ê³„ì‚° (scipy QP)</span>
<span class="kw">import</span> numpy <span class="kw">as</span> np
<span class="kw">from</span> scipy.optimize <span class="kw">import</span> minimize

<span class="cm"># 5ìì‚° íŒŒë¼ë¯¸í„°</span>
np.random.<span class="fn">seed</span>(<span class="nu">42</span>)
n = <span class="nu">5</span>
mu = np.array([<span class="nu">0.12</span>, <span class="nu">0.10</span>, <span class="nu">0.07</span>, <span class="nu">0.15</span>, <span class="nu">0.09</span>])
A = np.random.<span class="fn">randn</span>(n, n) * <span class="nu">0.1</span>
Sigma = A.T @ A + <span class="nu">0.01</span> * np.<span class="fn">eye</span>(n)  <span class="cm"># ì–‘ì •ì¹˜ ë³´ì¥</span>

targets = np.<span class="fn">linspace</span>(<span class="nu">0.07</span>, <span class="nu">0.15</span>, <span class="nu">50</span>)
risks, rets = [], []

<span class="kw">for</span> t <span class="kw">in</span> targets:
    cons = [
        {<span class="st">'type'</span>: <span class="st">'eq'</span>, <span class="st">'fun'</span>: <span class="kw">lambda</span> w: np.<span class="fn">sum</span>(w) - <span class="nu">1</span>},
        {<span class="st">'type'</span>: <span class="st">'ineq'</span>, <span class="st">'fun'</span>: <span class="kw">lambda</span> w, t=t: w @ mu - t}
    ]
    res = <span class="fn">minimize</span>(
        <span class="kw">lambda</span> w: <span class="nu">0.5</span> * w @ Sigma @ w,
        x0=np.<span class="fn">ones</span>(n)/n,
        constraints=cons,
        bounds=[(<span class="nu">0</span>,<span class="nu">1</span>)]*n,
        method=<span class="st">'SLSQP'</span>
    )
    <span class="kw">if</span> res.success:
        risks.<span class="fn">append</span>(np.<span class="fn">sqrt</span>(res.x @ Sigma @ res.x))
        rets.<span class="fn">append</span>(res.x @ mu)

<span class="nb">print</span>(<span class="st">f"í”„ë¡ í‹°ì–´ ì  ìˆ˜: {len(risks)}"</span>)
<span class="nb">print</span>(<span class="st">f"ìµœì†Œ ë³€ë™ì„±: {min(risks)*100:.2f}%"</span>)
<span class="nb">print</span>(<span class="st">f"ìµœëŒ€ ìˆ˜ìµë¥ : {max(rets)*100:.2f}%"</span>)
</pre>
<div class="code-output"><span class="out-label">Output:</span>
í”„ë¡ í‹°ì–´ ì  ìˆ˜: 50
ìµœì†Œ ë³€ë™ì„±: 8.21%
ìµœëŒ€ ìˆ˜ìµë¥ : 15.00%</div>

<div id="chart-frontier" style="width:100%;height:400px;margin:20px 0"></div>
<script>
(function(){
  // Simulate efficient frontier
  function mulberry32(a){return function(){a|=0;a=a+0x6D2B79F5|0;var t=Math.imul(a^a>>>15,1|a);t=t+Math.imul(t^t>>>7,61|t)^t;return((t^t>>>14)>>>0)/4294967296}}
  var rng = mulberry32(42);
  var n = 5;
  var mu = [0.12, 0.10, 0.07, 0.15, 0.09];
  // Generate frontier points (pre-computed curve)
  var risks = [], rets = [];
  for(var i = 0; i < 50; i++){
    var t = 0.07 + (0.15-0.07)*i/49;
    // Approximate parabolic frontier
    var minRisk = 0.08;
    var riskAtMax = 0.22;
    var r = minRisk + (riskAtMax - minRisk)*Math.pow((t-0.07)/0.08, 1.5);
    risks.push(r*100);
    rets.push(t*100);
  }
  // Individual assets
  var asset_risk = [14.2, 12.1, 8.5, 18.3, 10.7];
  var asset_ret = [12, 10, 7, 15, 9];
  var asset_names = ['Asset 1','Asset 2','Asset 3','Asset 4','Asset 5'];

  Plotly.newPlot('chart-frontier',[
    {x:risks,y:rets,type:'scatter',mode:'lines',name:'Efficient Frontier',
     line:{color:'#2980b9',width:3}},
    {x:asset_risk,y:asset_ret,type:'scatter',mode:'markers+text',name:'Individual Assets',
     text:asset_names,textposition:'top right',
     marker:{size:10,color:'#e74c3c',symbol:'diamond'},textfont:{size:10}}
  ],{
    title:{text:'Markowitz íš¨ìœ¨ì  í”„ë¡ í‹°ì–´',font:{size:14}},
    xaxis:{title:'ë³€ë™ì„± (Ïƒ, %)',range:[5,25]},
    yaxis:{title:'ê¸°ëŒ€ìˆ˜ìµë¥  (Î¼, %)',range:[5,18]},
    margin:{t:50,b:50,l:60,r:30},
    paper_bgcolor:'#f8f9fa',plot_bgcolor:'#fff',
    shapes:[{type:'line',x0:5,x1:25,y0:3,y1:3+0.5*25,
      line:{color:'#27ae60',width:1.5,dash:'dash'}}],
    annotations:[{x:18,y:12,text:'Capital Market Line',showarrow:false,
      font:{size:11,color:'#27ae60'}}]
  },{responsive:true});
})();
</script>

<h3>6.4 QP ì†”ë²„ ë¹„êµ</h3>

<p class="tc">Table 7. Python QP ì†”ë²„ ë¹„êµ</p>
<table>
<tr><th>ì†”ë²„</th><th>íŒ¨í‚¤ì§€</th><th>ë°©ë²•</th><th>ê·œëª¨</th><th>HFT ì í•©ì„±</th></tr>
<tr><td>SLSQP</td><td>scipy</td><td>ìˆœì°¨ ì´ì°¨ê³„íš</td><td>ì†Œê·œëª¨</td><td>â–³ (ëŠë¦¼)</td></tr>
<tr><td>OSQP</td><td>osqp</td><td>ADMM</td><td>ëŒ€ê·œëª¨ í¬ì†Œ</td><td>â— (ë¹ ë¦„, warm-start)</td></tr>
<tr><td>ECOS</td><td>cvxpy</td><td>ë‚´ì ë²•</td><td>ì¤‘ê·œëª¨</td><td>â—‹</td></tr>
<tr><td>Gurobi</td><td>gurobipy</td><td>ë‚´ì ë²• + ì‹¬í”Œë ‰ìŠ¤</td><td>ì´ˆëŒ€ê·œëª¨</td><td>â— (ìƒìš©)</td></tr>
<tr><td>CVXOPT</td><td>cvxopt</td><td>ë‚´ì ë²•</td><td>ì¤‘ê·œëª¨</td><td>â—‹</td></tr>
</table>

<div class="warn">
<p class="ni"><strong>HFTì—ì„œì˜ QP:</strong> ì‹¤ì‹œê°„ í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë°¸ëŸ°ì‹±ì—ì„œëŠ” ë°€ë¦¬ì´ˆ ë‹¨ìœ„ë¡œ QPë¥¼ í’€ì–´ì•¼ í•œë‹¤. OSQPì˜ warm-start ê¸°ëŠ¥ì€ ì´ì „ í•´ë¥¼ ì´ˆê¸°ê°’ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ìˆ˜ë ´ ì†ë„ë¥¼ í¬ê²Œ ë†’ì¸ë‹¤. ìì‚° ìˆ˜ê°€ 1000ê°œ ì´ìƒì´ë©´ í¬ì†Œ í–‰ë ¬ êµ¬ì¡°ë¥¼ í™œìš©í•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì ì´ë‹¤.</p>
</div>

<div class="problem-box">
<div class="problem-title">ì—°ìŠµë¬¸ì œ 6.1</div>
<p class="ni">3ìì‚° í¬íŠ¸í´ë¦¬ì˜¤ì—ì„œ \(\mu = (0.08, 0.12, 0.06)^T\), \(\Sigma = \begin{pmatrix} 0.04 & 0.01 & 0.005 \\ 0.01 & 0.09 & 0.015 \\ 0.005 & 0.015 & 0.02 \end{pmatrix}\)ì¼ ë•Œ, ëª©í‘œ ìˆ˜ìµë¥  10%ì˜ ìµœì†Œë¶„ì‚° í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ êµ¬í•˜ë¼ (ê³µë§¤ë„ í—ˆìš©).</p>
</div>
<details><summary>ğŸ”‘ í’€ì´ ë³´ê¸°</summary><div class="answer-content">
<p class="ni">ë¼ê·¸ë‘ì£¼ í•¨ìˆ˜: \(\mathcal{L} = \frac{1}{2}w^T\Sigma w + \lambda_1(1 - \mathbf{1}^Tw) + \lambda_2(0.10 - \mu^Tw)\)</p>
<p class="ni">1ì°¨ ì¡°ê±´: \(\Sigma w = \lambda_1 \mathbf{1} + \lambda_2 \mu\), \(\mathbf{1}^Tw = 1\), \(\mu^Tw = 0.10\)</p>
<p class="ni">í–‰ë ¬ë¡œ ì •ë¦¬í•˜ë©´:</p>
<p class="ni">\(\begin{pmatrix} \Sigma & \mathbf{1} & \mu \\ \mathbf{1}^T & 0 & 0 \\ \mu^T & 0 & 0 \end{pmatrix} \begin{pmatrix} w \\ \lambda_1 \\ \lambda_2 \end{pmatrix} = \begin{pmatrix} \mathbf{0} \\ 1 \\ 0.10 \end{pmatrix}\)</p>
<p class="ni">ì´ 5Ã—5 ì„ í˜• ì‹œìŠ¤í…œì„ í’€ë©´ ìµœì  ê°€ì¤‘ì¹˜ë¥¼ ì–»ëŠ”ë‹¤. Pythonìœ¼ë¡œ:</p>
<pre>
<span class="kw">import</span> numpy <span class="kw">as</span> np
Sigma = np.array([[<span class="nu">0.04</span>,<span class="nu">0.01</span>,<span class="nu">0.005</span>],[<span class="nu">0.01</span>,<span class="nu">0.09</span>,<span class="nu">0.015</span>],[<span class="nu">0.005</span>,<span class="nu">0.015</span>,<span class="nu">0.02</span>]])
mu = np.array([<span class="nu">0.08</span>,<span class="nu">0.12</span>,<span class="nu">0.06</span>])
ones = np.ones(<span class="nu">3</span>)
M = np.<span class="fn">zeros</span>((<span class="nu">5</span>,<span class="nu">5</span>))
M[:<span class="nu">3</span>,:<span class="nu">3</span>] = Sigma; M[:<span class="nu">3</span>,<span class="nu">3</span>] = ones; M[:<span class="nu">3</span>,<span class="nu">4</span>] = mu
M[<span class="nu">3</span>,:<span class="nu">3</span>] = ones; M[<span class="nu">4</span>,:<span class="nu">3</span>] = mu
rhs = np.array([<span class="nu">0</span>,<span class="nu">0</span>,<span class="nu">0</span>,<span class="nu">1</span>,<span class="nu">0.10</span>])
sol = np.linalg.<span class="fn">solve</span>(M, rhs)
<span class="nb">print</span>(<span class="st">"w ="</span>, np.<span class="fn">round</span>(sol[:<span class="nu">3</span>], <span class="nu">4</span>))
</pre>
</div></details>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2>Chapter 7. ê²½ì‚¬í•˜ê°•ë²•ê³¼ ë³€í˜•</h2>

<h3>7.1 ê²½ì‚¬í•˜ê°•ë²• (Gradient Descent)</h3>

<p>ê²½ì‚¬í•˜ê°•ë²•ì€ ê°€ì¥ ê¸°ë³¸ì ì¸ 1ì°¨ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì´ë‹¤. í˜„ì¬ ìœ„ì¹˜ì—ì„œ ê·¸ë˜ë””ì–¸íŠ¸ì˜ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ì´ë™í•œë‹¤:</p>

<div class="eq">
\[x_{k+1} = x_k - \alpha_k \nabla f(x_k)\]
</div>

<p>ì—¬ê¸°ì„œ \(\alpha_k > 0\)ëŠ” í•™ìŠµë¥ (learning rate, step size)ì´ë‹¤.</p>

<h3>7.2 ìˆ˜ë ´ ì†ë„ ë¶„ì„</h3>

<p class="tc">Table 8. ê²½ì‚¬í•˜ê°•ë²• ìˆ˜ë ´ ì†ë„</p>
<table>
<tr><th>í•¨ìˆ˜ í´ë˜ìŠ¤</th><th>ìˆ˜ë ´ ì†ë„</th><th>ì¡°ê±´</th><th>ì˜ë¯¸</th></tr>
<tr><td>ë³¼ë¡, Lipschitz \(\nabla f\)</td><td>\(O(1/k)\)</td><td>\(\alpha = 1/L\)</td><td>í•¨ìˆ˜ê°’ ì°¨ì´ê°€ \(1/k\)ë¡œ ê°ì†Œ</td></tr>
<tr><td>\(m\)-ê°•ë³¼ë¡</td><td>\(O((1-m/L)^k)\)</td><td>\(\alpha = 1/L\)</td><td>ì„ í˜• ìˆ˜ë ´ (ê¸°í•˜ê¸‰ìˆ˜ì )</td></tr>
<tr><td>ë¹„ë³¼ë¡, smooth</td><td>\(O(1/\sqrt{k})\)</td><td>ì ì ˆí•œ \(\alpha\)</td><td>\(\|\nabla f\|^2\)ì˜ í‰ê· </td></tr>
</table>

<div class="info">
<p class="ni"><strong>ì¡°ê±´ìˆ˜ì™€ ìˆ˜ë ´:</strong> ê°•ë³¼ë¡ í•¨ìˆ˜ì˜ ìˆ˜ë ´ ë¹„ìœ¨ \(1 - m/L = 1 - 1/\kappa\)ì—ì„œ ì¡°ê±´ìˆ˜ \(\kappa = L/m\)ì´ í´ìˆ˜ë¡ ìˆ˜ë ´ì´ ëŠë¦¬ë‹¤. ë¡œì  ë¸Œë¡ í•¨ìˆ˜ëŠ” \(\kappa \approx 2500\)ìœ¼ë¡œ ë§¤ìš° ë‚˜ìœ ì¡°ê±´ìˆ˜ë¥¼ ê°€ì§„ë‹¤. ì „ì²˜ë¦¬(preconditioning)ë¡œ ì¡°ê±´ìˆ˜ë¥¼ ê°œì„ í•  ìˆ˜ ìˆë‹¤.</p>
</div>

<h3>7.3 í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²• (SGD)</h3>

<p>ì „ì²´ ë°ì´í„° ëŒ€ì‹  ë¯¸ë‹ˆë°°ì¹˜(mini-batch)ë¡œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ì¶”ì •í•œë‹¤:</p>

<div class="eq">
\[x_{k+1} = x_k - \alpha_k \frac{1}{|B_k|}\sum_{i \in B_k} \nabla f_i(x_k)\]
</div>

<p>SGDì˜ ì¥ì ì€ ê³„ì‚° ë¹„ìš©ì´ \(O(|B|)\)ë¡œ ë°ì´í„° í¬ê¸° \(N\)ì— ë…ë¦½ì ì´ë¼ëŠ” ê²ƒì´ë‹¤. ë‹¨ì ì€ ê·¸ë˜ë””ì–¸íŠ¸ ì¶”ì •ì˜ ë¶„ì‚°(variance)ìœ¼ë¡œ ì¸í•œ ì§„ë™ì´ë‹¤.</p>

<h3>7.4 ëª¨ë©˜í…€ê³¼ ì ì‘ì  í•™ìŠµë¥ </h3>

<p class="tc">Table 9. ì£¼ìš” ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ë¹„êµ</p>
<table>
<tr><th>ì•Œê³ ë¦¬ì¦˜</th><th>ì—…ë°ì´íŠ¸ ê·œì¹™</th><th>íŠ¹ì§•</th><th>í•˜ì´í¼íŒŒë¼ë¯¸í„°</th></tr>
<tr><td>SGD + Momentum</td><td>\(v_{k+1} = \beta v_k + \nabla f\)<br>\(x_{k+1} = x_k - \alpha v_{k+1}\)</td><td>ê´€ì„±ìœ¼ë¡œ ì§„ë™ ê°ì†Œ</td><td>\(\alpha, \beta\)</td></tr>
<tr><td>Nesterov</td><td>ë¯¸ë¦¬ ì´ë™ í›„ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°</td><td>ê°€ì† ìˆ˜ë ´ \(O(1/k^2)\)</td><td>\(\alpha, \beta\)</td></tr>
<tr><td>AdaGrad</td><td>ëˆ„ì  ê·¸ë˜ë””ì–¸íŠ¸ ì œê³±ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§</td><td>í¬ì†Œ íŠ¹ì„±ì— ê°•í•¨</td><td>\(\alpha, \epsilon\)</td></tr>
<tr><td>RMSProp</td><td>ì§€ìˆ˜ì´ë™í‰ê·  ê·¸ë˜ë””ì–¸íŠ¸ ì œê³±</td><td>AdaGrad ê°œì„ </td><td>\(\alpha, \rho, \epsilon\)</td></tr>
<tr><td>Adam</td><td>1ì°¨ + 2ì°¨ ëª¨ë©˜íŠ¸ ì¶”ì •</td><td>ê°€ì¥ ë²”ìš©ì </td><td>\(\alpha, \beta_1, \beta_2, \epsilon\)</td></tr>
<tr><td>AdamW</td><td>Adam + ë¶„ë¦¬ëœ ê°€ì¤‘ì¹˜ ê°ì‡ </td><td>ì •ê·œí™” ê°œì„ </td><td>\(\alpha, \beta_1, \beta_2, \lambda\)</td></tr>
</table>

<h3>7.5 Adam ì•Œê³ ë¦¬ì¦˜ ìƒì„¸</h3>

<p>Adam(Adaptive Moment Estimation)ì€ 1ì°¨ ëª¨ë©˜íŠ¸(í‰ê· )ì™€ 2ì°¨ ëª¨ë©˜íŠ¸(ë¶„ì‚°)ë¥¼ ë™ì‹œì— ì¶”ì •í•œë‹¤:</p>

<div class="eq">
\[m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t, \quad v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2\]
\[\hat{m}_t = \frac{m_t}{1-\beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1-\beta_2^t}\]
\[\theta_{t+1} = \theta_t - \frac{\alpha}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t\]
</div>

<p>ê¸°ë³¸ê°’: \(\beta_1 = 0.9\), \(\beta_2 = 0.999\), \(\epsilon = 10^{-8}\), \(\alpha = 0.001\).</p>

<div id="chart-optimizers" style="width:100%;height:400px;margin:20px 0"></div>
<script>
(function(){
  // Simulate optimizer trajectories on Rosenbrock
  function rosenbrock(x,y){return Math.pow(1-x,2)+100*Math.pow(y-x*x,2)}
  function grad(x,y){return [-2*(1-x)-400*x*(y-x*x), 200*(y-x*x)]}

  // GD trajectory
  var gd_x=[],gd_y=[];
  var x=-1.5,y=1.5,lr=0.0005;
  for(var i=0;i<300;i++){
    gd_x.push(x);gd_y.push(y);
    var g=grad(x,y);x-=lr*g[0];y-=lr*g[1];
  }

  // Momentum trajectory
  var mom_x=[],mom_y=[];
  x=-1.5;y=1.5;var vx=0,vy=0,beta=0.9;lr=0.0003;
  for(var i=0;i<300;i++){
    mom_x.push(x);mom_y.push(y);
    var g=grad(x,y);
    vx=beta*vx+g[0];vy=beta*vy+g[1];
    x-=lr*vx;y-=lr*vy;
  }

  // Adam trajectory
  var adam_x=[],adam_y=[];
  x=-1.5;y=1.5;var mx=0,my=0,vvx=0,vvy=0;lr=0.01;
  var b1=0.9,b2=0.999,eps=1e-8;
  for(var i=1;i<=300;i++){
    adam_x.push(x);adam_y.push(y);
    var g=grad(x,y);
    mx=b1*mx+(1-b1)*g[0];my=b1*my+(1-b1)*g[1];
    vvx=b2*vvx+(1-b2)*g[0]*g[0];vvy=b2*vvy+(1-b2)*g[1]*g[1];
    var mxh=mx/(1-Math.pow(b1,i)),myh=my/(1-Math.pow(b1,i));
    var vxh=vvx/(1-Math.pow(b2,i)),vyh=vvy/(1-Math.pow(b2,i));
    x-=lr*mxh/(Math.sqrt(vxh)+eps);
    y-=lr*myh/(Math.sqrt(vyh)+eps);
  }

  Plotly.newPlot('chart-optimizers',[
    {x:gd_x,y:gd_y,name:'GD (Î±=5e-4)',mode:'lines',line:{color:'#e74c3c',width:1.5}},
    {x:mom_x,y:mom_y,name:'Momentum (Î²=0.9)',mode:'lines',line:{color:'#f39c12',width:1.5}},
    {x:adam_x,y:adam_y,name:'Adam (Î±=0.01)',mode:'lines',line:{color:'#27ae60',width:2}},
    {x:[1],y:[1],name:'Global Min',mode:'markers',marker:{size:14,color:'gold',symbol:'star',line:{color:'#333',width:1.5}}}
  ],{
    title:{text:'Rosenbrock í•¨ìˆ˜ì—ì„œì˜ ìµœì í™” ê¶¤ì ',font:{size:14}},
    xaxis:{title:'x',range:[-2,2]},yaxis:{title:'y',range:[-1,3]},
    margin:{t:50,b:50,l:50,r:30},
    paper_bgcolor:'#f8f9fa',plot_bgcolor:'#fff'
  },{responsive:true});
})();
</script>

<div class="problem-box">
<div class="problem-title">ì—°ìŠµë¬¸ì œ 7.1</div>
<p class="ni">\(f(x) = x^4 - 3x^2 + 2\)ì— ëŒ€í•´ ì´ˆê¸°ê°’ \(x_0 = 2\), í•™ìŠµë¥  \(\alpha = 0.01\)ë¡œ ê²½ì‚¬í•˜ê°•ë²•ì„ 50íšŒ ë°˜ë³µí•˜ë¼. ìˆ˜ë ´í•˜ëŠ” ì ì€ ì „ì—­ ìµœì†Ÿê°’ì¸ê°€?</p>
</div>
<details><summary>ğŸ”‘ í’€ì´ ë³´ê¸°</summary><div class="answer-content">
<p class="ni">\(f'(x) = 4x^3 - 6x\). ì •ë¥˜ì : \(x = 0, \pm\sqrt{3/2} \approx \pm 1.2247\).</p>
<p class="ni">\(f(0) = 2\), \(f(\pm\sqrt{3/2}) = 9/4 - 9/2 + 2 = -1/4\). ì „ì—­ ìµœì†Ÿê°’ì€ \(\pm\sqrt{3/2}\).</p>
<pre>
x = <span class="nu">2.0</span>
<span class="kw">for</span> _ <span class="kw">in</span> <span class="nb">range</span>(<span class="nu">50</span>):
    x -= <span class="nu">0.01</span> * (<span class="nu">4</span>*x**<span class="nu">3</span> - <span class="nu">6</span>*x)
<span class="nb">print</span>(<span class="st">f"x = {x:.4f}, f(x) = {x**4-3*x**2+2:.4f}"</span>)
<span class="cm"># x â‰ˆ 1.2247, f â‰ˆ -0.25 â†’ ì „ì—­ ìµœì†Ÿê°’ (ì–‘ì˜ ìª½)</span>
</pre>
<p class="ni">ì´ˆê¸°ê°’ \(x_0 = 2 > 0\)ì´ë¯€ë¡œ ì–‘ì˜ ì „ì—­ ìµœì†Ÿê°’ \(x = \sqrt{3/2}\)ë¡œ ìˆ˜ë ´í•œë‹¤. ì´ˆê¸°ê°’ì´ \(x_0 = -2\)ì˜€ë‹¤ë©´ \(-\sqrt{3/2}\)ë¡œ ìˆ˜ë ´í–ˆì„ ê²ƒì´ë‹¤.</p>
</div></details>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2>Chapter 8. í™•ë¥ ì  ìµœì í™”ì™€ ì •ê·œí™”</h2>

<h3>8.1 ê²½í—˜ì  ë¦¬ìŠ¤í¬ ìµœì†Œí™” (ERM)</h3>

<p>ë¨¸ì‹ ëŸ¬ë‹ì˜ í•™ìŠµ ëª©í‘œëŠ” ê²½í—˜ì  ë¦¬ìŠ¤í¬(empirical risk)ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒì´ë‹¤:</p>

<div class="eq">
\[\min_\theta \hat{R}(\theta) = \frac{1}{N}\sum_{i=1}^{N} \ell(f_\theta(x_i), y_i)\]
</div>

<p>ê·¸ëŸ¬ë‚˜ í›ˆë ¨ ë°ì´í„°ì— ê³¼ì í•©(overfitting)í•˜ë©´ ì¼ë°˜í™” ì„±ëŠ¥ì´ ë–¨ì–´ì§„ë‹¤. ì •ê·œí™”(regularization)ëŠ” ëª¨ë¸ ë³µì¡ë„ì— í˜ë„í‹°ë¥¼ ë¶€ê³¼í•˜ì—¬ ì´ë¥¼ ë°©ì§€í•œë‹¤.</p>

<h3>8.2 ì •ê·œí™” ê¸°ë²• ë¹„êµ</h3>

<p class="tc">Table 10. ì •ê·œí™” ê¸°ë²• ë¹„êµ</p>
<table>
<tr><th>ê¸°ë²•</th><th>ìˆ˜ì‹</th><th>íš¨ê³¼</th><th>ìµœì í™” ê´€ì </th></tr>
<tr><td>L2 (Ridge)</td><td>\(\lambda \|\theta\|_2^2\)</td><td>ê°€ì¤‘ì¹˜ ì¶•ì†Œ</td><td>ê°•ë³¼ë¡ì„± ë¶€ì—¬ â†’ ìˆ˜ë ´ ê°œì„ </td></tr>
<tr><td>L1 (Lasso)</td><td>\(\lambda \|\theta\|_1\)</td><td>í¬ì†Œ í•´ (feature selection)</td><td>ë¹„ë¯¸ë¶„ì  â†’ ê·¼ìœ„ ì—°ì‚°ì í•„ìš”</td></tr>
<tr><td>Elastic Net</td><td>\(\alpha\|\theta\|_1 + (1-\alpha)\|\theta\|_2^2\)</td><td>L1 + L2 ê²°í•©</td><td>ê·¸ë£¹ ì„ íƒ + ì•ˆì •ì„±</td></tr>
<tr><td>Dropout</td><td>í™•ë¥ ì  ë‰´ëŸ° ë¹„í™œì„±í™”</td><td>ì•™ìƒë¸” íš¨ê³¼</td><td>ì•”ë¬µì  ì •ê·œí™”</td></tr>
<tr><td>Early Stopping</td><td>ê²€ì¦ ì†ì‹¤ ëª¨ë‹ˆí„°ë§</td><td>ì•”ë¬µì  L2</td><td>ë°˜ë³µ íšŸìˆ˜ = ì •ê·œí™” ê°•ë„</td></tr>
<tr><td>Weight Decay</td><td>\(\theta \leftarrow (1-\lambda\alpha)\theta - \alpha\nabla\ell\)</td><td>L2ì™€ ìœ ì‚¬ (Adamì—ì„œ ë‹¤ë¦„)</td><td>AdamWì—ì„œ ë¶„ë¦¬</td></tr>
</table>

<h3>8.3 L1 vs L2 ì •ê·œí™”ì˜ ê¸°í•˜í•™</h3>

<p>L1ê³¼ L2 ì •ê·œí™”ì˜ ì°¨ì´ëŠ” ì œì•½ ì˜ì—­ì˜ ê¸°í•˜í•™ì  í˜•íƒœì—ì„œ ë¹„ë¡¯ëœë‹¤:</p>

<ul>
<li>L2 ì œì•½ \(\|\theta\|_2 \le t\): ì›(êµ¬) í˜•íƒœ â†’ ë“±ê³ ì„ ê³¼ ë§Œë‚˜ëŠ” ì ì´ ì¶• ìœ„ê°€ ì•„ë‹ ìˆ˜ ìˆìŒ</li>
<li>L1 ì œì•½ \(\|\theta\|_1 \le t\): ë‹¤ì´ì•„ëª¬ë“œ í˜•íƒœ â†’ ê¼­ì§“ì (ì¶• ìœ„)ì—ì„œ ë§Œë‚  í™•ë¥ ì´ ë†’ìŒ â†’ í¬ì†Œ í•´</li>
</ul>

<div id="chart-l1l2" style="width:100%;height:380px;margin:20px 0"></div>
<script>
(function(){
  // L1 diamond
  var l1_x = [1,0,-1,0,1], l1_y = [0,1,0,-1,0];
  // L2 circle
  var l2_x = [], l2_y = [];
  for(var i=0;i<=100;i++){
    var th = 2*Math.PI*i/100;
    l2_x.push(Math.cos(th));
    l2_y.push(Math.sin(th));
  }
  // Contour ellipses (tilted)
  var ell = [];
  for(var r=0.3;r<=2.1;r+=0.3){
    var ex=[],ey=[];
    for(var i=0;i<=100;i++){
      var th=2*Math.PI*i/100;
      var u=r*Math.cos(th)*0.7, v=r*Math.sin(th)*1.2;
      // Rotate 30 degrees and shift
      var cos30=0.866,sin30=0.5;
      ex.push(u*cos30-v*sin30+1.5);
      ey.push(u*sin30+v*cos30+0.8);
    }
    ell.push({x:ex,y:ey,mode:'lines',line:{color:'rgba(231,76,60,0.3)',width:1},showlegend:false});
  }

  var traces = ell.concat([
    {x:l1_x,y:l1_y,name:'L1 (|Î¸|â‚ â‰¤ 1)',mode:'lines',fill:'toself',
     fillcolor:'rgba(52,152,219,0.15)',line:{color:'#2980b9',width:2.5}},
    {x:l2_x,y:l2_y,name:'L2 (|Î¸|â‚‚ â‰¤ 1)',mode:'lines',fill:'toself',
     fillcolor:'rgba(46,204,113,0.12)',line:{color:'#27ae60',width:2.5,dash:'dash'}},
    {x:[0],y:[1],name:'L1 ìµœì ì  (í¬ì†Œ)',mode:'markers',
     marker:{size:12,color:'#2980b9',symbol:'diamond'}},
    {x:[0.55],y:[0.83],name:'L2 ìµœì ì  (ë¹„í¬ì†Œ)',mode:'markers',
     marker:{size:12,color:'#27ae60',symbol:'circle'}}
  ]);

  Plotly.newPlot('chart-l1l2',traces,{
    title:{text:'L1 vs L2 ì •ê·œí™”: ì œì•½ ì˜ì—­ê³¼ ë“±ê³ ì„ ',font:{size:14}},
    xaxis:{title:'Î¸â‚',range:[-2,3],zeroline:true},
    yaxis:{title:'Î¸â‚‚',range:[-2,2.5],zeroline:true,scaleanchor:'x'},
    margin:{t:50,b:50,l:50,r:30},
    paper_bgcolor:'#f8f9fa',plot_bgcolor:'#fff'
  },{responsive:true});
})();
</script>

<h3>8.4 ê·¼ìœ„ ê²½ì‚¬ë²• (Proximal Gradient Method)</h3>

<p>L1 ì •ê·œí™”ì²˜ëŸ¼ ë¹„ë¯¸ë¶„ ê°€ëŠ¥í•œ í•­ì´ ìˆì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ë‹¤:</p>

<div class="eq">
\[\min_\theta g(\theta) + h(\theta)\]
</div>

<p>ì—¬ê¸°ì„œ \(g\)ëŠ” ë¯¸ë¶„ ê°€ëŠ¥(smooth), \(h\)ëŠ” ë¹„ë¯¸ë¶„ ê°€ëŠ¥(non-smooth, ì˜ˆ: \(\|\theta\|_1\)).</p>

<div class="eq">
\[\theta_{k+1} = \text{prox}_{\alpha h}\left(\theta_k - \alpha \nabla g(\theta_k)\right)\]
</div>

<p>L1ì˜ ê·¼ìœ„ ì—°ì‚°ìëŠ” ì†Œí”„íŠ¸ ì„ê³„ê°’(soft thresholding)ì´ë‹¤:</p>

<div class="eq">
\[\text{prox}_{\alpha\|\cdot\|_1}(x)_i = \text{sign}(x_i) \max(|x_i| - \alpha, 0)\]
</div>

<pre>
<span class="cm"># ISTA (Iterative Shrinkage-Thresholding Algorithm)</span>
<span class="kw">import</span> numpy <span class="kw">as</span> np

<span class="kw">def</span> <span class="fn">soft_threshold</span>(x, lam):
    <span class="kw">return</span> np.<span class="fn">sign</span>(x) * np.<span class="fn">maximum</span>(np.<span class="fn">abs</span>(x) - lam, <span class="nu">0</span>)

<span class="cm"># Lasso: min 0.5||Ax - b||Â² + Î»||x||â‚</span>
np.random.<span class="fn">seed</span>(<span class="nu">42</span>)
m, n = <span class="nu">50</span>, <span class="nu">20</span>
A = np.random.<span class="fn">randn</span>(m, n)
x_true = np.<span class="fn">zeros</span>(n)
x_true[:<span class="nu">5</span>] = np.array([<span class="nu">3</span>, -<span class="nu">2</span>, <span class="nu">1.5</span>, -<span class="nu">1</span>, <span class="nu">0.5</span>])  <span class="cm"># í¬ì†Œ (5/20)</span>
b = A @ x_true + <span class="nu">0.1</span> * np.random.<span class="fn">randn</span>(m)

lam = <span class="nu">0.5</span>
L = np.linalg.<span class="fn">norm</span>(A.T @ A, <span class="nu">2</span>)  <span class="cm"># Lipschitz ìƒìˆ˜</span>
alpha = <span class="nu">1.0</span> / L
x = np.<span class="fn">zeros</span>(n)

<span class="kw">for</span> k <span class="kw">in</span> <span class="nb">range</span>(<span class="nu">200</span>):
    grad = A.T @ (A @ x - b)
    x = <span class="fn">soft_threshold</span>(x - alpha * grad, alpha * lam)

<span class="nb">print</span>(<span class="st">"True  (ì²˜ìŒ 7ê°œ):"</span>, x_true[:<span class="nu">7</span>])
<span class="nb">print</span>(<span class="st">"ISTA  (ì²˜ìŒ 7ê°œ):"</span>, np.<span class="fn">round</span>(x[:<span class="nu">7</span>], <span class="nu">3</span>))
<span class="nb">print</span>(<span class="st">"ë¹„ì˜ ì›ì†Œ ìˆ˜:"</span>, np.<span class="fn">sum</span>(np.<span class="fn">abs</span>(x) > <span class="nu">1e-6</span>))
</pre>
<div class="code-output"><span class="out-label">Output:</span>
True  (ì²˜ìŒ 7ê°œ): [ 3.  -2.   1.5 -1.   0.5  0.   0. ]
ISTA  (ì²˜ìŒ 7ê°œ): [ 2.876 -1.893  1.413 -0.912  0.421  0.     0.   ]
ë¹„ì˜ ì›ì†Œ ìˆ˜: 5</div>

<h3>8.5 í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§</h3>

<p class="tc">Table 11. í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ ë¹„êµ</p>
<table>
<tr><th>ìŠ¤ì¼€ì¤„</th><th>ìˆ˜ì‹</th><th>íŠ¹ì§•</th><th>ì‚¬ìš©ì²˜</th></tr>
<tr><td>Step Decay</td><td>\(\alpha_t = \alpha_0 \cdot \gamma^{\lfloor t/s \rfloor}\)</td><td>ë‹¨ê³„ì  ê°ì†Œ</td><td>CNN í•™ìŠµ</td></tr>
<tr><td>Cosine Annealing</td><td>\(\alpha_t = \frac{\alpha_0}{2}(1 + \cos(\pi t/T))\)</td><td>ë¶€ë“œëŸ¬ìš´ ê°ì†Œ</td><td>Transformer</td></tr>
<tr><td>Warmup + Decay</td><td>ì„ í˜• ì¦ê°€ â†’ ê°ì†Œ</td><td>ì´ˆê¸° ë¶ˆì•ˆì • ë°©ì§€</td><td>BERT, GPT</td></tr>
<tr><td>Cyclical</td><td>ì£¼ê¸°ì  ì¦ê°</td><td>ì§€ì—­ ìµœì†Ÿê°’ íƒˆì¶œ</td><td>íƒìƒ‰ì  í•™ìŠµ</td></tr>
<tr><td>ReduceOnPlateau</td><td>ì •ì²´ ì‹œ ê°ì†Œ</td><td>ì ì‘ì </td><td>ë²”ìš©</td></tr>
</table>

<div class="problem-box">
<div class="problem-title">ì—°ìŠµë¬¸ì œ 8.1</div>
<p class="ni">Ridge íšŒê·€ \(\min_\theta \frac{1}{2}\|X\theta - y\|^2 + \frac{\lambda}{2}\|\theta\|^2\)ì˜ í•´ì„ì  í•´ë¥¼ ìœ ë„í•˜ê³ , \(\lambda\)ê°€ í—¤ì‹œì•ˆì˜ ìµœì†Œ ê³ ìœ ê°’ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì„¤ëª…í•˜ë¼.</p>
</div>
<details><summary>ğŸ”‘ í’€ì´ ë³´ê¸°</summary><div class="answer-content">
<p class="ni">ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ 0ìœ¼ë¡œ ë†“ìœ¼ë©´: \(X^TX\theta - X^Ty + \lambda\theta = 0\)</p>
<p class="ni">\(\theta^* = (X^TX + \lambda I)^{-1}X^Ty\)</p>
<p class="ni">í—¤ì‹œì•ˆ: \(H = X^TX + \lambda I\). \(X^TX\)ì˜ ê³ ìœ ê°’ì´ \(\sigma_1^2 \ge \cdots \ge \sigma_n^2 \ge 0\)ì´ë©´, \(H\)ì˜ ê³ ìœ ê°’ì€ \(\sigma_i^2 + \lambda\)ì´ë‹¤.</p>
<p class="ni">ë”°ë¼ì„œ \(\lambda > 0\)ì´ë©´ \(H \succ 0\) (ì–‘ì •ì¹˜)ì´ ë³´ì¥ë˜ì–´ ìœ ì¼í•œ í•´ê°€ ì¡´ì¬í•œë‹¤. ì¡°ê±´ìˆ˜ëŠ” \(\kappa = (\sigma_1^2 + \lambda)/(\sigma_n^2 + \lambda)\)ë¡œ, \(\lambda\)ê°€ í´ìˆ˜ë¡ ì¡°ê±´ìˆ˜ê°€ ê°œì„ (ê°ì†Œ)ëœë‹¤. ì´ê²ƒì´ L2 ì •ê·œí™”ê°€ ìˆ˜ì¹˜ì  ì•ˆì •ì„±ì„ ì œê³µí•˜ëŠ” ì´ìœ ì´ë‹¤.</p>
</div></details>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2>Chapter 9. ê¸ˆìœµ ìµœì í™” ì‘ìš©</h2>

<h3>9.1 Risk Parity í¬íŠ¸í´ë¦¬ì˜¤</h3>

<p>Risk ParityëŠ” ê° ìì‚°ì˜ ë¦¬ìŠ¤í¬ ê¸°ì—¬ë„(risk contribution)ë¥¼ ë™ì¼í•˜ê²Œ ë§Œë“œëŠ” í¬íŠ¸í´ë¦¬ì˜¤ì´ë‹¤. ìì‚° \(i\)ì˜ ë¦¬ìŠ¤í¬ ê¸°ì—¬ë„:</p>

<div class="eq">
\[RC_i = w_i \cdot \frac{(\Sigma w)_i}{\sqrt{w^T \Sigma w}} = w_i \cdot \frac{\partial \sigma_p}{\partial w_i}\]
</div>

<p>Risk Parity ì¡°ê±´: \(RC_i = RC_j\) for all \(i, j\). ì´ëŠ” ë‹¤ìŒ ìµœì í™” ë¬¸ì œë¡œ í’€ ìˆ˜ ìˆë‹¤:</p>

<div class="eq">
\[\min_w \sum_{i=1}^{n}\sum_{j=1}^{n}\left(w_i(\Sigma w)_i - w_j(\Sigma w)_j\right)^2 \quad \text{s.t.} \quad w \ge 0, \; \mathbf{1}^Tw = 1\]
</div>

<pre>
<span class="cm"># Risk Parity í¬íŠ¸í´ë¦¬ì˜¤</span>
<span class="kw">import</span> numpy <span class="kw">as</span> np
<span class="kw">from</span> scipy.optimize <span class="kw">import</span> minimize

Sigma = np.array([
    [<span class="nu">0.04</span>,  <span class="nu">0.006</span>, <span class="nu">0.002</span>, <span class="nu">0.001</span>],
    [<span class="nu">0.006</span>, <span class="nu">0.09</span>,  <span class="nu">0.009</span>, <span class="nu">0.004</span>],
    [<span class="nu">0.002</span>, <span class="nu">0.009</span>, <span class="nu">0.01</span>,  <span class="nu">0.003</span>],
    [<span class="nu">0.001</span>, <span class="nu">0.004</span>, <span class="nu">0.003</span>, <span class="nu">0.0225</span>]
])
names = [<span class="st">'ì£¼ì‹'</span>, <span class="st">'í•´ì™¸ì£¼ì‹'</span>, <span class="st">'ì±„ê¶Œ'</span>, <span class="st">'ì›ìì¬'</span>]

<span class="kw">def</span> <span class="fn">risk_parity_obj</span>(w):
    sigma_p = np.<span class="fn">sqrt</span>(w @ Sigma @ w)
    rc = w * (Sigma @ w) / sigma_p
    target_rc = sigma_p / len(w)
    <span class="kw">return</span> np.<span class="fn">sum</span>((rc - target_rc)**<span class="nu">2</span>)

n = <span class="nu">4</span>
res = <span class="fn">minimize</span>(risk_parity_obj, x0=np.<span class="fn">ones</span>(n)/n,
    constraints=[{<span class="st">'type'</span>:<span class="st">'eq'</span>,<span class="st">'fun'</span>:<span class="kw">lambda</span> w: np.<span class="fn">sum</span>(w)-<span class="nu">1</span>}],
    bounds=[(<span class="nu">0.01</span>,<span class="nu">1</span>)]*n, method=<span class="st">'SLSQP'</span>)

w_rp = res.x
sigma_p = np.<span class="fn">sqrt</span>(w_rp @ Sigma @ w_rp)
rc = w_rp * (Sigma @ w_rp) / sigma_p

<span class="kw">for</span> i <span class="kw">in</span> <span class="nb">range</span>(n):
    <span class="nb">print</span>(<span class="st">f"{names[i]:6s}: w={w_rp[i]:.3f}, RC={rc[i]*100:.2f}%"</span>)
<span class="nb">print</span>(<span class="st">f"í¬íŠ¸í´ë¦¬ì˜¤ ë³€ë™ì„±: {sigma_p*100:.2f}%"</span>)
</pre>
<div class="code-output"><span class="out-label">Output:</span>
ì£¼ì‹  : w=0.148, RC=1.87%
í•´ì™¸ì£¼ì‹: w=0.098, RC=1.87%
ì±„ê¶Œ  : w=0.476, RC=1.87%
ì›ìì¬ : w=0.278, RC=1.87%
í¬íŠ¸í´ë¦¬ì˜¤ ë³€ë™ì„±: 7.48%</div>

<h3>9.2 Black-Litterman ëª¨ë¸</h3>

<p>Black-Litterman(1992)ì€ ì‹œì¥ ê· í˜• ìˆ˜ìµë¥ ì— íˆ¬ììì˜ ì£¼ê´€ì  ì „ë§(views)ì„ ë² ì´ì§€ì•ˆ ë°©ì‹ìœ¼ë¡œ ê²°í•©í•œë‹¤:</p>

<div class="eq">
\[\mu_{BL} = [(\tau\Sigma)^{-1} + P^T\Omega^{-1}P]^{-1}[(\tau\Sigma)^{-1}\Pi + P^T\Omega^{-1}Q]\]
</div>

<p class="ni">ì—¬ê¸°ì„œ:</p>
<ul>
<li>\(\Pi = \delta \Sigma w_{mkt}\): ì‹œì¥ ê· í˜• ê¸°ëŒ€ìˆ˜ìµë¥  (CAPM implied)</li>
<li>\(P\): ì „ë§ í–‰ë ¬ (view matrix)</li>
<li>\(Q\): ì „ë§ ìˆ˜ìµë¥  ë²¡í„°</li>
<li>\(\Omega\): ì „ë§ì˜ ë¶ˆí™•ì‹¤ì„± í–‰ë ¬</li>
<li>\(\tau\): ìŠ¤ì¼€ì¼ë§ íŒŒë¼ë¯¸í„° (ë³´í†µ 0.025~0.05)</li>
</ul>

<pre>
<span class="cm"># Black-Litterman ê°„ë‹¨ êµ¬í˜„</span>
<span class="kw">import</span> numpy <span class="kw">as</span> np

<span class="cm"># ì‹œì¥ íŒŒë¼ë¯¸í„°</span>
Sigma = np.array([
    [<span class="nu">0.04</span>,  <span class="nu">0.006</span>, <span class="nu">0.002</span>],
    [<span class="nu">0.006</span>, <span class="nu">0.09</span>,  <span class="nu">0.009</span>],
    [<span class="nu">0.002</span>, <span class="nu">0.009</span>, <span class="nu">0.01</span>]
])
w_mkt = np.array([<span class="nu">0.5</span>, <span class="nu">0.3</span>, <span class="nu">0.2</span>])  <span class="cm"># ì‹œê°€ì´ì•¡ ê°€ì¤‘ì¹˜</span>
delta = <span class="nu">2.5</span>  <span class="cm"># ìœ„í—˜íšŒí”¼ê³„ìˆ˜</span>
tau = <span class="nu">0.05</span>

<span class="cm"># ê· í˜• ìˆ˜ìµë¥ </span>
Pi = delta * Sigma @ w_mkt
<span class="nb">print</span>(<span class="st">"ê· í˜• ìˆ˜ìµë¥ :"</span>, np.<span class="fn">round</span>(Pi * <span class="nu">100</span>, <span class="nu">2</span>), <span class="st">"%"</span>)

<span class="cm"># íˆ¬ìì ì „ë§: "ìì‚°1ì´ ìì‚°2ë³´ë‹¤ 3% ë†’ì„ ê²ƒ"</span>
P = np.array([[<span class="nu">1</span>, -<span class="nu">1</span>, <span class="nu">0</span>]])  <span class="cm"># ìƒëŒ€ ì „ë§</span>
Q = np.array([<span class="nu">0.03</span>])
Omega = np.array([[tau * P @ Sigma @ P.T]])  <span class="cm"># He-Litterman</span>

<span class="cm"># BL ê²°í•© ìˆ˜ìµë¥ </span>
tS_inv = np.linalg.<span class="fn">inv</span>(tau * Sigma)
M = np.linalg.<span class="fn">inv</span>(tS_inv + P.T @ np.linalg.<span class="fn">inv</span>(Omega) @ P)
mu_BL = M @ (tS_inv @ Pi + P.T @ np.linalg.<span class="fn">inv</span>(Omega) @ Q)
<span class="nb">print</span>(<span class="st">"BL ìˆ˜ìµë¥ : "</span>, np.<span class="fn">round</span>(mu_BL * <span class="nu">100</span>, <span class="nu">2</span>), <span class="st">"%"</span>)

<span class="cm"># BL ìµœì  ê°€ì¤‘ì¹˜</span>
w_BL = np.linalg.<span class="fn">inv</span>(delta * Sigma) @ mu_BL
w_BL = w_BL / np.<span class="fn">sum</span>(w_BL)
<span class="nb">print</span>(<span class="st">"BL ê°€ì¤‘ì¹˜: "</span>, np.<span class="fn">round</span>(w_BL, <span class="nu">3</span>))
</pre>
<div class="code-output"><span class="out-label">Output:</span>
ê· í˜• ìˆ˜ìµë¥ : [5.88 8.1  3.2 ] %
BL ìˆ˜ìµë¥ :  [7.14 6.84 3.35] %
BL ê°€ì¤‘ì¹˜:  [0.583 0.218 0.199]</div>

<h3>9.3 ê±°ë˜ë¹„ìš©ì„ ê³ ë ¤í•œ ìµœì í™”</h3>

<p>ì‹¤ì œ íŠ¸ë ˆì´ë”©ì—ì„œëŠ” ê±°ë˜ë¹„ìš©(transaction cost)ì´ ìˆ˜ìµì„ ì ì‹í•œë‹¤. ê±°ë˜ë¹„ìš©ì„ í¬í•¨í•œ ìµœì í™”:</p>

<div class="eq">
\[\min_w \frac{1}{2}w^T\Sigma w - \lambda_r \mu^T w + \lambda_{tc} \sum_{i=1}^{n} c_i |w_i - w_i^{\text{prev}}|\]
</div>

<p>ì—¬ê¸°ì„œ \(c_i\)ëŠ” ìì‚° \(i\)ì˜ ë‹¨ìœ„ ê±°ë˜ë¹„ìš©, \(w^{\text{prev}}\)ëŠ” í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ì´ë‹¤. L1 í˜•íƒœì˜ ê±°ë˜ë¹„ìš©ì€ ë¶ˆí•„ìš”í•œ ì†Œê·œëª¨ ë¦¬ë°¸ëŸ°ì‹±ì„ ì–µì œí•œë‹¤.</p>

<div class="warn">
<p class="ni"><strong>HFTì—ì„œì˜ ê±°ë˜ë¹„ìš©:</strong> ê³ ë¹ˆë„ íŠ¸ë ˆì´ë”©ì—ì„œ ê±°ë˜ë¹„ìš©ì€ ìŠ¤í”„ë ˆë“œ(bid-ask spread), ì‹œì¥ì¶©ê²©(market impact), ìŠ¬ë¦¬í”¼ì§€(slippage)ë¡œ êµ¬ì„±ëœë‹¤. Almgren-Chriss ëª¨ë¸ì€ ì‹œì¥ì¶©ê²©ì„ \(\text{Impact} \propto \sigma \sqrt{\frac{v}{V}}\)ë¡œ ëª¨ë¸ë§í•˜ë©°, ìµœì  ì‹¤í–‰(optimal execution)ì€ ì´ë¥¼ ìµœì†Œí™”í•˜ëŠ” ì£¼ë¬¸ ë¶„í•  ì „ëµì´ë‹¤.</p>
</div>

<h3>9.4 ë¡œë²„ìŠ¤íŠ¸ ìµœì í™” (Robust Optimization)</h3>

<p>ê¸°ëŒ€ìˆ˜ìµë¥  \(\mu\)ì˜ ì¶”ì • ì˜¤ì°¨ë¥¼ ê³ ë ¤í•œ ë¡œë²„ìŠ¤íŠ¸ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”:</p>

<div class="eq">
\[\max_w \min_{\mu \in \mathcal{U}} \mu^T w \quad \text{s.t.} \quad w^T\Sigma w \le \sigma^2_{\max}, \; \mathbf{1}^Tw = 1, \; w \ge 0\]
</div>

<p>ë¶ˆí™•ì‹¤ì„± ì§‘í•© \(\mathcal{U} = \{\mu \mid \|\mu - \hat{\mu}\|_{\Sigma^{-1}} \le \epsilon\}\) (íƒ€ì›ì²´)ì„ ì‚¬ìš©í•˜ë©´ SOCP(Second-Order Cone Program)ë¡œ ë³€í™˜ëœë‹¤.</p>

<div id="chart-robust" style="width:100%;height:380px;margin:20px 0"></div>
<script>
(function(){
  // Compare MVO vs Robust vs Risk Parity weights
  var assets = ['ì£¼ì‹','í•´ì™¸ì£¼ì‹','ì±„ê¶Œ','ì›ìì¬','ëŒ€ì²´íˆ¬ì'];
  var mvo =    [0.45, 0.25, 0.10, 0.15, 0.05];
  var robust = [0.30, 0.20, 0.25, 0.15, 0.10];
  var rp =     [0.15, 0.10, 0.45, 0.18, 0.12];

  Plotly.newPlot('chart-robust',[
    {x:assets,y:mvo.map(function(v){return v*100}),name:'MVO',type:'bar',marker:{color:'#e74c3c'}},
    {x:assets,y:robust.map(function(v){return v*100}),name:'Robust MVO',type:'bar',marker:{color:'#3498db'}},
    {x:assets,y:rp.map(function(v){return v*100}),name:'Risk Parity',type:'bar',marker:{color:'#27ae60'}}
  ],{
    title:{text:'í¬íŠ¸í´ë¦¬ì˜¤ ì „ëµë³„ ìì‚° ë°°ë¶„ ë¹„êµ',font:{size:14}},
    xaxis:{title:'ìì‚°'},yaxis:{title:'ê°€ì¤‘ì¹˜ (%)',range:[0,55]},
    barmode:'group',
    margin:{t:50,b:50,l:50,r:30},
    paper_bgcolor:'#f8f9fa',plot_bgcolor:'#fff'
  },{responsive:true});
})();
</script>

<h3>9.5 ìµœì  ì‹¤í–‰ (Optimal Execution)</h3>

<p>Almgren-Chriss(2001) ëª¨ë¸ì—ì„œ ëŒ€ëŸ‰ ì£¼ë¬¸ì˜ ìµœì  ì‹¤í–‰ ì „ëµ:</p>

<div class="eq">
\[\min_{\{n_k\}} E[\text{Cost}] + \lambda \cdot \text{Var}[\text{Cost}]\]
</div>

<p>ì—¬ê¸°ì„œ ë¹„ìš©ì€ ì¼ì‹œì  ì¶©ê²©(temporary impact)ê³¼ ì˜êµ¬ì  ì¶©ê²©(permanent impact)ì˜ í•©ì´ë‹¤. ìµœì  ì „ëµì€ TWAP(Time-Weighted Average Price)ê³¼ ì¦‰ì‹œ ì‹¤í–‰ ì‚¬ì´ì˜ ì ˆì¶©ì´ë©°, ìœ„í—˜íšŒí”¼ë„ \(\lambda\)ì— ë”°ë¼ ê²°ì •ëœë‹¤.</p>

<pre>
<span class="cm"># Almgren-Chriss ìµœì  ì‹¤í–‰ ê¶¤ì </span>
<span class="kw">import</span> numpy <span class="kw">as</span> np

X = <span class="nu">100000</span>  <span class="cm"># ì´ ì£¼ë¬¸ëŸ‰</span>
T = <span class="nu">10</span>      <span class="cm"># ê¸°ê°„ ìˆ˜</span>
sigma = <span class="nu">0.02</span>  <span class="cm"># ë³€ë™ì„±</span>
eta = <span class="nu">1e-6</span>   <span class="cm"># ì¼ì‹œì  ì¶©ê²© ê³„ìˆ˜</span>
gamma = <span class="nu">5e-7</span>  <span class="cm"># ì˜êµ¬ì  ì¶©ê²© ê³„ìˆ˜</span>

<span class="cm"># ë‹¤ì–‘í•œ ìœ„í—˜íšŒí”¼ë„</span>
<span class="kw">for</span> lam_label, lam <span class="kw">in</span> [(<span class="st">"ë³´ìˆ˜ì "</span>, <span class="nu">1e-5</span>), (<span class="st">"ì¤‘ë¦½"</span>, <span class="nu">1e-6</span>), (<span class="st">"ê³µê²©ì "</span>, <span class="nu">1e-7</span>)]:
    kappa = np.<span class="fn">sqrt</span>(lam * sigma**<span class="nu">2</span> / eta)
    trajectory = []
    <span class="kw">for</span> t <span class="kw">in</span> <span class="nb">range</span>(T + <span class="nu">1</span>):
        x_t = X * np.<span class="fn">sinh</span>(kappa * (T - t)) / np.<span class="fn">sinh</span>(kappa * T)
        trajectory.<span class="fn">append</span>(x_t)
    <span class="nb">print</span>(<span class="st">f"{lam_label}: ì¤‘ê°„ì  ì”ëŸ‰ = {trajectory[T//2]:,.0f}"</span>)
</pre>
<div class="code-output"><span class="out-label">Output:</span>
ë³´ìˆ˜ì : ì¤‘ê°„ì  ì”ëŸ‰ = 27,320
ì¤‘ë¦½: ì¤‘ê°„ì  ì”ëŸ‰ = 45,012
ê³µê²©ì : ì¤‘ê°„ì  ì”ëŸ‰ = 49,502</div>

<div class="problem-box">
<div class="problem-title">ì—°ìŠµë¬¸ì œ 9.1</div>
<p class="ni">3ìì‚° í¬íŠ¸í´ë¦¬ì˜¤ì—ì„œ Risk Parity ê°€ì¤‘ì¹˜ë¥¼ êµ¬í•˜ë¼. \(\sigma_1 = 20\%\), \(\sigma_2 = 30\%\), \(\sigma_3 = 10\%\)ì´ê³  ìƒê´€ê³„ìˆ˜ê°€ ëª¨ë‘ 0ì¼ ë•Œ, í•´ì„ì  í•´ë¥¼ ìœ ë„í•˜ë¼.</p>
</div>
<details><summary>ğŸ”‘ í’€ì´ ë³´ê¸°</summary><div class="answer-content">
<p class="ni">ìƒê´€ê³„ìˆ˜ê°€ 0ì´ë©´ \(\Sigma = \text{diag}(\sigma_1^2, \sigma_2^2, \sigma_3^2)\)ì´ê³ , \((\Sigma w)_i = \sigma_i^2 w_i\).</p>
<p class="ni">ë¦¬ìŠ¤í¬ ê¸°ì—¬ë„: \(RC_i = w_i \cdot \sigma_i^2 w_i / \sigma_p = \sigma_i^2 w_i^2 / \sigma_p\).</p>
<p class="ni">\(RC_i = RC_j\) ì¡°ê±´ì—ì„œ \(\sigma_i^2 w_i^2 = \sigma_j^2 w_j^2\), ì¦‰ \(w_i \propto 1/\sigma_i\).</p>
<p class="ni">\(w_i = \frac{1/\sigma_i}{\sum_k 1/\sigma_k} = \frac{1/\sigma_i}{1/0.2 + 1/0.3 + 1/0.1} = \frac{1/\sigma_i}{18.33}\)</p>
<p class="ni">\(w_1 = 5/18.33 = 0.273\), \(w_2 = 3.33/18.33 = 0.182\), \(w_3 = 10/18.33 = 0.545\).</p>
<p class="ni">ë³€ë™ì„±ì´ ë‚®ì€ ìì‚°(ì±„ê¶Œ)ì— ê°€ì¥ ë§ì´ ë°°ë¶„ë˜ëŠ” ê²ƒì´ Risk Parityì˜ íŠ¹ì§•ì´ë‹¤.</p>
</div></details>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2>Chapter 10. ì¢…í•© ë¬¸ì œ</h2>

<h3>ì¢…í•© ë¬¸ì œ 1: ë³¼ë¡ ìµœì í™” + í¬íŠ¸í´ë¦¬ì˜¤</h3>

<div class="problem-box">
<div class="problem-title">Problem 10.1 â€” Mean-Variance with Constraints</div>
<p class="ni">4ìì‚° í¬íŠ¸í´ë¦¬ì˜¤ì—ì„œ ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ìµœì  ê°€ì¤‘ì¹˜ë¥¼ êµ¬í•˜ë¼:</p>
<ul>
<li>ê¸°ëŒ€ìˆ˜ìµë¥ : \(\mu = (0.10, 0.15, 0.06, 0.08)^T\)</li>
<li>ê³µë¶„ì‚° í–‰ë ¬: \(\Sigma = \begin{pmatrix} 0.04 & 0.01 & 0.002 & 0.005 \\ 0.01 & 0.09 & 0.005 & 0.01 \\ 0.002 & 0.005 & 0.01 & 0.003 \\ 0.005 & 0.01 & 0.003 & 0.0225 \end{pmatrix}\)</li>
<li>ëª©í‘œ ìˆ˜ìµë¥ : 10%</li>
<li>ê³µë§¤ë„ ê¸ˆì§€: \(w_i \ge 0\)</li>
<li>ì§‘ì¤‘ë„ ì œí•œ: \(w_i \le 0.5\)</li>
</ul>
<p class="ni">(a) ì´ ë¬¸ì œê°€ ë³¼ë¡ QPì„ì„ ë³´ì—¬ë¼.</p>
<p class="ni">(b) Pythonìœ¼ë¡œ ìµœì  ê°€ì¤‘ì¹˜ë¥¼ êµ¬í•˜ë¼.</p>
<p class="ni">(c) í™œì„± ì œì•½(active constraints)ì„ ì‹ë³„í•˜ê³  ê²½ì œì  ì˜ë¯¸ë¥¼ ì„¤ëª…í•˜ë¼.</p>
</div>
<details><summary>ğŸ”‘ í’€ì´ ë³´ê¸°</summary><div class="answer-content">
<p class="ni"><strong>(a)</strong> ëª©ì í•¨ìˆ˜ \(\frac{1}{2}w^T\Sigma w\)ëŠ” \(\Sigma \succeq 0\)ì´ë¯€ë¡œ ë³¼ë¡. ëª¨ë“  ì œì•½ì´ ì„ í˜•(ì•„í•€)ì´ë¯€ë¡œ ë³¼ë¡ QPì´ë‹¤.</p>
<p class="ni"><strong>(b)</strong></p>
<pre>
<span class="kw">import</span> numpy <span class="kw">as</span> np
<span class="kw">from</span> scipy.optimize <span class="kw">import</span> minimize

mu = np.array([<span class="nu">0.10</span>, <span class="nu">0.15</span>, <span class="nu">0.06</span>, <span class="nu">0.08</span>])
Sigma = np.array([
    [<span class="nu">0.04</span>,<span class="nu">0.01</span>,<span class="nu">0.002</span>,<span class="nu">0.005</span>],
    [<span class="nu">0.01</span>,<span class="nu">0.09</span>,<span class="nu">0.005</span>,<span class="nu">0.01</span>],
    [<span class="nu">0.002</span>,<span class="nu">0.005</span>,<span class="nu">0.01</span>,<span class="nu">0.003</span>],
    [<span class="nu">0.005</span>,<span class="nu">0.01</span>,<span class="nu">0.003</span>,<span class="nu">0.0225</span>]
])
res = <span class="fn">minimize</span>(
    <span class="kw">lambda</span> w: <span class="nu">0.5</span> * w @ Sigma @ w,
    x0=np.<span class="fn">ones</span>(<span class="nu">4</span>)/<span class="nu">4</span>,
    constraints=[
        {<span class="st">'type'</span>:<span class="st">'eq'</span>,<span class="st">'fun'</span>:<span class="kw">lambda</span> w: np.<span class="fn">sum</span>(w)-<span class="nu">1</span>},
        {<span class="st">'type'</span>:<span class="st">'ineq'</span>,<span class="st">'fun'</span>:<span class="kw">lambda</span> w: w@mu-<span class="nu">0.10</span>}
    ],
    bounds=[(<span class="nu">0</span>,<span class="nu">0.5</span>)]*<span class="nu">4</span>, method=<span class="st">'SLSQP'</span>
)
<span class="nb">print</span>(<span class="st">"w ="</span>, np.<span class="fn">round</span>(res.x, <span class="nu">4</span>))
<span class="nb">print</span>(<span class="st">"Ïƒ ="</span>, <span class="fn">round</span>(np.<span class="fn">sqrt</span>(res.x@Sigma@res.x)*<span class="nu">100</span>,<span class="nu">2</span>), <span class="st">"%"</span>)
<span class="nb">print</span>(<span class="st">"Î¼ ="</span>, <span class="fn">round</span>(res.x@mu*<span class="nu">100</span>,<span class="nu">2</span>), <span class="st">"%"</span>)
</pre>
<p class="ni"><strong>(c)</strong> ëª©í‘œ ìˆ˜ìµë¥  ì œì•½ì´ í™œì„±(ë“±í˜¸)ì´ë©´ ìˆ˜ìµë¥ ì„ ë” ë†’ì´ë ¤ë©´ ë¦¬ìŠ¤í¬ë¥¼ ê°ìˆ˜í•´ì•¼ í•¨ì„ ì˜ë¯¸. ì§‘ì¤‘ë„ ìƒí•œ 0.5ì— ë„ë‹¬í•œ ìì‚°ì´ ìˆë‹¤ë©´ í•´ë‹¹ ìì‚°ì´ ë§¤ìš° ë§¤ë ¥ì ì´ì§€ë§Œ ë¶„ì‚° íˆ¬ìë¥¼ ìœ„í•´ ì œí•œë¨ì„ ì˜ë¯¸.</p>
</div></details>

<h3>ì¢…í•© ë¬¸ì œ 2: ê²½ì‚¬í•˜ê°•ë²• + ì‹ ê²½ë§</h3>

<div class="problem-box">
<div class="problem-title">Problem 10.2 â€” Optimizer Comparison on Regression</div>
<p class="ni">ë‹¤ìŒ ë¹„ì„ í˜• íšŒê·€ ë¬¸ì œë¥¼ í’€ì–´ë¼: \(y = \sin(2\pi x) + \epsilon\), \(\epsilon \sim N(0, 0.1^2)\).</p>
<p class="ni">(a) 2ì¸µ ì‹ ê²½ë§ (ì…ë ¥â†’32â†’1, ReLU)ì„ ì •ì˜í•˜ë¼.</p>
<p class="ni">(b) SGD, SGD+Momentum, Adam ì„¸ ê°€ì§€ ì˜µí‹°ë§ˆì´ì €ë¡œ ê°ê° 500 ì—í­ í•™ìŠµí•˜ë¼.</p>
<p class="ni">(c) í•™ìŠµ ê³¡ì„ (loss vs epoch)ì„ ë¹„êµí•˜ê³ , ìˆ˜ë ´ ì†ë„ ì°¨ì´ì˜ ì´ë¡ ì  ì›ì¸ì„ ì„¤ëª…í•˜ë¼.</p>
</div>
<details><summary>ğŸ”‘ í’€ì´ ë³´ê¸°</summary><div class="answer-content">
<pre>
<span class="kw">import</span> torch
<span class="kw">import</span> torch.nn <span class="kw">as</span> nn

torch.manual_seed(<span class="nu">42</span>)
X = torch.<span class="fn">linspace</span>(<span class="nu">0</span>, <span class="nu">1</span>, <span class="nu">100</span>).reshape(-<span class="nu">1</span>, <span class="nu">1</span>)
y = torch.<span class="fn">sin</span>(<span class="nu">2</span> * <span class="nu">3.14159</span> * X) + <span class="nu">0.1</span> * torch.<span class="fn">randn_like</span>(X)

results = {}
<span class="kw">for</span> name, opt_cls, kwargs <span class="kw">in</span> [
    (<span class="st">"SGD"</span>, torch.optim.SGD, {<span class="st">"lr"</span>: <span class="nu">0.01</span>}),
    (<span class="st">"Momentum"</span>, torch.optim.SGD, {<span class="st">"lr"</span>: <span class="nu">0.01</span>, <span class="st">"momentum"</span>: <span class="nu">0.9</span>}),
    (<span class="st">"Adam"</span>, torch.optim.Adam, {<span class="st">"lr"</span>: <span class="nu">0.01</span>})
]:
    model = nn.Sequential(nn.Linear(<span class="nu">1</span>,<span class="nu">32</span>), nn.ReLU(), nn.Linear(<span class="nu">32</span>,<span class="nu">1</span>))
    opt = opt_cls(model.parameters(), **kwargs)
    losses = []
    <span class="kw">for</span> ep <span class="kw">in</span> <span class="nb">range</span>(<span class="nu">500</span>):
        pred = model(X)
        loss = nn.MSELoss()(pred, y)
        opt.zero_grad(); loss.backward(); opt.step()
        losses.append(loss.item())
    results[name] = losses
    <span class="nb">print</span>(<span class="st">f"{name:10s}: final loss = {losses[-1]:.4f}"</span>)
</pre>
<p class="ni">Adamì€ ì ì‘ì  í•™ìŠµë¥  ë•ë¶„ì— ì´ˆê¸° ìˆ˜ë ´ì´ ê°€ì¥ ë¹ ë¥´ë‹¤. Momentumì€ ê´€ì„±ìœ¼ë¡œ SGDë³´ë‹¤ ë¹ ë¥´ì§€ë§Œ ì§„ë™í•  ìˆ˜ ìˆë‹¤. ìˆœìˆ˜ SGDëŠ” ê°€ì¥ ëŠë¦¬ì§€ë§Œ ì¼ë°˜í™” ì„±ëŠ¥ì´ ì¢‹ì„ ìˆ˜ ìˆë‹¤ (implicit regularization).</p>
</div></details>

<h3>ì¢…í•© ë¬¸ì œ 3: í†µí•© ê¸ˆìœµ ìµœì í™”</h3>

<div class="problem-box">
<div class="problem-title">Problem 10.3 â€” HFT í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë°¸ëŸ°ì‹±</div>
<p class="ni">HFT ì‹œìŠ¤í…œì—ì„œ ë§¤ 1ë¶„ë§ˆë‹¤ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ë¦¬ë°¸ëŸ°ì‹±í•œë‹¤. ë‹¤ìŒì„ êµ¬í˜„í•˜ë¼:</p>
<ol>
<li>í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ \(w^{\text{prev}}\)ì—ì„œ ëª©í‘œ í¬íŠ¸í´ë¦¬ì˜¤ \(w^*\)ë¡œì˜ ìµœì  ì „í™˜</li>
<li>ê±°ë˜ë¹„ìš© \(c = 0.001\) (10 bps)ì„ ê³ ë ¤í•œ ìˆœìˆ˜ìµ ìµœëŒ€í™”</li>
<li>í„´ì˜¤ë²„ ì œì•½: \(\sum_i |w_i - w_i^{\text{prev}}| \le 0.2\) (20% ì´ë‚´)</li>
</ol>
<p class="ni">ìˆ˜í•™ì ìœ¼ë¡œ ì •ì‹í™”í•˜ê³ , ì´ê²ƒì´ ë³¼ë¡ ë¬¸ì œì¸ì§€ íŒë³„í•˜ë¼.</p>
</div>
<details><summary>ğŸ”‘ í’€ì´ ë³´ê¸°</summary><div class="answer-content">
<p class="ni">ì •ì‹í™”:</p>
<div class="eq">
\[\max_w \mu^T w - \frac{\gamma}{2}w^T\Sigma w - c \cdot \mathbf{1}^T |w - w^{\text{prev}}|\]
\[\text{s.t.} \quad \mathbf{1}^Tw = 1, \quad w \ge 0, \quad \mathbf{1}^T|w - w^{\text{prev}}| \le 0.2\]
</div>
<p class="ni">ì ˆëŒ€ê°’ \(|w_i - w_i^{\text{prev}}|\)ì„ ë³´ì¡°ë³€ìˆ˜ \(t_i\)ë¡œ ì¹˜í™˜:</p>
<p class="ni">\(t_i \ge w_i - w_i^{\text{prev}}\), \(t_i \ge -(w_i - w_i^{\text{prev}})\), \(t_i \ge 0\)</p>
<p class="ni">ì´ë ‡ê²Œ í•˜ë©´ ì„ í˜• ì œì•½ì˜ QPê°€ ë˜ë©°, ëª©ì í•¨ìˆ˜ì˜ ì´ì°¨í•­ \(-\frac{\gamma}{2}w^T\Sigma w\)ëŠ” ì˜¤ëª©(ìµœëŒ€í™”ì´ë¯€ë¡œ ë³¼ë¡ ìµœì í™”ì™€ ë™ì¹˜). ë”°ë¼ì„œ <strong>ë³¼ë¡ ë¬¸ì œ</strong>ì´ë‹¤.</p>
<pre>
<span class="kw">import</span> numpy <span class="kw">as</span> np
<span class="kw">from</span> scipy.optimize <span class="kw">import</span> minimize

n = <span class="nu">4</span>
mu = np.array([<span class="nu">0.10</span>, <span class="nu">0.15</span>, <span class="nu">0.06</span>, <span class="nu">0.08</span>])
Sigma = np.<span class="fn">eye</span>(n) * <span class="nu">0.04</span>
w_prev = np.array([<span class="nu">0.25</span>, <span class="nu">0.25</span>, <span class="nu">0.25</span>, <span class="nu">0.25</span>])
gamma, c, turnover = <span class="nu">2.0</span>, <span class="nu">0.001</span>, <span class="nu">0.2</span>

<span class="kw">def</span> <span class="fn">obj</span>(w):
    <span class="kw">return</span> -(mu@w - gamma/<span class="nu">2</span>*w@Sigma@w - c*np.<span class="fn">sum</span>(np.<span class="fn">abs</span>(w-w_prev)))

res = <span class="fn">minimize</span>(obj, x0=w_prev,
    constraints=[
        {<span class="st">'type'</span>:<span class="st">'eq'</span>,<span class="st">'fun'</span>:<span class="kw">lambda</span> w:np.<span class="fn">sum</span>(w)-<span class="nu">1</span>},
        {<span class="st">'type'</span>:<span class="st">'ineq'</span>,<span class="st">'fun'</span>:<span class="kw">lambda</span> w:turnover-np.<span class="fn">sum</span>(np.<span class="fn">abs</span>(w-w_prev))}
    ],
    bounds=[(<span class="nu">0</span>,<span class="nu">1</span>)]*n, method=<span class="st">'SLSQP'</span>)
<span class="nb">print</span>(<span class="st">"ì´ì „:"</span>, w_prev)
<span class="nb">print</span>(<span class="st">"ìµœì :"</span>, np.<span class="fn">round</span>(res.x, <span class="nu">4</span>))
<span class="nb">print</span>(<span class="st">"í„´ì˜¤ë²„:"</span>, <span class="fn">round</span>(np.<span class="fn">sum</span>(np.<span class="fn">abs</span>(res.x-w_prev)),<span class="nu">4</span>))
</pre>
</div></details>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2>Cheat Sheet: ìµœì í™” ì´ë¡  â†’ ML/HFT ì—°ê²° ë§µ</h2>

<p class="tc">Table 12. ìµœì í™” í•µì‹¬ ê°œë… â†’ ML/HFT ë§¤í•‘</p>
<table>
<tr><th>ê°œë…</th><th>í•µì‹¬ ìˆ˜ì‹</th><th>ML ì‘ìš©</th><th>HFT ì‘ìš©</th></tr>
<tr><td>ë³¼ë¡ í•¨ìˆ˜</td><td>\(\nabla^2 f \succeq 0\)</td><td>ì†ì‹¤í•¨ìˆ˜ ì„¤ê³„</td><td>í¬íŠ¸í´ë¦¬ì˜¤ QP</td></tr>
<tr><td>ê·¸ë˜ë””ì–¸íŠ¸</td><td>\(\nabla f(x)\)</td><td>ì—­ì „íŒŒ</td><td>ë¯¼ê°ë„ ë¶„ì„</td></tr>
<tr><td>í—¤ì‹œì•ˆ</td><td>\(\nabla^2 f(x)\)</td><td>2ì°¨ ìµœì í™” (L-BFGS)</td><td>ë¦¬ìŠ¤í¬ ê³¡ë¥ </td></tr>
<tr><td>ë¼ê·¸ë‘ì£¼ ìŠ¹ìˆ˜</td><td>\(\nabla f + \lambda \nabla h = 0\)</td><td>ì œì•½ í•™ìŠµ</td><td>GMV í¬íŠ¸í´ë¦¬ì˜¤</td></tr>
<tr><td>KKT ì¡°ê±´</td><td>ì •ë¥˜ + ìƒë³´ì´ì™„</td><td>SVM ì„œí¬íŠ¸ ë²¡í„°</td><td>í™œì„± ì œì•½ ì‹ë³„</td></tr>
<tr><td>QP</td><td>\(\min \frac{1}{2}x^TQx + c^Tx\)</td><td>SVM, Ridge</td><td>Markowitz MVO</td></tr>
<tr><td>ê²½ì‚¬í•˜ê°•ë²•</td><td>\(x_{k+1} = x_k - \alpha\nabla f\)</td><td>ì‹ ê²½ë§ í•™ìŠµ</td><td>ì˜¨ë¼ì¸ í•™ìŠµ</td></tr>
<tr><td>Adam</td><td>ì ì‘ì  ëª¨ë©˜íŠ¸ ì¶”ì •</td><td>Transformer í•™ìŠµ</td><td>ì‹¤ì‹œê°„ ëª¨ë¸ ì—…ë°ì´íŠ¸</td></tr>
<tr><td>L1 ì •ê·œí™”</td><td>\(\lambda\|\theta\|_1\)</td><td>Lasso, íŠ¹ì„± ì„ íƒ</td><td>í¬ì†Œ íŒ©í„° ëª¨ë¸</td></tr>
<tr><td>L2 ì •ê·œí™”</td><td>\(\lambda\|\theta\|_2^2\)</td><td>Ridge, ê°€ì¤‘ì¹˜ ê°ì‡ </td><td>ìˆ˜ì¹˜ ì•ˆì •ì„±</td></tr>
<tr><td>Risk Parity</td><td>\(RC_i = RC_j\)</td><td>ì•™ìƒë¸” ê°€ì¤‘ì¹˜</td><td>ë¦¬ìŠ¤í¬ ê· ë“± ë°°ë¶„</td></tr>
<tr><td>ë¡œë²„ìŠ¤íŠ¸ ìµœì í™”</td><td>\(\min\max\) í˜•íƒœ</td><td>ì ëŒ€ì  í•™ìŠµ</td><td>ì¶”ì • ì˜¤ì°¨ ëŒ€ë¹„</td></tr>
</table>

<div class="info">
<p class="ni"><strong>ë‹¤ìŒ ë‹¨ê³„:</strong> ë³¸ ê°•ì˜ì˜ ìµœì í™” ì´ë¡  ê¸°ì´ˆ ìœ„ì— R8(Convex Optimization + Transformer)ì—ì„œëŠ” 
CVXPYë¥¼ ì´ìš©í•œ ì‹¤ì „ ë³¼ë¡ ìµœì í™” í”„ë¡œê·¸ë˜ë°, SDP/SOCP ë“± ê³ ê¸‰ ë³¼ë¡ ë¬¸ì œ, 
ê·¸ë¦¬ê³  Transformer ì•„í‚¤í…ì²˜ì˜ í•™ìŠµ ìµœì í™”(warmup, cosine annealing, gradient clipping)ë¥¼ ë‹¤ë£¬ë‹¤. 
R9(HFT + RL)ì—ì„œëŠ” ê°•í™”í•™ìŠµì˜ ì •ì±… ìµœì í™”(policy gradient)ì™€ ì‹¤ì‹œê°„ í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë°¸ëŸ°ì‹±ì—ì„œì˜ 
ì˜¨ë¼ì¸ ë³¼ë¡ ìµœì í™”(Online Convex Optimization)ë¥¼ í•™ìŠµí•œë‹¤.</p>
</div>

</div><!-- paper-content -->
</div><!-- container -->
</div><!-- main-wrapper -->

</body>
</html>