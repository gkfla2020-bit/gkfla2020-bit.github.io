<!DOCTYPE html>
<html lang="ko">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Round 4 - Supervised Learning: Regression + Classification</title>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:wght@300;400;500&family=Space+Mono:wght@400&family=Inter:wght@300;400&display=swap" rel="stylesheet">
<style>
*{margin:0;padding:0;box-sizing:border-box}
body{font-family:'Inter',sans-serif;background:#fafaf8;color:#1a1a1a;line-height:1.7;overflow-x:hidden}
.sidebar{position:fixed;left:0;top:0;width:260px;height:100vh;background:rgba(255,255,255,.97);border-right:1px solid rgba(0,0,0,.06);padding:32px 24px;z-index:100;overflow-y:auto;display:flex;flex-direction:column}
.sidebar-profile{text-align:center;margin-bottom:28px;padding-bottom:24px;border-bottom:1px solid rgba(0,0,0,.08)}
.profile-icon{font-size:48px;margin-bottom:8px}
.profile-name{font-family:'Cormorant Garamond',serif;font-size:1.3rem;font-weight:500;margin-bottom:4px}
.profile-title{font-size:.68rem;color:#888;letter-spacing:.08em;text-transform:uppercase;margin-bottom:8px}
.profile-bio{font-size:.78rem;color:#666;line-height:1.5}
.sidebar-nav{flex:1;margin-top:16px}
.nav-section{margin-bottom:20px}
.nav-section-title{font-size:.6rem;font-weight:600;color:#aaa;letter-spacing:.15em;text-transform:uppercase;margin-bottom:10px}
.nav-list{list-style:none}
.nav-list li{margin-bottom:5px}
.nav-list a{font-size:.78rem;color:#555;text-decoration:none;transition:all .2s;display:block;padding:3px 0}
.nav-list a:hover{color:#0080c6;padding-left:4px}
.nav-list a.active{color:#0080c6;font-weight:500}
.nav-list a.done{color:#28a745}
.badge{display:inline-block;font-size:.5rem;background:#0080c6;color:#fff;padding:1px 5px;border-radius:8px;margin-left:3px;vertical-align:middle}
.badge-done{background:#28a745}
.sidebar-footer{padding-top:16px;border-top:1px solid rgba(0,0,0,.06);font-size:.65rem;color:#aaa;text-align:center}
.main-wrapper{margin-left:260px;min-height:100vh}
.container{max-width:1100px;margin:0 auto;padding:50px 40px 80px}
.paper-content{font-family:'Times New Roman','Nanum Myeongjo',serif;line-height:1.8;background:#fff;padding:40px;border-radius:8px;box-shadow:0 2px 20px rgba(0,0,0,.05)}
.paper-header{text-align:center;margin-bottom:40px;padding-bottom:30px;border-bottom:2px solid #333}
.paper-category{font-size:14px;color:#666;margin-bottom:10px}
.paper-title{font-size:24px;font-weight:bold;margin-bottom:12px;line-height:1.4}
.paper-subtitle{font-size:14px;color:#555;margin-bottom:8px}
.paper-team{font-size:13px;color:#444}
</style>
<style>
.abstract{background:#f8f9fa;padding:25px;margin:30px 0;border-left:4px solid #2c3e50}
.abstract-title{font-weight:bold;font-size:16px;margin-bottom:15px}
h2{font-size:18px;margin:35px 0 20px;padding-bottom:8px;border-bottom:1px solid #ddd;color:#2c3e50}
h3{font-size:15px;margin:25px 0 15px;color:#34495e}
h4{font-size:14px;margin:20px 0 12px;color:#34495e}
p{text-align:justify;margin-bottom:15px;text-indent:2em}
p.ni{text-indent:0}
table{width:100%;border-collapse:collapse;margin:20px 0;font-size:12px}
th,td{border:1px solid #ddd;padding:10px 8px;text-align:center}
th{background:#2c3e50;color:white;font-weight:bold}
tr:nth-child(even){background:#f8f9fa}
tr:hover{background:#e8f4f8}
.tc{font-size:13px;font-weight:bold;margin:15px 0 10px;text-align:center}
.eq{text-align:center;margin:20px 0;padding:15px;background:#f8f9fa;border-radius:4px;overflow-x:auto}
ul,ol{margin-left:2em;margin-bottom:15px}
li{margin-bottom:6px}
.def{background:#fff9e6;border:1px solid #ffc107;border-radius:4px;padding:20px;margin:20px 0}
.info{background:#e8f4f8;border-left:4px solid #3498db;padding:20px;margin:20px 0}
.warn{background:#fff3cd;border-left:4px solid #f39c12;padding:20px;margin:20px 0}
.ok{background:#d4edda;border-left:4px solid #28a745;padding:20px;margin:20px 0}
pre{background:#1e1e1e;color:#d4d4d4;padding:20px;border-radius:6px;overflow-x:auto;margin:20px 0;font-family:'Space Mono','Consolas',monospace;font-size:13px;line-height:1.6}
code{font-family:'Space Mono','Consolas',monospace;font-size:13px}
p code,li code,td code{background:#f0f0f0;padding:2px 6px;border-radius:3px;color:#c7254e;font-size:12px}
.cc{font-size:12px;font-weight:bold;color:#2c3e50;margin-top:15px;margin-bottom:4px}
.cm{color:#6a9955}.kw{color:#569cd6}.st{color:#ce9178}.fn{color:#dcdcaa}.nb{color:#4ec9b0}.nu{color:#b5cea8}
.progress-bar{width:100%;height:6px;background:#e0e0e0;border-radius:3px;margin-top:16px}
.progress-fill{height:100%;background:linear-gradient(90deg,#0080c6,#00b894);border-radius:3px;width:40%}
.progress-label{font-size:11px;color:#888;margin-top:4px;text-align:center}
@media(max-width:1024px){
.sidebar{width:100%;height:auto;position:relative;border-right:none;border-bottom:1px solid rgba(0,0,0,.08);padding:16px}
.sidebar-profile{margin-bottom:10px;padding-bottom:10px;display:flex;align-items:center;gap:12px;text-align:left}
.profile-icon{font-size:32px;margin-bottom:0}.profile-bio{display:none}
.nav-section{display:inline-block;margin-right:16px;margin-bottom:8px}
.nav-list{display:flex;gap:10px;flex-wrap:wrap}.nav-list li{margin-bottom:0}
.sidebar-footer{display:none}
.main-wrapper{margin-left:0}
.container{padding:0}.paper-content{padding:20px 16px;border-radius:0;box-shadow:none}
.paper-title{font-size:18px}p{font-size:14px;text-indent:1.5em;text-align:left}
pre{font-size:11px;padding:14px}table{font-size:10px;display:block;overflow-x:auto}
}
</style>
</head>
<body>

<div class="sidebar">
<div class="sidebar-profile">
<div class="profile-icon">&#x1F680;</div>
<div class="profile-name">HFT ML Master Plan</div>
<div class="profile-title">Convex Opt + DL + HFT</div>
<div class="profile-bio">10 Rounds: Zero to HFT System Trading</div>
</div>
<div class="sidebar-nav">
<div class="nav-section">
<div class="nav-section-title">Curriculum</div>
<ul class="nav-list">
<li><a class="done" href="../round_01/lecture_01.html">R1. Python + Finance <span class="badge badge-done">DONE</span></a></li>
<li><a class="done" href="../round_02/lecture_02.html">R2. Linear Algebra + Stats <span class="badge badge-done">DONE</span></a></li>
<li><a class="done" href="../round_03/lecture_03.html">R3. Data / Feature Eng. <span class="badge badge-done">DONE</span></a></li>
<li><a class="active" href="#">R4. Supervised Learning <span class="badge">NOW</span></a></li>
<li><a href="#">R5. Unsupervised + TS</a></li>
<li><a href="#">R6. NLP + Sentiment</a></li>
<li><a href="#">R7. Deep Learning</a></li>
<li><a href="#">R8. Convex Opt + Transformer</a></li>
<li><a href="#">R9. HFT + RL</a></li>
<li><a href="#">R10. Final Project</a></li>
</ul>
</div>
<div class="nav-section">
<div class="nav-section-title">This Lecture</div>
<ul class="nav-list">
<li><a href="#ch1">1. MLì´ë€ ë¬´ì—‡ì¸ê°€</a></li>
<li><a href="#ch2">2. íšŒê·€ vs ë¶„ë¥˜</a></li>
<li><a href="#ch3">3. ì„ í˜•íšŒê·€</a></li>
<li><a href="#ch4">4. Ridge / Lasso ì •ê·œí™”</a></li>
<li><a href="#ch5">5. ë¡œì§€ìŠ¤í‹± íšŒê·€</a></li>
<li><a href="#ch6">6. ëª¨ë¸ í‰ê°€ ì§€í‘œ</a></li>
<li><a href="#ch7">7. êµì°¨ê²€ì¦ê³¼ ê³¼ì í•©</a></li>
<li><a href="#ch8">8. ê²°ì • íŠ¸ë¦¬</a></li>
<li><a href="#ch9">9. Random Forest</a></li>
<li><a href="#ch10">10. Gradient Boosting</a></li>
<li><a href="#ch11">11. XGBoost / LightGBM</a></li>
<li><a href="#ch12">12. ì‹¤ì „: ì£¼ê°€ ë°©í–¥ ì˜ˆì¸¡</a></li>
<li><a href="#ch13">13. Quiz + ë¯¸ë‹ˆ í”„ë¡œì íŠ¸</a></li>
</ul>
</div>
</div>
<div class="sidebar-footer">Round 4 of 10 Â· ğŸ“ˆ Supervised Learning</div>
</div>

<div class="main-wrapper">
<div class="container">
<div class="paper-content">

<div class="paper-header">
<div class="paper-category">Round 4 / 10 Â· ML í•µì‹¬ ë¬´ê¸° ì‹œì‘</div>
<h1 class="paper-title">Supervised Learning: Regression + Classification for Algorithmic Trading</h1>
<div class="paper-subtitle">ë°ì´í„°ì—ì„œ íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬ ì£¼ê°€ ìˆ˜ìµë¥ ì„ ì˜ˆì¸¡í•˜ê³  ë§¤ë§¤ ë°©í–¥ì„ ë¶„ë¥˜í•œë‹¤</div>
<div class="paper-team">Textbooks: MLAT Ch.6~7, 11~12 / MLDSF Ch.4~6 / í˜¼ê³µíŒŒ ë³µìŠµ</div>
<div class="progress-bar"><div class="progress-fill"></div></div>
<div class="progress-label">Overall Progress: 40%</div>
</div>

<div class="abstract">
<div class="abstract-title">Learning Objectives</div>
<p class="ni">Round 4ë¥¼ ë§ˆì¹˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆë‹¤:</p>
<ul>
<li>ì§€ë„í•™ìŠµì˜ ë‘ ê°€ì§€ ìœ í˜•(íšŒê·€/ë¶„ë¥˜)ì„ êµ¬ë¶„í•˜ê³  ê¸ˆìœµ ë¬¸ì œì— ë§¤í•‘í•  ìˆ˜ ìˆë‹¤</li>
<li>ì„ í˜•íšŒê·€ë¥¼ ì§ì ‘ êµ¬í˜„í•˜ê³ , ê³„ìˆ˜ì˜ ê¸ˆìœµì  ì˜ë¯¸ë¥¼ í•´ì„í•  ìˆ˜ ìˆë‹¤</li>
<li>Ridge/Lasso ì •ê·œí™”ê°€ ì™œ í•„ìš”í•œì§€ ì´í•´í•˜ê³  ì ìš©í•  ìˆ˜ ìˆë‹¤</li>
<li>ë¡œì§€ìŠ¤í‹± íšŒê·€ë¡œ ì£¼ê°€ ìƒìŠ¹/í•˜ë½ì„ ë¶„ë¥˜í•  ìˆ˜ ìˆë‹¤</li>
<li>MSE, MAE, RÂ², AUC-ROC, í˜¼ë™í–‰ë ¬ ë“± í‰ê°€ ì§€í‘œë¥¼ ì˜¬ë°”ë¥´ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤</li>
<li>êµì°¨ê²€ì¦ìœ¼ë¡œ ê³¼ì í•©ì„ íƒì§€í•˜ê³  ë°©ì§€í•  ìˆ˜ ìˆë‹¤</li>
<li>ê²°ì • íŠ¸ë¦¬ì˜ ì‘ë™ ì›ë¦¬ë¥¼ ì´í•´í•˜ê³  ì‹œê°í™”í•  ìˆ˜ ìˆë‹¤</li>
<li>Random Forestì™€ Gradient Boostingì˜ ì°¨ì´ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤</li>
<li>XGBoost/LightGBMìœ¼ë¡œ ì‹¤ì „ ì£¼ê°€ ë°©í–¥ ì˜ˆì¸¡ ëª¨ë¸ì„ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤</li>
</ul>
<div style="font-size:13px;color:#555;margin-top:15px;font-style:italic"><strong>Keywords:</strong> Supervised Learning, Linear Regression, Ridge, Lasso, Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, XGBoost, LightGBM, Cross-Validation, Overfitting</div>
</div>

<!-- Round 4 ì „ì²´ í•™ìŠµ ë¡œë“œë§µ ë‹¤ì´ì–´ê·¸ë¨ (CSS) -->
<div style="margin:30px 0;padding:25px;background:linear-gradient(135deg,#f0f4f8,#e8eef4);border-radius:10px;border:1px solid #ccc">
<p class="ni" style="text-align:center;font-weight:bold;font-size:15px;margin-bottom:18px;color:#2c3e50">ğŸ§  ì§€ë„í•™ìŠµ ì „ì²´ ë¡œë“œë§µ</p>
<div style="display:flex;align-items:stretch;justify-content:center;gap:6px;flex-wrap:wrap;font-size:12px">
<div style="background:#3498db;color:#fff;padding:15px 12px;border-radius:8px;text-align:center;min-width:110px;display:flex;flex-direction:column;justify-content:center">
<div style="font-size:22px;margin-bottom:4px">ğŸ“</div>
<div style="font-weight:bold">ì„ í˜• ëª¨ë¸</div>
<div style="font-size:10px;opacity:0.9;margin-top:4px">ì„ í˜•íšŒê·€<br>Ridge/Lasso<br>ë¡œì§€ìŠ¤í‹±</div>
<div style="font-size:10px;margin-top:4px;background:rgba(255,255,255,0.2);padding:2px 4px;border-radius:3px">Ch.3~5</div>
</div>
<div style="display:flex;align-items:center;color:#3498db;font-size:20px">â–¶</div>
<div style="background:#e67e22;color:#fff;padding:15px 12px;border-radius:8px;text-align:center;min-width:110px;display:flex;flex-direction:column;justify-content:center">
<div style="font-size:22px;margin-bottom:4px">ğŸ“</div>
<div style="font-weight:bold">í‰ê°€ & ê²€ì¦</div>
<div style="font-size:10px;opacity:0.9;margin-top:4px">MSE, AUC<br>êµì°¨ê²€ì¦<br>ê³¼ì í•© ë°©ì§€</div>
<div style="font-size:10px;margin-top:4px;background:rgba(255,255,255,0.2);padding:2px 4px;border-radius:3px">Ch.6~7</div>
</div>
<div style="display:flex;align-items:center;color:#e67e22;font-size:20px">â–¶</div>
<div style="background:#27ae60;color:#fff;padding:15px 12px;border-radius:8px;text-align:center;min-width:110px;display:flex;flex-direction:column;justify-content:center">
<div style="font-size:22px;margin-bottom:4px">ğŸŒ³</div>
<div style="font-weight:bold">íŠ¸ë¦¬ ëª¨ë¸</div>
<div style="font-size:10px;opacity:0.9;margin-top:4px">ê²°ì • íŠ¸ë¦¬<br>Random Forest<br>Bagging</div>
<div style="font-size:10px;margin-top:4px;background:rgba(255,255,255,0.2);padding:2px 4px;border-radius:3px">Ch.8~9</div>
</div>
<div style="display:flex;align-items:center;color:#27ae60;font-size:20px">â–¶</div>
<div style="background:#9b59b6;color:#fff;padding:15px 12px;border-radius:8px;text-align:center;min-width:110px;display:flex;flex-direction:column;justify-content:center">
<div style="font-size:22px;margin-bottom:4px">ğŸš€</div>
<div style="font-weight:bold">ë¶€ìŠ¤íŒ…</div>
<div style="font-size:10px;opacity:0.9;margin-top:4px">Gradient Boost<br>XGBoost<br>LightGBM</div>
<div style="font-size:10px;margin-top:4px;background:rgba(255,255,255,0.2);padding:2px 4px;border-radius:3px">Ch.10~11</div>
</div>
<div style="display:flex;align-items:center;color:#9b59b6;font-size:20px">â–¶</div>
<div style="background:#e74c3c;color:#fff;padding:15px 12px;border-radius:8px;text-align:center;min-width:110px;display:flex;flex-direction:column;justify-content:center">
<div style="font-size:22px;margin-bottom:4px">ğŸ’°</div>
<div style="font-weight:bold">ì‹¤ì „ í”„ë¡œì íŠ¸</div>
<div style="font-size:10px;opacity:0.9;margin-top:4px">ì£¼ê°€ ë°©í–¥ ì˜ˆì¸¡<br>í”¼ì²˜ ì¤‘ìš”ë„<br>ë°±í…ŒìŠ¤íŠ¸ ì—°ê²°</div>
<div style="font-size:10px;margin-top:4px;background:rgba(255,255,255,0.2);padding:2px 4px;border-radius:3px">Ch.12</div>
</div>
</div>
</div>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- Ch1: MLì´ë€ ë¬´ì—‡ì¸ê°€ -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2 id="ch1">1. ë¨¸ì‹ ëŸ¬ë‹ì´ë€ ë¬´ì—‡ì¸ê°€ â€” "ë°ì´í„°ì—ì„œ ê·œì¹™ì„ ìŠ¤ìŠ¤ë¡œ ì°¾ëŠ”ë‹¤"</h2>

<h3>1.1 ì „í†µì  í”„ë¡œê·¸ë˜ë° vs ë¨¸ì‹ ëŸ¬ë‹</h3>
<p>ì „í†µì  í”„ë¡œê·¸ë˜ë°ì—ì„œëŠ” ì¸ê°„ì´ ê·œì¹™ì„ ì§ì ‘ ì½”ë”©í•œë‹¤. "RSIê°€ 30 ì´í•˜ì´ë©´ ë§¤ìˆ˜, 70 ì´ìƒì´ë©´ ë§¤ë„" â€” ì´ê²ƒì€ ì¸ê°„ì´ ë§Œë“  ê·œì¹™ì´ë‹¤. í•˜ì§€ë§Œ ê¸ˆìœµ ì‹œì¥ì€ ë„ˆë¬´ ë³µì¡í•´ì„œ ì¸ê°„ì´ ëª¨ë“  ê·œì¹™ì„ ë§Œë“¤ ìˆ˜ ì—†ë‹¤. ìˆ˜ë°± ê°œì˜ í”¼ì²˜ê°€ ì„œë¡œ ë¹„ì„ í˜•ì ìœ¼ë¡œ ìƒí˜¸ì‘ìš©í•˜ê³ , ì‹œì¥ í™˜ê²½ì´ ê³„ì† ë³€í•œë‹¤.</p>

<p>ë¨¸ì‹ ëŸ¬ë‹(Machine Learning, ML)ì€ ì ‘ê·¼ ë°©ì‹ì´ ë‹¤ë¥´ë‹¤. ë°ì´í„°ë¥¼ ì£¼ë©´ ì»´í“¨í„°ê°€ ìŠ¤ìŠ¤ë¡œ íŒ¨í„´(ê·œì¹™)ì„ ì°¾ì•„ë‚¸ë‹¤. ì¸ê°„ì€ "ì–´ë–¤ ë°ì´í„°ë¥¼ ì¤„ ê²ƒì¸ê°€"ì™€ "ì–´ë–¤ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•  ê²ƒì¸ê°€"ë§Œ ê²°ì •í•˜ë©´ ëœë‹¤.</p>

<!-- ì „í†µ í”„ë¡œê·¸ë˜ë° vs ML ë¹„êµ ë‹¤ì´ì–´ê·¸ë¨ -->
<div style="margin:25px 0;padding:20px;background:#f8f9fa;border-radius:8px;border:1px solid #ddd">
<p class="ni" style="text-align:center;font-weight:bold;font-size:14px;margin-bottom:15px;color:#2c3e50">ğŸ”„ ì „í†µì  í”„ë¡œê·¸ë˜ë° vs ë¨¸ì‹ ëŸ¬ë‹</p>
<div style="display:flex;gap:20px;justify-content:center;flex-wrap:wrap;font-size:12px">
<div style="flex:1;min-width:250px;background:#fff;padding:15px;border-radius:8px;border:2px solid #3498db">
<div style="font-weight:bold;color:#3498db;font-size:13px;margin-bottom:10px;text-align:center">ì „í†µì  í”„ë¡œê·¸ë˜ë°</div>
<div style="display:flex;flex-direction:column;gap:6px;align-items:center">
<div style="background:#e8f4f8;padding:6px 12px;border-radius:4px">ğŸ“Š ë°ì´í„° + ğŸ“ ê·œì¹™</div>
<div style="color:#3498db">â†“</div>
<div style="background:#3498db;color:#fff;padding:8px 16px;border-radius:4px;font-weight:bold">ì»´í“¨í„°</div>
<div style="color:#3498db">â†“</div>
<div style="background:#e8f4f8;padding:6px 12px;border-radius:4px">ğŸ“¤ ê²°ê³¼</div>
</div>
<div style="margin-top:8px;color:#555;text-align:center;font-size:11px">ì¸ê°„ì´ ê·œì¹™ì„ ë§Œë“ ë‹¤</div>
</div>
<div style="flex:1;min-width:250px;background:#fff;padding:15px;border-radius:8px;border:2px solid #e74c3c">
<div style="font-weight:bold;color:#e74c3c;font-size:13px;margin-bottom:10px;text-align:center">ë¨¸ì‹ ëŸ¬ë‹</div>
<div style="display:flex;flex-direction:column;gap:6px;align-items:center">
<div style="background:#fde8e8;padding:6px 12px;border-radius:4px">ğŸ“Š ë°ì´í„° + ğŸ“¤ ì •ë‹µ</div>
<div style="color:#e74c3c">â†“</div>
<div style="background:#e74c3c;color:#fff;padding:8px 16px;border-radius:4px;font-weight:bold">ì»´í“¨í„° (í•™ìŠµ)</div>
<div style="color:#e74c3c">â†“</div>
<div style="background:#fde8e8;padding:6px 12px;border-radius:4px">ğŸ“ ê·œì¹™ (ëª¨ë¸)</div>
</div>
<div style="margin-top:8px;color:#555;text-align:center;font-size:11px">ì»´í“¨í„°ê°€ ê·œì¹™ì„ ì°¾ëŠ”ë‹¤</div>
</div>
</div>
</div>

<div class="def">
<p class="ni"><strong>ì •ì˜: ì§€ë„í•™ìŠµ (Supervised Learning)</strong></p>
<p class="ni">ì…ë ¥(X)ê³¼ ì •ë‹µ(y)ì´ ìŒìœ¼ë¡œ ì£¼ì–´ì§„ ë°ì´í„°ì—ì„œ, X â†’ yì˜ ë§¤í•‘ í•¨ìˆ˜ fë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì´ë‹¤. "ì§€ë„"ë¼ëŠ” ì´ë¦„ì€ ì •ë‹µ(label)ì´ "ì„ ìƒë‹˜"ì²˜ëŸ¼ í•™ìŠµì„ ì•ˆë‚´í•˜ê¸° ë•Œë¬¸ì´ë‹¤.</p>
<div class="eq">\[ \hat{y} = f(X) \quad \text{where } f \text{ is learned from } \{(X_1, y_1), (X_2, y_2), \ldots, (X_n, y_n)\} \]</div>
<p class="ni">ê¸ˆìœµì—ì„œì˜ ì˜ˆ: X = [RSI, MACD, ë³€ë™ì„±, ê±°ë˜ëŸ‰, ...] â†’ y = ë‚´ì¼ ìˆ˜ìµë¥  (íšŒê·€) ë˜ëŠ” ìƒìŠ¹/í•˜ë½ (ë¶„ë¥˜)</p>
</div>

<h3>1.2 MLì˜ ì„¸ ê°€ì§€ ìœ í˜•</h3>

<div class="tc">Table 1. ë¨¸ì‹ ëŸ¬ë‹ì˜ ì„¸ ê°€ì§€ ìœ í˜•</div>
<table>
<tr><th>ìœ í˜•</th><th>ì •ë‹µ ìœ ë¬´</th><th>ëª©í‘œ</th><th>ê¸ˆìœµ ì˜ˆì‹œ</th><th>ë¼ìš´ë“œ</th></tr>
<tr><td>ì§€ë„í•™ìŠµ (Supervised)</td><td>âœ… ìˆìŒ</td><td>ì˜ˆì¸¡ (íšŒê·€/ë¶„ë¥˜)</td><td>ì£¼ê°€ ë°©í–¥ ì˜ˆì¸¡, ë¶€ë„ í™•ë¥ </td><td>R4 (ì´ë²ˆ!)</td></tr>
<tr><td>ë¹„ì§€ë„í•™ìŠµ (Unsupervised)</td><td>âŒ ì—†ìŒ</td><td>êµ¬ì¡° ë°œê²¬ (í´ëŸ¬ìŠ¤í„°ë§/ì°¨ì›ì¶•ì†Œ)</td><td>ì¢…ëª© ê·¸ë£¹í•‘, íŒ©í„° ì¶”ì¶œ</td><td>R5</td></tr>
<tr><td>ê°•í™”í•™ìŠµ (Reinforcement)</td><td>ğŸ® ë³´ìƒ</td><td>ìµœì  í–‰ë™ í•™ìŠµ</td><td>ìë™ë§¤ë§¤ ì—ì´ì „íŠ¸</td><td>R9</td></tr>
</table>

<p>ì´ë²ˆ ë¼ìš´ë“œì—ì„œëŠ” ì§€ë„í•™ìŠµì— ì§‘ì¤‘í•œë‹¤. ì§€ë„í•™ìŠµì€ ê¸ˆìœµ MLì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ìœ í˜•ì´ë‹¤. "ê³¼ê±° ë°ì´í„°ë¡œ í•™ìŠµí•˜ê³ , ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•œë‹¤" â€” ì´ê²ƒì´ ì•Œê³ ë¦¬ì¦˜ íŠ¸ë ˆì´ë”©ì˜ í•µì‹¬ì´ê¸° ë•Œë¬¸ì´ë‹¤.</p>

<h3>1.3 ê¸ˆìœµ MLì˜ íŠ¹ìˆ˜í•œ ì–´ë ¤ì›€</h3>
<p>ê¸ˆìœµ ë°ì´í„°ì— MLì„ ì ìš©í•˜ëŠ” ê²ƒì€ ì´ë¯¸ì§€ ì¸ì‹ì´ë‚˜ ìì—°ì–´ ì²˜ë¦¬ë³´ë‹¤ í›¨ì”¬ ì–´ë µë‹¤. ì™œ ê·¸ëŸ°ì§€ ì´í•´í•˜ëŠ” ê²ƒì´ ë§¤ìš° ì¤‘ìš”í•˜ë‹¤.</p>

<div class="warn">
<p class="ni"><strong>ê¸ˆìœµ MLì´ ì–´ë ¤ìš´ 5ê°€ì§€ ì´ìœ :</strong></p>
<ol>
<li><strong>ì‹ í˜¸ ëŒ€ ì¡ìŒ ë¹„ìœ¨(SNR)ì´ ê·¹ë„ë¡œ ë‚®ë‹¤:</strong> ì´ë¯¸ì§€ ì¸ì‹ì˜ ì •í™•ë„ëŠ” 99%ë¥¼ ë„˜ì§€ë§Œ, ì£¼ê°€ ë°©í–¥ ì˜ˆì¸¡ì€ 55%ë§Œ ë„˜ì–´ë„ ëŒ€ë‹¨í•˜ë‹¤. ê¸ˆìœµ ë°ì´í„°ì˜ ëŒ€ë¶€ë¶„ì€ ë…¸ì´ì¦ˆ(ì¡ìŒ)ì´ê³ , ì§„ì§œ ì‹ í˜¸ëŠ” ì•„ì£¼ ì‘ë‹¤.</li>
<li><strong>ë¹„ì •ìƒì„± (Non-stationarity):</strong> ì‹œì¥ì˜ í†µê³„ì  ì„±ì§ˆì´ ì‹œê°„ì— ë”°ë¼ ë³€í•œë‹¤. 2020ë…„ì— ì˜ ì‘ë™í•œ ëª¨ë¸ì´ 2024ë…„ì—ëŠ” ì•ˆ ë  ìˆ˜ ìˆë‹¤.</li>
<li><strong>ì ì‘ì  ì‹œì¥ (Adaptive Markets):</strong> ë‹¤ë¥¸ ì°¸ì—¬ìë“¤ë„ MLì„ ì‚¬ìš©í•œë‹¤. íŒ¨í„´ì´ ë°œê²¬ë˜ë©´ ì‚¬ë¼ì§„ë‹¤ (ì•ŒíŒŒ ê°ì‡ ).</li>
<li><strong>ê³¼ì í•©ì˜ ìœ í˜¹:</strong> í”¼ì²˜ê°€ ë§ê³  ë°ì´í„°ê°€ ì ìœ¼ë©´, ëª¨ë¸ì´ ê³¼ê±° ë…¸ì´ì¦ˆë¥¼ "í•™ìŠµ"í•´ë²„ë¦°ë‹¤.</li>
<li><strong>ì‹œê°„ ì˜ì¡´ì„±:</strong> ê¸ˆìœµ ë°ì´í„°ëŠ” ì‹œê°„ ìˆœì„œê°€ ì¤‘ìš”í•˜ë‹¤. ì¼ë°˜ì ì¸ ëœë¤ ì…”í”Œ êµì°¨ê²€ì¦ì„ ì“°ë©´ ë¯¸ë˜ ì •ë³´ê°€ ëˆ„ì¶œëœë‹¤.</li>
</ol>
</div>

<div class="info">
<p class="ni"><strong>êµì¬ ì—°ë™:</strong> MLAT Ch.6 "The Machine Learning Process"ì—ì„œ ML ì›Œí¬í”Œë¡œìš°ì˜ ì „ì²´ êµ¬ì¡°ë¥¼, Ch.7 "Linear Models"ì—ì„œ ì„ í˜• ëª¨ë¸ì˜ ì´ë¡ ê³¼ ê¸ˆìœµ ì ìš©ì„ ë‹¤ë£¬ë‹¤. MLDSF Ch.4 "Supervised Learning"ì—ì„œëŠ” ì§€ë„í•™ìŠµ ëª¨ë¸ì˜ ê°œê´€ê³¼ ê¸ˆìœµ ì¼€ì´ìŠ¤ìŠ¤í„°ë””ë¥¼ ì œê³µí•œë‹¤.</p>
</div>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- Ch2: íšŒê·€ vs ë¶„ë¥˜ -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2 id="ch2">2. íšŒê·€ vs ë¶„ë¥˜ â€” ì§€ë„í•™ìŠµì˜ ë‘ ê°ˆë˜</h2>

<h3>2.1 íšŒê·€ (Regression): ì—°ì†ì ì¸ ìˆ«ìë¥¼ ì˜ˆì¸¡</h3>
<p>íšŒê·€ëŠ” ì¶œë ¥(y)ì´ ì—°ì†ì ì¸ ìˆ«ìì¼ ë•Œ ì‚¬ìš©í•œë‹¤. "ë‚´ì¼ ì‚¼ì„±ì „ì ìˆ˜ìµë¥ ì€ ëª‡ %ì¼ê¹Œ?" â€” ì´ê²ƒì´ íšŒê·€ ë¬¸ì œë‹¤. ì¶œë ¥ì´ -5%, 0%, +3.2% ê°™ì€ ì—°ì†ì ì¸ ê°’ì´ê¸° ë•Œë¬¸ì´ë‹¤.</p>

<h3>2.2 ë¶„ë¥˜ (Classification): ì¹´í…Œê³ ë¦¬ë¥¼ ì˜ˆì¸¡</h3>
<p>ë¶„ë¥˜ëŠ” ì¶œë ¥(y)ì´ ì´ì‚°ì ì¸ ì¹´í…Œê³ ë¦¬ì¼ ë•Œ ì‚¬ìš©í•œë‹¤. "ë‚´ì¼ ì‚¼ì„±ì „ìê°€ ì˜¤ë¥¼ê¹Œ ë‚´ë¦´ê¹Œ?" â€” ì´ê²ƒì´ ë¶„ë¥˜ ë¬¸ì œë‹¤. ì¶œë ¥ì´ "ìƒìŠ¹" ë˜ëŠ” "í•˜ë½" ë‘ ê°€ì§€ ì¤‘ í•˜ë‚˜ì´ê¸° ë•Œë¬¸ì´ë‹¤.</p>

<div class="tc">Table 2. íšŒê·€ vs ë¶„ë¥˜ ë¹„êµ</div>
<table>
<tr><th>êµ¬ë¶„</th><th>íšŒê·€ (Regression)</th><th>ë¶„ë¥˜ (Classification)</th></tr>
<tr><td>ì¶œë ¥ íƒ€ì…</td><td>ì—°ì† ìˆ«ì (ì˜ˆ: ìˆ˜ìµë¥  %)</td><td>ì¹´í…Œê³ ë¦¬ (ì˜ˆ: ìƒìŠ¹/í•˜ë½)</td></tr>
<tr><td>ê¸ˆìœµ ì˜ˆì‹œ</td><td>ë‚´ì¼ ìˆ˜ìµë¥  ì˜ˆì¸¡, VaR ì¶”ì •</td><td>ìƒìŠ¹/í•˜ë½ ì˜ˆì¸¡, ë¶€ë„ ì—¬ë¶€</td></tr>
<tr><td>í‰ê°€ ì§€í‘œ</td><td>MSE, MAE, RÂ²</td><td>Accuracy, AUC-ROC, F1</td></tr>
<tr><td>ëŒ€í‘œ ëª¨ë¸</td><td>ì„ í˜•íšŒê·€, Ridge, Lasso</td><td>ë¡œì§€ìŠ¤í‹± íšŒê·€, SVM, íŠ¸ë¦¬</td></tr>
<tr><td>ì†ì‹¤ í•¨ìˆ˜</td><td>Mean Squared Error</td><td>Cross-Entropy (Log Loss)</td></tr>
</table>

<div class="warn">
<p class="ni"><strong>ê¸ˆìœµ MLì—ì„œì˜ ì‹¤ì „ ì„ íƒ:</strong> ì‹¤ì „ì—ì„œëŠ” ë¶„ë¥˜ê°€ ë” ë§ì´ ì‚¬ìš©ëœë‹¤. ì™œ? ìˆ˜ìµë¥ ì˜ ì •í™•í•œ í¬ê¸°ë¥¼ ë§ì¶”ëŠ” ê²ƒ(íšŒê·€)ë³´ë‹¤, ë°©í–¥ë§Œ ë§ì¶”ëŠ” ê²ƒ(ë¶„ë¥˜)ì´ í›¨ì”¬ ì‰½ê¸° ë•Œë¬¸ì´ë‹¤. "ë‚´ì¼ +2.3% ì˜¤ë¥¸ë‹¤"ë¥¼ ë§ì¶”ê¸°ëŠ” ê±°ì˜ ë¶ˆê°€ëŠ¥í•˜ì§€ë§Œ, "ë‚´ì¼ ì˜¤ë¥¸ë‹¤"ë¥¼ 55% í™•ë¥ ë¡œ ë§ì¶”ëŠ” ê²ƒì€ ê°€ëŠ¥í•˜ë‹¤. ê·¸ë¦¬ê³  ë°©í–¥ë§Œ ë§ì¶°ë„ ëˆì„ ë²Œ ìˆ˜ ìˆë‹¤.</p>
</div>

<h3>2.3 ê¸ˆìœµ ë¬¸ì œë¥¼ MLë¡œ ë³€í™˜í•˜ê¸°</h3>
<p>ê¸ˆìœµ ë¬¸ì œë¥¼ ML ë¬¸ì œë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì´ ì²« ë²ˆì§¸ ë‹¨ê³„ë‹¤. Round 3ì—ì„œ ë§Œë“  í”¼ì²˜ í…Œì´ë¸”ì´ ì…ë ¥(X)ì´ ë˜ê³ , ìš°ë¦¬ê°€ ì˜ˆì¸¡í•˜ê³  ì‹¶ì€ ê²ƒì´ ì¶œë ¥(y)ì´ ëœë‹¤.</p>

<pre><code><span class="cm"># ê¸ˆìœµ ë¬¸ì œ â†’ ML ë¬¸ì œ ë³€í™˜ ì˜ˆì œ</span>
<span class="kw">import</span> yfinance <span class="kw">as</span> yf
<span class="kw">import</span> pandas <span class="kw">as</span> pd
<span class="kw">import</span> numpy <span class="kw">as</span> np

<span class="cm"># 1. ë°ì´í„° ìˆ˜ì§‘ (Round 3 ë³µìŠµ)</span>
data = yf.download(<span class="st">"005930.KS"</span>, start=<span class="st">"2020-01-01"</span>, end=<span class="st">"2025-12-31"</span>)
close = data[<span class="st">"Close"</span>].squeeze()  <span class="cm"># yfinance 1.0+: Closeê°€ ì´ë¯¸ ìˆ˜ì •ì¢…ê°€</span>

<span class="cm"># 2. í”¼ì²˜ ìƒì„± (X) â€” Round 3ì—ì„œ ë°°ìš´ ê²ƒë“¤</span>
features = pd.DataFrame(index=close.index)
features[<span class="st">"ret_1d"</span>] = close.pct_change(<span class="nu">1</span>)      <span class="cm"># 1ì¼ ìˆ˜ìµë¥ </span>
features[<span class="st">"ret_5d"</span>] = close.pct_change(<span class="nu">5</span>)      <span class="cm"># 5ì¼ ìˆ˜ìµë¥ </span>
features[<span class="st">"ret_20d"</span>] = close.pct_change(<span class="nu">20</span>)    <span class="cm"># 20ì¼ ìˆ˜ìµë¥ </span>
features[<span class="st">"vol_20d"</span>] = close.pct_change().rolling(<span class="nu">20</span>).std()  <span class="cm"># 20ì¼ ë³€ë™ì„±</span>
features[<span class="st">"sma_ratio"</span>] = close / close.rolling(<span class="nu">20</span>).mean()  <span class="cm"># ê°€ê²©/SMA20</span>

<span class="cm"># RSI ê³„ì‚°</span>
delta = close.diff()
gain = delta.where(delta > <span class="nu">0</span>, <span class="nu">0</span>)
loss = -delta.where(delta < <span class="nu">0</span>, <span class="nu">0</span>)
avg_gain = gain.ewm(alpha=<span class="nu">1</span>/<span class="nu">14</span>, min_periods=<span class="nu">14</span>).mean()
avg_loss = loss.ewm(alpha=<span class="nu">1</span>/<span class="nu">14</span>, min_periods=<span class="nu">14</span>).mean()
features[<span class="st">"rsi"</span>] = <span class="nu">100</span> - (<span class="nu">100</span> / (<span class="nu">1</span> + avg_gain / avg_loss))

<span class="cm"># 3. íƒ€ê²Ÿ ìƒì„± (y)</span>
<span class="cm"># íšŒê·€ íƒ€ê²Ÿ: 5ì¼ í›„ ìˆ˜ìµë¥ </span>
features[<span class="st">"target_reg"</span>] = close.pct_change(<span class="nu">5</span>).shift(-<span class="nu">5</span>)  <span class="cm"># ë¯¸ë˜ 5ì¼ ìˆ˜ìµë¥ </span>

<span class="cm"># ë¶„ë¥˜ íƒ€ê²Ÿ: 5ì¼ í›„ ìƒìŠ¹(1) / í•˜ë½(0)</span>
features[<span class="st">"target_cls"</span>] = (close.pct_change(<span class="nu">5</span>).shift(-<span class="nu">5</span>) > <span class="nu">0</span>).astype(<span class="nb">int</span>)

<span class="cm"># 4. ê²°ì¸¡ì¹˜ ì œê±°</span>
features = features.dropna()
<span class="fn">print</span>(<span class="st">f"í”¼ì²˜ í…Œì´ë¸”: </span>{features.shape}<span class="st">"</span>)
<span class="fn">print</span>(features.head(<span class="nu">5</span>))
<span class="fn">print</span>(<span class="st">f"\në¶„ë¥˜ íƒ€ê²Ÿ ë¶„í¬:\n</span>{features[<span class="st">'target_cls'</span>].value_counts()}<span class="st">"</span>)</code></pre>

<div class="def">
<p class="ni"><strong>í•µì‹¬: shift(-5)ì˜ ì˜ë¯¸</strong></p>
<p class="ni"><code>shift(-5)</code>ëŠ” ë°ì´í„°ë¥¼ 5í–‰ ìœ„ë¡œ ë‹¹ê¸´ë‹¤. ì¦‰, ì˜¤ëŠ˜ í–‰ì— "5ì¼ í›„ì˜ ìˆ˜ìµë¥ "ì´ ë“¤ì–´ê°„ë‹¤. ì´ê²ƒì´ MLì—ì„œ "ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•œë‹¤"ë¥¼ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì´ë‹¤. í•™ìŠµ ì‹œì—ëŠ” ê³¼ê±° ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ê³ , íƒ€ê²Ÿì€ ë¯¸ë˜ ê°’ì´ë‹¤. ë‹¨, ë§ˆì§€ë§‰ 5í–‰ì€ ë¯¸ë˜ ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ NaNì´ ë˜ì–´ ì œê±°ëœë‹¤.</p>
</div>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- Ch3: ì„ í˜•íšŒê·€ -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2 id="ch3">3. ì„ í˜•íšŒê·€ â€” ëª¨ë“  MLì˜ ì¶œë°œì </h2>

<h3>3.1 ì„ í˜•íšŒê·€ë€?</h3>
<p>ì„ í˜•íšŒê·€(Linear Regression)ëŠ” ê°€ì¥ ë‹¨ìˆœí•˜ë©´ì„œë„ ê°€ì¥ ì¤‘ìš”í•œ ML ëª¨ë¸ì´ë‹¤. ì…ë ¥ ë³€ìˆ˜ë“¤ì˜ ê°€ì¤‘í•©(weighted sum)ìœ¼ë¡œ ì¶œë ¥ì„ ì˜ˆì¸¡í•œë‹¤. "ë‹¨ìˆœí•˜ë‹¤"ê³  ë¬´ì‹œí•˜ë©´ ì•ˆ ëœë‹¤ â€” ê¸ˆìœµì—ì„œ Fama-French íŒ©í„° ëª¨ë¸, CAPM, ë¦¬ìŠ¤í¬ ëª¨ë¸ ë“± í•µì‹¬ ì´ë¡ ì´ ëª¨ë‘ ì„ í˜•íšŒê·€ì— ê¸°ë°˜í•œë‹¤. MLAT Ch.7ì—ì„œë„ ì„ í˜•íšŒê·€ë¥¼ "From Risk Factors to Return Forecasts"ì˜ ê¸°ë³¸ ë„êµ¬ë¡œ ë‹¤ë£¬ë‹¤.</p>

<div class="eq">\[ \hat{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_p x_p = \beta_0 + \sum_{j=1}^{p} \beta_j x_j \]</div>

<p>ê° ê¸°í˜¸ì˜ ì˜ë¯¸:</p>
<ul>
<li>\(\hat{y}\): ì˜ˆì¸¡ê°’ (predicted value)</li>
<li>\(\beta_0\): ì ˆí¸ (intercept) â€” ëª¨ë“  í”¼ì²˜ê°€ 0ì¼ ë•Œì˜ ê¸°ë³¸ ì˜ˆì¸¡ê°’</li>
<li>\(\beta_j\): jë²ˆì§¸ í”¼ì²˜ì˜ ê³„ìˆ˜ (coefficient) â€” "ì´ í”¼ì²˜ê°€ 1 ì¦ê°€í•˜ë©´ yê°€ \(\beta_j\)ë§Œí¼ ë³€í•œë‹¤"</li>
<li>\(x_j\): jë²ˆì§¸ í”¼ì²˜ì˜ ê°’</li>
<li>\(p\): í”¼ì²˜ì˜ ê°œìˆ˜</li>
</ul>

<h3>3.2 OLS (Ordinary Least Squares) â€” ìµœì†Œì œê³±ë²•</h3>
<p>ì„ í˜•íšŒê·€ì˜ í•™ìŠµ ëª©í‘œëŠ” ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´(ì”ì°¨, residual)ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê³„ìˆ˜ Î²ë¥¼ ì°¾ëŠ” ê²ƒì´ë‹¤. ê°€ì¥ ê¸°ë³¸ì ì¸ ë°©ë²•ì´ OLS(ìµœì†Œì œê³±ë²•)ë‹¤. ì”ì°¨ì˜ ì œê³±í•©(RSS)ì„ ìµœì†Œí™”í•œë‹¤.</p>

<div class="eq">\[ \text{RSS} = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 = \sum_{i=1}^{n} \left(y_i - \beta_0 - \sum_{j=1}^{p} \beta_j x_{ij}\right)^2 \]</div>

<p>í–‰ë ¬ í‘œê¸°ë¡œ ì“°ë©´ ë” ê¹”ë”í•˜ë‹¤ (Round 2ì—ì„œ ë°°ìš´ ì„ í˜•ëŒ€ìˆ˜ê°€ ì—¬ê¸°ì„œ ì“°ì¸ë‹¤!):</p>

<div class="eq">\[ \hat{\boldsymbol{\beta}} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{y} \]</div>

<p>ì´ ê³µì‹ì€ "ë‹«íŒ í˜•íƒœ í•´(closed-form solution)"ë¼ê³  í•œë‹¤. ë°˜ë³µ ê³„ì‚° ì—†ì´ í•œ ë²ˆì— ìµœì  ê³„ìˆ˜ë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤. MLAT Ch.7ì—ì„œ ì„¤ëª…í•˜ë“¯, ì´ í•´ëŠ” ì”ì°¨ ë²¡í„° \(\mathbf{y} - \hat{\mathbf{y}}\)ê°€ í”¼ì²˜ ê³µê°„ì— ì§êµ(orthogonal)í•˜ë„ë¡ ë§Œë“ ë‹¤ â€” Round 2ì—ì„œ ë°°ìš´ ì§êµ ê°œë…ì´ ì—¬ê¸°ì„œ ì—°ê²°ëœë‹¤.</p>

<h3>3.3 íŒŒì´ì¬ìœ¼ë¡œ ì„ í˜•íšŒê·€ êµ¬í˜„</h3>

<pre><code><span class="cm"># === ì„ í˜•íšŒê·€: statsmodels (í†µê³„ì  ì¶”ë¡ ) + sklearn (ì˜ˆì¸¡) ===</span>
<span class="kw">import</span> numpy <span class="kw">as</span> np
<span class="kw">import</span> pandas <span class="kw">as</span> pd
<span class="kw">import</span> statsmodels.api <span class="kw">as</span> sm
<span class="kw">from</span> sklearn.linear_model <span class="kw">import</span> LinearRegression
<span class="kw">from</span> sklearn.model_selection <span class="kw">import</span> train_test_split
<span class="kw">from</span> sklearn.metrics <span class="kw">import</span> mean_squared_error, r2_score

<span class="cm"># í”¼ì²˜(X)ì™€ íƒ€ê²Ÿ(y) ë¶„ë¦¬</span>
feature_cols = [<span class="st">"ret_1d"</span>, <span class="st">"ret_5d"</span>, <span class="st">"ret_20d"</span>, <span class="st">"vol_20d"</span>, <span class="st">"sma_ratio"</span>, <span class="st">"rsi"</span>]
X = features[feature_cols]
y = features[<span class="st">"target_reg"</span>]  <span class="cm"># íšŒê·€ íƒ€ê²Ÿ: 5ì¼ í›„ ìˆ˜ìµë¥ </span>

<span class="cm"># ì‹œê°„ ê¸°ì¤€ ë¶„ë¦¬ (ê¸ˆìœµì—ì„œëŠ” ë°˜ë“œì‹œ ì‹œê°„ ìˆœì„œë¡œ!)</span>
split_date = <span class="st">"2024-01-01"</span>
X_train = X[X.index < split_date]
X_test = X[X.index >= split_date]
y_train = y[y.index < split_date]
y_test = y[y.index >= split_date]

<span class="fn">print</span>(<span class="st">f"Train: </span>{<span class="fn">len</span>(X_train)}<span class="st">í–‰, Test: </span>{<span class="fn">len</span>(X_test)}<span class="st">í–‰"</span>)
<span class="fn">print</span>(<span class="st">f"Train ê¸°ê°„: </span>{X_train.index[0].date()}<span class="st"> ~ </span>{X_train.index[-1].date()}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"Test ê¸°ê°„:  </span>{X_test.index[0].date()}<span class="st"> ~ </span>{X_test.index[-1].date()}<span class="st">"</span>)</code></pre>

<div class="warn">
<p class="ni"><strong>ê¸ˆìœµ MLì˜ ì² ì¹™: ì‹œê°„ ê¸°ì¤€ ë¶„ë¦¬!</strong> ì¼ë°˜ì ì¸ MLì—ì„œëŠ” <code>train_test_split(shuffle=True)</code>ë¡œ ëœë¤í•˜ê²Œ ë‚˜ëˆˆë‹¤. í•˜ì§€ë§Œ ê¸ˆìœµì—ì„œëŠ” ì ˆëŒ€ ì…”í”Œí•˜ë©´ ì•ˆ ëœë‹¤. 2024ë…„ ë°ì´í„°ë¡œ í•™ìŠµí•˜ê³  2023ë…„ì„ ì˜ˆì¸¡í•˜ë©´ ë¯¸ë˜ ì •ë³´ ëˆ„ì¶œì´ë‹¤. ë°˜ë“œì‹œ "ê³¼ê±°ë¡œ í•™ìŠµ â†’ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡" ìˆœì„œë¥¼ ì§€ì¼œì•¼ í•œë‹¤. MLAT Ch.7ì—ì„œë„ ì´ ì ì„ ê°•ì¡°í•œë‹¤.</p>
</div>

<pre><code><span class="cm"># === ë°©ë²• 1: statsmodels â€” í†µê³„ì  ì¶”ë¡ ì— ê°•ì  ===</span>
<span class="cm"># ìƒìˆ˜í•­(ì ˆí¸) ì¶”ê°€</span>
X_train_sm = sm.add_constant(X_train)
X_test_sm = sm.add_constant(X_test)

<span class="cm"># OLS í•™ìŠµ</span>
model_sm = sm.OLS(y_train, X_train_sm).fit()
<span class="fn">print</span>(model_sm.summary())
<span class="cm"># â†’ RÂ², ê° ê³„ìˆ˜ì˜ p-value, t-í†µê³„ëŸ‰, F-í†µê³„ëŸ‰ ë“± ìƒì„¸ í†µê³„ ì¶œë ¥</span>
<span class="cm"># â†’ MLAT Ch.7 Figure 7.2ì™€ ë™ì¼í•œ í˜•íƒœì˜ OLS Regression Results</span></code></pre>

<pre><code><span class="cm"># === ë°©ë²• 2: sklearn â€” ì˜ˆì¸¡ì— ê°•ì  ===</span>
model_sk = LinearRegression()
model_sk.fit(X_train, y_train)

<span class="cm"># ì˜ˆì¸¡</span>
y_pred_train = model_sk.predict(X_train)
y_pred_test = model_sk.predict(X_test)

<span class="cm"># í‰ê°€</span>
<span class="fn">print</span>(<span class="st">"=== ì„ í˜•íšŒê·€ ì„±ëŠ¥ ==="</span>)
<span class="fn">print</span>(<span class="st">f"Train MSE: </span>{mean_squared_error(y_train, y_pred_train):.6f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"Test MSE:  </span>{mean_squared_error(y_test, y_pred_test):.6f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"Train RÂ²:  </span>{r2_score(y_train, y_pred_train):.4f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"Test RÂ²:   </span>{r2_score(y_test, y_pred_test):.4f}<span class="st">"</span>)

<span class="cm"># ê³„ìˆ˜ í•´ì„</span>
<span class="fn">print</span>(<span class="st">"\n=== ê³„ìˆ˜ (Coefficients) ==="</span>)
<span class="kw">for</span> name, coef <span class="kw">in</span> <span class="fn">zip</span>(feature_cols, model_sk.coef_):
    <span class="fn">print</span>(<span class="st">f"  </span>{name:12s}<span class="st">: </span>{coef:+.4f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"  </span>{<span class="st">'intercept'</span>:12s}<span class="st">: </span>{model_sk.intercept_:+.4f}<span class="st">"</span>)</code></pre>

<div class="info">
<p class="ni"><strong>ê³„ìˆ˜ í•´ì„ ì˜ˆì‹œ:</strong> <code>ret_5d</code>ì˜ ê³„ìˆ˜ê°€ +0.15ë¼ë©´, "ìµœê·¼ 5ì¼ ìˆ˜ìµë¥ ì´ 1%p ë†’ì„ ë•Œ, í–¥í›„ 5ì¼ ìˆ˜ìµë¥ ì´ 0.15%p ë†’ì„ ê²ƒìœ¼ë¡œ ì˜ˆì¸¡í•œë‹¤"ëŠ” ëœ»ì´ë‹¤. ì´ê²ƒì€ ëª¨ë©˜í…€ íš¨ê³¼ë¥¼ í¬ì°©í•œ ê²ƒì´ë‹¤. ë°˜ëŒ€ë¡œ <code>rsi</code>ì˜ ê³„ìˆ˜ê°€ ìŒìˆ˜ë¼ë©´, RSIê°€ ë†’ì„ìˆ˜ë¡(ê³¼ë§¤ìˆ˜) í–¥í›„ ìˆ˜ìµë¥ ì´ ë‚®ì„ ê²ƒìœ¼ë¡œ ì˜ˆì¸¡í•œë‹¤ëŠ” ëœ»ì´ë‹¤ â€” í‰ê· íšŒê·€ íš¨ê³¼ë‹¤.</p>
</div>

<h3>3.4 ì„ í˜•íšŒê·€ì˜ ê°€ì •ê³¼ í•œê³„</h3>
<p>OLSê°€ ìµœì ì˜ ì¶”ì •ëŸ‰(BLUE, Best Linear Unbiased Estimator)ì´ ë˜ë ¤ë©´ Gauss-Markov ê°€ì •ì´ ì¶©ì¡±ë˜ì–´ì•¼ í•œë‹¤. MLAT Ch.7ì—ì„œ ìƒì„¸íˆ ë‹¤ë£¨ëŠ” ì´ ê°€ì •ë“¤ì„ ê¸ˆìœµ ë§¥ë½ì—ì„œ ì‚´í´ë³´ì:</p>

<div class="tc">Table 3. Gauss-Markov ê°€ì •ê³¼ ê¸ˆìœµì—ì„œì˜ ìœ„ë°˜ ì‚¬ë¡€</div>
<table>
<tr><th>ê°€ì •</th><th>ë‚´ìš©</th><th>ê¸ˆìœµì—ì„œ ìœ„ë°˜ ì‚¬ë¡€</th><th>í•´ê²°ì±…</th></tr>
<tr><td>ì„ í˜•ì„±</td><td>Xì™€ yì˜ ê´€ê³„ê°€ ì„ í˜•</td><td>RSI 30 ì´í•˜/70 ì´ìƒì—ì„œ ë¹„ì„ í˜• ë°˜ì‘</td><td>ë‹¤í•­ í”¼ì²˜, íŠ¸ë¦¬ ëª¨ë¸</td></tr>
<tr><td>ë…ë¦½ì„±</td><td>ì”ì°¨ê°€ ì„œë¡œ ë…ë¦½</td><td>ì‹œê³„ì—´ ìê¸°ìƒê´€ (ì˜¤ëŠ˜ ì”ì°¨ â†’ ë‚´ì¼ ì”ì°¨)</td><td>Newey-West í‘œì¤€ì˜¤ì°¨</td></tr>
<tr><td>ë“±ë¶„ì‚°ì„±</td><td>ì”ì°¨ì˜ ë¶„ì‚°ì´ ì¼ì •</td><td>ë³€ë™ì„± í´ëŸ¬ìŠ¤í„°ë§ (ìœ„ê¸° ì‹œ ì”ì°¨ ê¸‰ì¦)</td><td>Robust í‘œì¤€ì˜¤ì°¨, GARCH</td></tr>
<tr><td>ì •ê·œì„±</td><td>ì”ì°¨ê°€ ì •ê·œë¶„í¬</td><td>ê¸ˆìœµ ìˆ˜ìµë¥ ì˜ íŒ»í…Œì¼</td><td>ëŒ€í‘œë³¸ì—ì„œ ê·¼ì‚¬ì  ì„±ë¦½</td></tr>
<tr><td>ë‹¤ì¤‘ê³µì„ ì„± ì—†ìŒ</td><td>í”¼ì²˜ ê°„ ë†’ì€ ìƒê´€ ì—†ìŒ</td><td>RSIì™€ ëª¨ë©˜í…€ì˜ ë†’ì€ ìƒê´€</td><td>VIF ì²´í¬, PCA, ì •ê·œí™”</td></tr>
</table>

<p>ê¸ˆìœµ ë°ì´í„°ëŠ” ì´ ê°€ì •ë“¤ì„ ê±°ì˜ í•­ìƒ ìœ„ë°˜í•œë‹¤. ê·¸ë˜ì„œ ì„ í˜•íšŒê·€ë§Œìœ¼ë¡œëŠ” í•œê³„ê°€ ìˆê³ , ì •ê·œí™”(Ridge/Lasso)ë‚˜ ë¹„ì„ í˜• ëª¨ë¸(íŠ¸ë¦¬, ì•™ìƒë¸”)ì´ í•„ìš”í•˜ë‹¤.</p>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- Ch4: Ridge / Lasso ì •ê·œí™” -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2 id="ch4">4. Ridge / Lasso ì •ê·œí™” â€” ê³¼ì í•©ì„ ë§‰ëŠ” ë²Œì¹™</h2>

<h3>4.1 ì™œ ì •ê·œí™”ê°€ í•„ìš”í•œê°€</h3>
<p>í”¼ì²˜ê°€ ë§ì•„ì§€ë©´ ì„ í˜•íšŒê·€ëŠ” í•™ìŠµ ë°ì´í„°ì— ê³¼ì í•©(overfitting)ë˜ê¸° ì‰½ë‹¤. ê³„ìˆ˜ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ì»¤ì§€ë©´ì„œ í•™ìŠµ ë°ì´í„°ì˜ ë…¸ì´ì¦ˆê¹Œì§€ "í•™ìŠµ"í•´ë²„ë¦°ë‹¤. ì •ê·œí™”(Regularization)ëŠ” ê³„ìˆ˜ì˜ í¬ê¸°ì— ë²Œì¹™(penalty)ì„ ë¶€ê³¼í•˜ì—¬ ì´ë¥¼ ë°©ì§€í•œë‹¤. MLAT Ch.7 "Regularizing linear regression using shrinkage" ì„¹ì…˜ì—ì„œ ì´ ê°œë…ì„ ìƒì„¸íˆ ë‹¤ë£¬ë‹¤.</p>

<p>ì§ê´€ì ìœ¼ë¡œ ì´í•´í•˜ì: ê³„ìˆ˜ê°€ í¬ë‹¤ = ëª¨ë¸ì´ ë³µì¡í•˜ë‹¤ = ê³¼ì í•© ìœ„í—˜ì´ ë†’ë‹¤. ì •ê·œí™”ëŠ” "ê³„ìˆ˜ë¥¼ ì‘ê²Œ ìœ ì§€í•˜ë¼"ëŠ” ì œì•½ì„ ì¶”ê°€í•˜ì—¬ ëª¨ë¸ì„ ë‹¨ìˆœí•˜ê²Œ ë§Œë“ ë‹¤.</p>

<h3>4.2 Ridge íšŒê·€ (L2 ì •ê·œí™”)</h3>
<p>Ridge íšŒê·€ëŠ” OLS ì†ì‹¤í•¨ìˆ˜ì— ê³„ìˆ˜ì˜ ì œê³±í•©(L2 norm)ì„ ë²Œì¹™ìœ¼ë¡œ ì¶”ê°€í•œë‹¤.</p>

<div class="eq">\[ \text{Loss}_{\text{Ridge}} = \sum_{i=1}^{n}(y_i - \hat{y}_i)^2 + \lambda \sum_{j=1}^{p} \beta_j^2 \]</div>

<p>\(\lambda\)(ëŒë‹¤)ëŠ” ì •ê·œí™” ê°•ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ë‹¤. \(\lambda = 0\)ì´ë©´ ì¼ë°˜ OLSì™€ ë™ì¼í•˜ê³ , \(\lambda\)ê°€ ì»¤ì§ˆìˆ˜ë¡ ê³„ìˆ˜ê°€ 0ì— ê°€ê¹Œì›Œì§„ë‹¤. RidgeëŠ” ëª¨ë“  ê³„ìˆ˜ë¥¼ ê· ë“±í•˜ê²Œ ì¶•ì†Œ(shrink)í•˜ì§€ë§Œ, ì •í™•íˆ 0ìœ¼ë¡œ ë§Œë“¤ì§€ëŠ” ì•ŠëŠ”ë‹¤.</p>

<h3>4.3 Lasso íšŒê·€ (L1 ì •ê·œí™”)</h3>
<p>LassoëŠ” ê³„ìˆ˜ì˜ ì ˆëŒ€ê°’ í•©(L1 norm)ì„ ë²Œì¹™ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.</p>

<div class="eq">\[ \text{Loss}_{\text{Lasso}} = \sum_{i=1}^{n}(y_i - \hat{y}_i)^2 + \lambda \sum_{j=1}^{p} |\beta_j| \]</div>

<p>Lassoì˜ í•µì‹¬ íŠ¹ì„±: ì¼ë¶€ ê³„ìˆ˜ë¥¼ ì •í™•íˆ 0ìœ¼ë¡œ ë§Œë“ ë‹¤. ì¦‰, ìë™ìœ¼ë¡œ í”¼ì²˜ ì„ íƒ(feature selection)ì„ ìˆ˜í–‰í•œë‹¤. 20ê°œ í”¼ì²˜ ì¤‘ ì‹¤ì œë¡œ ìœ ìš©í•œ 5ê°œë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ 15ê°œì˜ ê³„ìˆ˜ë¥¼ 0ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆë‹¤. ì´ê²ƒì´ Ridgeì™€ì˜ ê°€ì¥ í° ì°¨ì´ë‹¤.</p>

<div class="def">
<p class="ni"><strong>Ridge vs Lasso í•µì‹¬ ì°¨ì´</strong></p>
<ul>
<li><strong>Ridge (L2):</strong> ëª¨ë“  ê³„ìˆ˜ë¥¼ ì‘ê²Œ ë§Œë“ ë‹¤. í”¼ì²˜ë¥¼ ì œê±°í•˜ì§€ ì•ŠëŠ”ë‹¤. ë‹¤ì¤‘ê³µì„ ì„±ì— ê°•í•˜ë‹¤.</li>
<li><strong>Lasso (L1):</strong> ì¼ë¶€ ê³„ìˆ˜ë¥¼ 0ìœ¼ë¡œ ë§Œë“ ë‹¤ (í”¼ì²˜ ì„ íƒ). í•´ì„ì´ ì‰½ë‹¤. í”¼ì²˜ê°€ ë§ì„ ë•Œ ìœ ë¦¬í•˜ë‹¤.</li>
<li><strong>Elastic Net:</strong> Ridge + Lassoë¥¼ ê²°í•©. ë‘ ë²Œì¹™ì„ ë™ì‹œì— ì‚¬ìš©í•œë‹¤.</li>
</ul>
</div>

<h3>4.4 íŒŒì´ì¬ìœ¼ë¡œ Ridge/Lasso êµ¬í˜„</h3>

<pre><code><span class="cm"># === Ridge / Lasso / Elastic Net ë¹„êµ ===</span>
<span class="kw">from</span> sklearn.linear_model <span class="kw">import</span> Ridge, Lasso, ElasticNet
<span class="kw">from</span> sklearn.preprocessing <span class="kw">import</span> StandardScaler
<span class="kw">from</span> sklearn.metrics <span class="kw">import</span> mean_squared_error

<span class="cm"># ìŠ¤ì¼€ì¼ë§ (ì •ê·œí™” ëª¨ë¸ì—ì„œëŠ” í•„ìˆ˜!)</span>
scaler = StandardScaler()
X_train_s = scaler.fit_transform(X_train)
X_test_s = scaler.transform(X_test)

<span class="cm"># ì—¬ëŸ¬ ëª¨ë¸ ë¹„êµ</span>
models = {
    <span class="st">"OLS"</span>: LinearRegression(),
    <span class="st">"Ridge(Î±=0.1)"</span>: Ridge(alpha=<span class="nu">0.1</span>),
    <span class="st">"Ridge(Î±=1.0)"</span>: Ridge(alpha=<span class="nu">1.0</span>),
    <span class="st">"Ridge(Î±=10)"</span>: Ridge(alpha=<span class="nu">10</span>),
    <span class="st">"Lasso(Î±=0.001)"</span>: Lasso(alpha=<span class="nu">0.001</span>),
    <span class="st">"Lasso(Î±=0.01)"</span>: Lasso(alpha=<span class="nu">0.01</span>),
    <span class="st">"ElasticNet"</span>: ElasticNet(alpha=<span class="nu">0.01</span>, l1_ratio=<span class="nu">0.5</span>),
}

<span class="fn">print</span>(<span class="st">"=== ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ ==="</span>)
<span class="fn">print</span>(<span class="st">f"</span>{<span class="st">'ëª¨ë¸'</span>:20s} {<span class="st">'Train MSE'</span>:>12s} {<span class="st">'Test MSE'</span>:>12s} {<span class="st">'ë¹„ì˜ ê³„ìˆ˜'</span>:>10s}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">"-"</span> * <span class="nu">58</span>)

<span class="kw">for</span> name, model <span class="kw">in</span> models.items():
    model.fit(X_train_s, y_train)
    train_mse = mean_squared_error(y_train, model.predict(X_train_s))
    test_mse = mean_squared_error(y_test, model.predict(X_test_s))
    n_nonzero = np.sum(np.abs(model.coef_) > <span class="nu">1e-6</span>)
    <span class="fn">print</span>(<span class="st">f"</span>{name:20s} {train_mse:12.6f} {test_mse:12.6f} {n_nonzero:10d}<span class="st">"</span>)</code></pre>

<pre><code><span class="cm"># ê³„ìˆ˜ ë¹„êµ ì‹œê°í™”</span>
<span class="kw">import</span> matplotlib.pyplot <span class="kw">as</span> plt

fig, ax = plt.subplots(figsize=(<span class="nu">12</span>, <span class="nu">5</span>))
x_pos = np.arange(<span class="fn">len</span>(feature_cols))
width = <span class="nu">0.15</span>

<span class="kw">for</span> i, (name, model) <span class="kw">in</span> <span class="fn">enumerate</span>([
    (<span class="st">"OLS"</span>, models[<span class="st">"OLS"</span>]),
    (<span class="st">"Ridge(1.0)"</span>, models[<span class="st">"Ridge(Î±=1.0)"</span>]),
    (<span class="st">"Lasso(0.01)"</span>, models[<span class="st">"Lasso(Î±=0.01)"</span>]),
]):
    ax.bar(x_pos + i * width, model.coef_, width, label=name, alpha=<span class="nu">0.8</span>)

ax.set_xticks(x_pos + width)
ax.set_xticklabels(feature_cols, rotation=<span class="nu">45</span>)
ax.set_ylabel(<span class="st">"ê³„ìˆ˜ í¬ê¸°"</span>)
ax.set_title(<span class="st">"OLS vs Ridge vs Lasso ê³„ìˆ˜ ë¹„êµ"</span>)
ax.legend()
ax.grid(<span class="kw">True</span>, alpha=<span class="nu">0.3</span>)
ax.axhline(y=<span class="nu">0</span>, color=<span class="st">"black"</span>, linewidth=<span class="nu">0.5</span>)
plt.tight_layout()
plt.show()</code></pre>

<div class="info">
<p class="ni"><strong>êµì¬ ì—°ë™:</strong> MLAT Ch.7 "How ridge regression works"ì™€ "How lasso regression works" ì„¹ì…˜ì—ì„œ Ridge/Lassoì˜ ê¸°í•˜í•™ì  í•´ì„(ì œì•½ ì˜ì—­ì˜ ëª¨ì–‘)ê³¼ í•´ ê²½ë¡œ(solution path)ë¥¼ ì‹œê°ì ìœ¼ë¡œ ì„¤ëª…í•œë‹¤. Ridgeì˜ ì œì•½ ì˜ì—­ì€ ì›(circle)ì´ê³ , LassoëŠ” ë‹¤ì´ì•„ëª¬ë“œ(diamond)ë‹¤. ë‹¤ì´ì•„ëª¬ë“œì˜ ê¼­ì§“ì ì—ì„œ í•´ê°€ ë§Œë‚˜ë©´ ì¼ë¶€ ê³„ìˆ˜ê°€ ì •í™•íˆ 0ì´ ëœë‹¤ â€” ì´ê²ƒì´ Lassoì˜ í”¼ì²˜ ì„ íƒ ì›ë¦¬ë‹¤.</p>
</div>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- Ch5: ë¡œì§€ìŠ¤í‹± íšŒê·€ -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2 id="ch5">5. ë¡œì§€ìŠ¤í‹± íšŒê·€ â€” í™•ë¥ ë¡œ ë¶„ë¥˜í•˜ê¸°</h2>

<h3>5.1 ì™œ ì„ í˜•íšŒê·€ë¡œ ë¶„ë¥˜í•˜ë©´ ì•ˆ ë˜ëŠ”ê°€</h3>
<p>ìƒìŠ¹(1)/í•˜ë½(0)ì„ ì˜ˆì¸¡í•˜ê³  ì‹¶ë‹¤ë©´, ì„ í˜•íšŒê·€ë¥¼ ê·¸ëŒ€ë¡œ ì“°ë©´ ì•ˆ ë ê¹Œ? ì•ˆ ëœë‹¤. ì„ í˜•íšŒê·€ì˜ ì¶œë ¥ì€ -âˆ ~ +âˆ ë²”ìœ„ì¸ë°, í™•ë¥ ì€ 0 ~ 1 ë²”ìœ„ì—¬ì•¼ í•œë‹¤. ì„ í˜•íšŒê·€ë¡œ ë¶„ë¥˜í•˜ë©´ "ìƒìŠ¹ í™•ë¥  150%" ê°™ì€ ë§ë„ ì•ˆ ë˜ëŠ” ê²°ê³¼ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆë‹¤.</p>

<h3>5.2 ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ â€” ì‹¤ìˆ˜ë¥¼ í™•ë¥ ë¡œ ë³€í™˜</h3>
<p>ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ì„ í˜•íšŒê·€ì˜ ì¶œë ¥ì„ ì‹œê·¸ëª¨ì´ë“œ(sigmoid) í•¨ìˆ˜ì— í†µê³¼ì‹œì¼œ 0~1 ì‚¬ì´ì˜ í™•ë¥ ë¡œ ë³€í™˜í•œë‹¤.</p>

<div class="eq">\[ P(y=1|X) = \sigma(z) = \frac{1}{1 + e^{-z}}, \quad z = \beta_0 + \sum_{j=1}^{p} \beta_j x_j \]</div>

<p>ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ì˜ ì„±ì§ˆ: zê°€ ë§¤ìš° í¬ë©´ Ïƒ(z) â†’ 1 (í™•ì‹¤íˆ ìƒìŠ¹), zê°€ ë§¤ìš° ì‘ìœ¼ë©´ Ïƒ(z) â†’ 0 (í™•ì‹¤íˆ í•˜ë½), z = 0ì´ë©´ Ïƒ(z) = 0.5 (ë°˜ë°˜).</p>

<pre><code><span class="cm"># ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ ì‹œê°í™”</span>
<span class="kw">import</span> numpy <span class="kw">as</span> np
<span class="kw">import</span> matplotlib.pyplot <span class="kw">as</span> plt

z = np.linspace(-<span class="nu">6</span>, <span class="nu">6</span>, <span class="nu">200</span>)
sigmoid = <span class="nu">1</span> / (<span class="nu">1</span> + np.exp(-z))

fig, ax = plt.subplots(figsize=(<span class="nu">10</span>, <span class="nu">5</span>))
ax.plot(z, sigmoid, color=<span class="st">"navy"</span>, linewidth=<span class="nu">2</span>)
ax.axhline(y=<span class="nu">0.5</span>, color=<span class="st">"red"</span>, linestyle=<span class="st">"--"</span>, alpha=<span class="nu">0.5</span>, label=<span class="st">"ì„ê³„ê°’ 0.5"</span>)
ax.axvline(x=<span class="nu">0</span>, color=<span class="st">"gray"</span>, linestyle=<span class="st">":"</span>, alpha=<span class="nu">0.5</span>)
ax.fill_between(z, sigmoid, <span class="nu">0.5</span>, where=(sigmoid > <span class="nu">0.5</span>), alpha=<span class="nu">0.1</span>, color=<span class="st">"green"</span>, label=<span class="st">"ìƒìŠ¹ ì˜ˆì¸¡"</span>)
ax.fill_between(z, sigmoid, <span class="nu">0.5</span>, where=(sigmoid < <span class="nu">0.5</span>), alpha=<span class="nu">0.1</span>, color=<span class="st">"red"</span>, label=<span class="st">"í•˜ë½ ì˜ˆì¸¡"</span>)
ax.set_xlabel(<span class="st">"z (ì„ í˜• ê²°í•©)"</span>)
ax.set_ylabel(<span class="st">"Ïƒ(z) = P(ìƒìŠ¹)"</span>)
ax.set_title(<span class="st">"ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜: ì‹¤ìˆ˜ â†’ í™•ë¥ "</span>)
ax.legend()
ax.grid(<span class="kw">True</span>, alpha=<span class="nu">0.3</span>)
plt.tight_layout()
plt.show()</code></pre>

<h3>5.3 ë¡œì§€ìŠ¤í‹± íšŒê·€ë¡œ ì£¼ê°€ ë°©í–¥ ì˜ˆì¸¡</h3>

<pre><code><span class="cm"># === ë¡œì§€ìŠ¤í‹± íšŒê·€: ì£¼ê°€ ìƒìŠ¹/í•˜ë½ ë¶„ë¥˜ ===</span>
<span class="kw">from</span> sklearn.linear_model <span class="kw">import</span> LogisticRegression
<span class="kw">from</span> sklearn.metrics <span class="kw">import</span> accuracy_score, classification_report

<span class="cm"># ë¶„ë¥˜ íƒ€ê²Ÿ ì‚¬ìš©</span>
y_cls = features[<span class="st">"target_cls"</span>]
y_train_cls = y_cls[y_cls.index < split_date]
y_test_cls = y_cls[y_cls.index >= split_date]

<span class="cm"># ë¡œì§€ìŠ¤í‹± íšŒê·€ í•™ìŠµ</span>
log_reg = LogisticRegression(C=<span class="nu">1.0</span>, max_iter=<span class="nu">1000</span>)
log_reg.fit(X_train_s, y_train_cls)

<span class="cm"># ì˜ˆì¸¡: í´ë˜ìŠ¤ì™€ í™•ë¥ </span>
y_pred_cls = log_reg.predict(X_test_s)
y_pred_prob = log_reg.predict_proba(X_test_s)[:, <span class="nu">1</span>]  <span class="cm"># ìƒìŠ¹ í™•ë¥ </span>

<span class="fn">print</span>(<span class="st">"=== ë¡œì§€ìŠ¤í‹± íšŒê·€ ì„±ëŠ¥ ==="</span>)
<span class="fn">print</span>(<span class="st">f"ì •í™•ë„ (Accuracy): </span>{accuracy_score(y_test_cls, y_pred_cls):.4f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"\në¶„ë¥˜ ë¦¬í¬íŠ¸:"</span>)
<span class="fn">print</span>(classification_report(y_test_cls, y_pred_cls, target_names=[<span class="st">"í•˜ë½"</span>, <span class="st">"ìƒìŠ¹"</span>]))

<span class="cm"># ê³„ìˆ˜ í•´ì„</span>
<span class="fn">print</span>(<span class="st">"=== ê³„ìˆ˜ (ìƒìŠ¹ í™•ë¥ ì— ëŒ€í•œ ì˜í–¥) ==="</span>)
<span class="kw">for</span> name, coef <span class="kw">in</span> <span class="fn">zip</span>(feature_cols, log_reg.coef_[<span class="nu">0</span>]):
    direction = <span class="st">"â†‘ìƒìŠ¹"</span> <span class="kw">if</span> coef > <span class="nu">0</span> <span class="kw">else</span> <span class="st">"â†“í•˜ë½"</span>
    <span class="fn">print</span>(<span class="st">f"  </span>{name:12s}<span class="st">: </span>{coef:+.4f}<span class="st"> â†’ ì´ í”¼ì²˜â†‘ ì‹œ </span>{direction}<span class="st"> í™•ë¥ â†‘"</span>)</code></pre>

<div class="def">
<p class="ni"><strong>C íŒŒë¼ë¯¸í„°ì˜ ì˜ë¯¸:</strong> ë¡œì§€ìŠ¤í‹± íšŒê·€ì˜ <code>C</code>ëŠ” ì •ê·œí™” ê°•ë„ì˜ ì—­ìˆ˜ë‹¤. Cê°€ í¬ë©´ ì •ê·œí™”ê°€ ì•½í•˜ê³ (ë³µì¡í•œ ëª¨ë¸), Cê°€ ì‘ìœ¼ë©´ ì •ê·œí™”ê°€ ê°•í•˜ë‹¤(ë‹¨ìˆœí•œ ëª¨ë¸). Ridge/Lassoì˜ Î±ì™€ ë°˜ëŒ€ ë°©í–¥ì´ë¼ëŠ” ì ì— ì£¼ì˜í•˜ì. <code>C=1.0</code>ì´ ê¸°ë³¸ê°’ì´ë‹¤.</p>
</div>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- Ch6: ëª¨ë¸ í‰ê°€ ì§€í‘œ -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2 id="ch6">6. ëª¨ë¸ í‰ê°€ ì§€í‘œ â€” "ì´ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì¢‹ì€ê°€?"</h2>

<h3>6.1 íšŒê·€ í‰ê°€ ì§€í‘œ</h3>

<div class="tc">Table 4. íšŒê·€ ëª¨ë¸ í‰ê°€ ì§€í‘œ</div>
<table>
<tr><th>ì§€í‘œ</th><th>ìˆ˜ì‹</th><th>ë²”ìœ„</th><th>í•´ì„</th></tr>
<tr><td>MSE</td><td>\(\frac{1}{n}\sum(y_i - \hat{y}_i)^2\)</td><td>[0, âˆ)</td><td>ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ. í° ì˜¤ì°¨ì— ë¯¼ê°</td></tr>
<tr><td>RMSE</td><td>\(\sqrt{\text{MSE}}\)</td><td>[0, âˆ)</td><td>yì™€ ê°™ì€ ë‹¨ìœ„. í•´ì„ì´ ì§ê´€ì </td></tr>
<tr><td>MAE</td><td>\(\frac{1}{n}\sum|y_i - \hat{y}_i|\)</td><td>[0, âˆ)</td><td>ì´ìƒì¹˜ì— ëœ ë¯¼ê°</td></tr>
<tr><td>RÂ²</td><td>\(1 - \frac{\text{RSS}}{\text{TSS}}\)</td><td>(-âˆ, 1]</td><td>1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ. 0ì´ë©´ í‰ê·  ì˜ˆì¸¡ê³¼ ë™ì¼</td></tr>
</table>

<div class="warn">
<p class="ni"><strong>ê¸ˆìœµì—ì„œ RÂ²ì˜ í•¨ì •:</strong> ê¸ˆìœµ ìˆ˜ìµë¥  ì˜ˆì¸¡ì—ì„œ RÂ²ëŠ” ë³´í†µ 0.01~0.05 ìˆ˜ì¤€ì´ë‹¤. "ê²¨ìš° 1~5%ë°–ì— ì„¤ëª… ëª» í•˜ëŠ”ë° ì“¸ëª¨ê°€ ìˆë‚˜?"ë¼ê³  ìƒê°í•  ìˆ˜ ìˆì§€ë§Œ, ê¸ˆìœµì—ì„œëŠ” ì´ ì •ë„ë©´ ì¶©ë¶„íˆ ìˆ˜ìµì„ ë‚¼ ìˆ˜ ìˆë‹¤. ë§¤ì¼ 55%ì˜ í™•ë¥ ë¡œ ë°©í–¥ì„ ë§ì¶”ë©´ ì—°ê°„ ìƒë‹¹í•œ ìˆ˜ìµì´ ëœë‹¤. RÂ²ê°€ ë‚®ë‹¤ê³  ëª¨ë¸ì„ ë²„ë¦¬ì§€ ë§ì.</p>
</div>

<h3>6.2 ë¶„ë¥˜ í‰ê°€ ì§€í‘œ</h3>

<h4>í˜¼ë™í–‰ë ¬ (Confusion Matrix)</h4>
<p>ë¶„ë¥˜ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê°€ì¥ ìƒì„¸í•˜ê²Œ ë³´ì—¬ì£¼ëŠ” ë„êµ¬ë‹¤. 4ê°€ì§€ ê²½ìš°ë¥¼ êµ¬ë¶„í•œë‹¤:</p>

<!-- í˜¼ë™í–‰ë ¬ CSS ë‹¤ì´ì–´ê·¸ë¨ -->
<div style="margin:25px 0;padding:20px;background:#f8f9fa;border-radius:8px;border:1px solid #ddd">
<p class="ni" style="text-align:center;font-weight:bold;font-size:14px;margin-bottom:15px;color:#2c3e50">ğŸ“Š í˜¼ë™í–‰ë ¬ (Confusion Matrix)</p>
<div style="display:grid;grid-template-columns:80px 1fr 1fr;grid-template-rows:40px 1fr 1fr;gap:4px;max-width:400px;margin:0 auto;font-size:12px">
<div></div>
<div style="background:#2c3e50;color:#fff;padding:8px;text-align:center;border-radius:4px 4px 0 0;font-weight:bold">ì˜ˆì¸¡: ìƒìŠ¹</div>
<div style="background:#2c3e50;color:#fff;padding:8px;text-align:center;border-radius:4px 4px 0 0;font-weight:bold">ì˜ˆì¸¡: í•˜ë½</div>
<div style="background:#34495e;color:#fff;padding:8px;text-align:center;border-radius:4px 0 0 4px;font-weight:bold;writing-mode:horizontal-tb">ì‹¤ì œ: ìƒìŠ¹</div>
<div style="background:#d4edda;padding:12px;text-align:center;border-radius:0"><strong style="color:#155724">TP</strong><br>ì§„ì–‘ì„±<br><span style="font-size:10px;color:#555">"ìƒìŠ¹ ë§ì¶¤ âœ“"</span></div>
<div style="background:#f8d7da;padding:12px;text-align:center;border-radius:0"><strong style="color:#721c24">FN</strong><br>ìœ„ìŒì„±<br><span style="font-size:10px;color:#555">"ìƒìŠ¹ì¸ë° í•˜ë½ ì˜ˆì¸¡"</span></div>
<div style="background:#34495e;color:#fff;padding:8px;text-align:center;border-radius:4px 0 0 4px;font-weight:bold">ì‹¤ì œ: í•˜ë½</div>
<div style="background:#f8d7da;padding:12px;text-align:center;border-radius:0"><strong style="color:#721c24">FP</strong><br>ìœ„ì–‘ì„±<br><span style="font-size:10px;color:#555">"í•˜ë½ì¸ë° ìƒìŠ¹ ì˜ˆì¸¡"</span></div>
<div style="background:#d4edda;padding:12px;text-align:center;border-radius:0"><strong style="color:#155724">TN</strong><br>ì§„ìŒì„±<br><span style="font-size:10px;color:#555">"í•˜ë½ ë§ì¶¤ âœ“"</span></div>
</div>
</div>

<pre><code><span class="cm"># === í˜¼ë™í–‰ë ¬ê³¼ ë¶„ë¥˜ ì§€í‘œ ===</span>
<span class="kw">from</span> sklearn.metrics <span class="kw">import</span> (confusion_matrix, accuracy_score,
    precision_score, recall_score, f1_score, roc_auc_score, roc_curve)

<span class="cm"># í˜¼ë™í–‰ë ¬</span>
cm = confusion_matrix(y_test_cls, y_pred_cls)
<span class="fn">print</span>(<span class="st">"=== í˜¼ë™í–‰ë ¬ ==="</span>)
<span class="fn">print</span>(<span class="st">f"TN=</span>{cm[0,0]}<span class="st">, FP=</span>{cm[0,1]}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"FN=</span>{cm[1,0]}<span class="st">, TP=</span>{cm[1,1]}<span class="st">"</span>)

<span class="cm"># ì£¼ìš” ì§€í‘œ</span>
<span class="fn">print</span>(<span class="st">f"\nAccuracy:  </span>{accuracy_score(y_test_cls, y_pred_cls):.4f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"Precision: </span>{precision_score(y_test_cls, y_pred_cls):.4f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"Recall:    </span>{recall_score(y_test_cls, y_pred_cls):.4f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"F1 Score:  </span>{f1_score(y_test_cls, y_pred_cls):.4f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"AUC-ROC:   </span>{roc_auc_score(y_test_cls, y_pred_prob):.4f}<span class="st">"</span>)</code></pre>

<h4>AUC-ROC ê³¡ì„ </h4>
<p>AUC-ROCëŠ” ë¶„ë¥˜ ëª¨ë¸ì˜ ê°€ì¥ ì¤‘ìš”í•œ í‰ê°€ ì§€í‘œ ì¤‘ í•˜ë‚˜ë‹¤. ì„ê³„ê°’(threshold)ì„ ë³€í™”ì‹œí‚¤ë©´ì„œ True Positive Rate(ì¬í˜„ìœ¨)ê³¼ False Positive Rateì˜ ê´€ê³„ë¥¼ ê·¸ë¦° ê³¡ì„ ì´ë‹¤. AUC(Area Under Curve)ê°€ 1ì´ë©´ ì™„ë²½í•œ ë¶„ë¥˜, 0.5ë©´ ëœë¤ ì¶”ì¸¡ê³¼ ë™ì¼í•˜ë‹¤.</p>

<pre><code><span class="cm"># AUC-ROC ê³¡ì„  ì‹œê°í™”</span>
fpr, tpr, thresholds = roc_curve(y_test_cls, y_pred_prob)
auc = roc_auc_score(y_test_cls, y_pred_prob)

fig, ax = plt.subplots(figsize=(<span class="nu">8</span>, <span class="nu">6</span>))
ax.plot(fpr, tpr, color=<span class="st">"navy"</span>, linewidth=<span class="nu">2</span>, label=<span class="st">f"ë¡œì§€ìŠ¤í‹± íšŒê·€ (AUC = </span>{auc:.3f}<span class="st">)"</span>)
ax.plot([<span class="nu">0</span>, <span class="nu">1</span>], [<span class="nu">0</span>, <span class="nu">1</span>], color=<span class="st">"red"</span>, linestyle=<span class="st">"--"</span>, label=<span class="st">"ëœë¤ (AUC = 0.500)"</span>)
ax.set_xlabel(<span class="st">"False Positive Rate"</span>)
ax.set_ylabel(<span class="st">"True Positive Rate"</span>)
ax.set_title(<span class="st">"ROC Curve â€” ì£¼ê°€ ë°©í–¥ ì˜ˆì¸¡"</span>)
ax.legend(loc=<span class="st">"lower right"</span>)
ax.grid(<span class="kw">True</span>, alpha=<span class="nu">0.3</span>)
plt.tight_layout()
plt.show()</code></pre>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- Ch7: êµì°¨ê²€ì¦ê³¼ ê³¼ì í•© -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2 id="ch7">7. êµì°¨ê²€ì¦ê³¼ ê³¼ì í•© â€” MLì˜ ê°€ì¥ í° ì </h2>

<h3>7.1 ê³¼ì í•© (Overfitting) vs ê³¼ì†Œì í•© (Underfitting)</h3>
<p>ê³¼ì í•©ì€ ëª¨ë¸ì´ í•™ìŠµ ë°ì´í„°ì˜ ë…¸ì´ì¦ˆê¹Œì§€ "ì™¸ì›Œë²„ë¦¬ëŠ”" í˜„ìƒì´ë‹¤. í•™ìŠµ ë°ì´í„°ì—ì„œëŠ” ì„±ëŠ¥ì´ ì¢‹ì§€ë§Œ, ìƒˆë¡œìš´ ë°ì´í„°(í…ŒìŠ¤íŠ¸)ì—ì„œëŠ” ì„±ëŠ¥ì´ ê¸‰ë½í•œë‹¤. MLAT Ch.6ì—ì„œ ì´ê²ƒì„ bias-variance trade-offë¡œ ì„¤ëª…í•œë‹¤.</p>

<!-- ê³¼ì í•© ë‹¤ì´ì–´ê·¸ë¨ -->
<div style="margin:25px 0;padding:20px;background:#f8f9fa;border-radius:8px;border:1px solid #ddd">
<p class="ni" style="text-align:center;font-weight:bold;font-size:14px;margin-bottom:15px;color:#2c3e50">âš–ï¸ Bias-Variance Trade-off</p>
<div style="display:flex;gap:10px;justify-content:center;flex-wrap:wrap;font-size:12px">
<div style="flex:1;min-width:180px;background:#fde8e8;padding:15px;border-radius:8px;border:2px solid #e74c3c;text-align:center">
<div style="font-weight:bold;color:#e74c3c;font-size:13px;margin-bottom:6px">ê³¼ì†Œì í•© (Underfitting)</div>
<div style="font-size:11px;color:#555">High Bias, Low Variance</div>
<div style="margin:8px 0;font-size:24px">ğŸ“‰</div>
<div style="font-size:11px;color:#555">ëª¨ë¸ì´ ë„ˆë¬´ ë‹¨ìˆœ<br>Train âŒ Test âŒ</div>
<div style="margin-top:6px;background:#fff;padding:4px;border-radius:3px;font-size:10px">ì˜ˆ: í”¼ì²˜ 1ê°œë¡œ ì„ í˜•íšŒê·€</div>
</div>
<div style="flex:1;min-width:180px;background:#d4edda;padding:15px;border-radius:8px;border:2px solid #28a745;text-align:center">
<div style="font-weight:bold;color:#28a745;font-size:13px;margin-bottom:6px">ì ì ˆí•œ ì í•© âœ“</div>
<div style="font-size:11px;color:#555">Balanced Bias-Variance</div>
<div style="margin:8px 0;font-size:24px">âœ…</div>
<div style="font-size:11px;color:#555">ì¼ë°˜í™” ì„±ëŠ¥ ìµœì <br>Train âœ“ Test âœ“</div>
<div style="margin-top:6px;background:#fff;padding:4px;border-radius:3px;font-size:10px">ì˜ˆ: ì •ê·œí™”ëœ ëª¨ë¸, ì ì ˆí•œ íŠ¸ë¦¬ ê¹Šì´</div>
</div>
<div style="flex:1;min-width:180px;background:#fde8e8;padding:15px;border-radius:8px;border:2px solid #e74c3c;text-align:center">
<div style="font-weight:bold;color:#e74c3c;font-size:13px;margin-bottom:6px">ê³¼ì í•© (Overfitting)</div>
<div style="font-size:11px;color:#555">Low Bias, High Variance</div>
<div style="margin:8px 0;font-size:24px">ğŸ“ˆ</div>
<div style="font-size:11px;color:#555">ëª¨ë¸ì´ ë„ˆë¬´ ë³µì¡<br>Train âœ“ Test âŒ</div>
<div style="margin-top:6px;background:#fff;padding:4px;border-radius:3px;font-size:10px">ì˜ˆ: ê¹Šì´ ë¬´ì œí•œ ê²°ì • íŠ¸ë¦¬</div>
</div>
</div>
</div>

<h3>7.2 ê¸ˆìœµ ì‹œê³„ì—´ êµì°¨ê²€ì¦ â€” TimeSeriesSplit</h3>
<p>ì¼ë°˜ì ì¸ K-Fold êµì°¨ê²€ì¦ì€ ë°ì´í„°ë¥¼ ëœë¤í•˜ê²Œ ì„ì–´ì„œ ë‚˜ëˆˆë‹¤. í•˜ì§€ë§Œ ê¸ˆìœµ ì‹œê³„ì—´ì—ì„œëŠ” ì´ê²ƒì´ ë¯¸ë˜ ì •ë³´ ëˆ„ì¶œì„ ì¼ìœ¼í‚¨ë‹¤. ê¸ˆìœµì—ì„œëŠ” ë°˜ë“œì‹œ ì‹œê°„ ìˆœì„œë¥¼ ìœ ì§€í•˜ëŠ” êµì°¨ê²€ì¦ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤.</p>

<pre><code><span class="cm"># === ê¸ˆìœµ ì‹œê³„ì—´ êµì°¨ê²€ì¦ ===</span>
<span class="kw">from</span> sklearn.model_selection <span class="kw">import</span> TimeSeriesSplit, cross_val_score

<span class="cm"># TimeSeriesSplit: ì‹œê°„ ìˆœì„œë¥¼ ìœ ì§€í•˜ëŠ” êµì°¨ê²€ì¦</span>
tscv = TimeSeriesSplit(n_splits=<span class="nu">5</span>)

<span class="cm"># ê° foldì˜ êµ¬ì¡° í™•ì¸</span>
<span class="fn">print</span>(<span class="st">"=== TimeSeriesSplit êµ¬ì¡° ==="</span>)
<span class="kw">for</span> i, (train_idx, test_idx) <span class="kw">in</span> <span class="fn">enumerate</span>(tscv.split(X_train)):
    <span class="fn">print</span>(<span class="st">f"Fold </span>{i+1}<span class="st">: Train[</span>{train_idx[0]}<span class="st">:</span>{train_idx[-1]}<span class="st">] â†’ Test[</span>{test_idx[0]}<span class="st">:</span>{test_idx[-1]}<span class="st">]"</span>)
    <span class="fn">print</span>(<span class="st">f"        Train </span>{<span class="fn">len</span>(train_idx)}<span class="st">í–‰, Test </span>{<span class="fn">len</span>(test_idx)}<span class="st">í–‰"</span>)

<span class="cm"># êµì°¨ê²€ì¦ ì ìˆ˜</span>
scores = cross_val_score(
    LogisticRegression(C=<span class="nu">1.0</span>, max_iter=<span class="nu">1000</span>),
    scaler.fit_transform(X_train),
    y_train_cls,
    cv=tscv,
    scoring=<span class="st">"roc_auc"</span>
)
<span class="fn">print</span>(<span class="st">f"\n=== êµì°¨ê²€ì¦ AUC-ROC ==="</span>)
<span class="fn">print</span>(<span class="st">f"ê° Fold: </span>{scores.round(4)}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"í‰ê· : </span>{scores.mean():.4f}<span class="st"> Â± </span>{scores.std():.4f}<span class="st">"</span>)</code></pre>

<div class="info">
<p class="ni"><strong>êµì¬ ì—°ë™:</strong> MLAT Ch.6 "How to select a model using cross-validation"ì—ì„œ êµì°¨ê²€ì¦ì˜ ë‹¤ì–‘í•œ ë³€í˜•ì„ ë‹¤ë£¬ë‹¤. íŠ¹íˆ ê¸ˆìœµì—ì„œëŠ” Purged K-Fold CV(í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì‚¬ì´ì— ê°­ì„ ë‘ì–´ ì •ë³´ ëˆ„ì¶œ ë°©ì§€)ê°€ ë” ì—„ê²©í•œ ë°©ë²•ì´ë‹¤. MLAT Ch.7ì—ì„œëŠ” GridSearchCVë¥¼ ì‚¬ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì˜ˆì œë¥¼ ì œê³µí•œë‹¤.</p>
</div>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- Ch8: ê²°ì • íŠ¸ë¦¬ -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2 id="ch8">8. ê²°ì • íŠ¸ë¦¬ â€” ë¹„ì„ í˜• ê´€ê³„ë¥¼ í¬ì°©í•˜ë‹¤</h2>

<h3>8.1 ê²°ì • íŠ¸ë¦¬ë€?</h3>
<p>ê²°ì • íŠ¸ë¦¬(Decision Tree)ëŠ” ë°ì´í„°ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì´ë‹¤. "RSIê°€ 30 ì´í•˜ì¸ê°€?" â†’ "ì˜ˆ" â†’ "5ì¼ ëª¨ë©˜í…€ì´ ì–‘ìˆ˜ì¸ê°€?" â†’ "ì˜ˆ" â†’ "ìƒìŠ¹ ì˜ˆì¸¡" ê°™ì€ if-else ê·œì¹™ì˜ íŠ¸ë¦¬ êµ¬ì¡°ë¥¼ ìë™ìœ¼ë¡œ í•™ìŠµí•œë‹¤. MLAT Ch.11ì—ì„œ "Decision trees learn rules from data that encode nonlinear relationships"ë¼ê³  ì„¤ëª…í•˜ë“¯, ì„ í˜• ëª¨ë¸ì´ í¬ì°©í•˜ì§€ ëª»í•˜ëŠ” ë¹„ì„ í˜• íŒ¨í„´ì„ ì¡ì•„ë‚¼ ìˆ˜ ìˆë‹¤.</p>

<!-- ê²°ì • íŠ¸ë¦¬ êµ¬ì¡° CSS ë‹¤ì´ì–´ê·¸ë¨ -->
<div style="margin:25px 0;padding:20px;background:linear-gradient(135deg,#f8f9fa,#e8f0e8);border-radius:10px;border:1px solid #ccc">
<p class="ni" style="text-align:center;font-weight:bold;font-size:14px;margin-bottom:15px;color:#2c3e50">ğŸŒ³ ê²°ì • íŠ¸ë¦¬ êµ¬ì¡° ì˜ˆì‹œ</p>
<div style="display:flex;flex-direction:column;align-items:center;gap:8px;font-size:12px">
<div style="background:#3498db;color:#fff;padding:10px 20px;border-radius:8px;font-weight:bold">RSI â‰¤ 30?</div>
<div style="display:flex;gap:60px">
<div style="text-align:center;color:#27ae60;font-weight:bold">Yes â†™</div>
<div style="text-align:center;color:#e74c3c;font-weight:bold">â†˜ No</div>
</div>
<div style="display:flex;gap:20px">
<div style="background:#e67e22;color:#fff;padding:8px 16px;border-radius:8px">ëª¨ë©˜í…€ > 0?</div>
<div style="background:#e67e22;color:#fff;padding:8px 16px;border-radius:8px">ë³€ë™ì„± > 0.3?</div>
</div>
<div style="display:flex;gap:10px;flex-wrap:wrap;justify-content:center">
<div style="background:#27ae60;color:#fff;padding:6px 12px;border-radius:4px;font-size:11px">ğŸ“ˆ ìƒìŠ¹ (68%)</div>
<div style="background:#e74c3c;color:#fff;padding:6px 12px;border-radius:4px;font-size:11px">ğŸ“‰ í•˜ë½ (55%)</div>
<div style="background:#e74c3c;color:#fff;padding:6px 12px;border-radius:4px;font-size:11px">ğŸ“‰ í•˜ë½ (62%)</div>
<div style="background:#27ae60;color:#fff;padding:6px 12px;border-radius:4px;font-size:11px">ğŸ“ˆ ìƒìŠ¹ (51%)</div>
</div>
</div>
</div>

<h3>8.2 ë¶„í•  ê¸°ì¤€: Gini vs Entropy</h3>
<p>ê²°ì • íŠ¸ë¦¬ëŠ” ë°ì´í„°ë¥¼ ë¶„í• í•  ë•Œ "ì–´ë–¤ í”¼ì²˜ì˜ ì–´ë–¤ ê°’ìœ¼ë¡œ ë‚˜ëˆ„ë©´ ê°€ì¥ ìˆœìˆ˜í•œ(homogeneous) ê·¸ë£¹ì´ ë§Œë“¤ì–´ì§€ëŠ”ê°€"ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•œë‹¤. ì—¬ê¸°ì„œ "ìˆœìˆ˜í•˜ë‹¤"ëŠ” ê²ƒì€ í•œ ê·¸ë£¹ ì•ˆì— ê°™ì€ í´ë˜ìŠ¤(ì˜ˆ: ìƒìŠ¹ë§Œ, ë˜ëŠ” í•˜ë½ë§Œ)ê°€ ëª¨ì—¬ ìˆë‹¤ëŠ” ëœ»ì´ë‹¤. ì´ ìˆœìˆ˜ë„ë¥¼ ì¸¡ì •í•˜ëŠ” ë°©ë²•ì´ ë‘ ê°€ì§€ ìˆë‹¤: Gini ë¶ˆìˆœë„ì™€ Entropy.</p>

<h4>ë¶ˆìˆœë„(Impurity)ë€? â€” ì§ê´€ì  ë¹„ìœ </h4>
<p>êµì‹¤ì— í•™ìƒ 100ëª…ì´ ìˆë‹¤ê³  í•˜ì. ì „ì›ì´ ë‚¨í•™ìƒì´ë©´ "ìˆœìˆ˜í•œ" ê·¸ë£¹ì´ë‹¤ â€” ëˆ„ê°€ ë‚¨í•™ìƒì¸ì§€ ë§ì¶”ê¸° ì‰½ë‹¤. ë°˜ë©´ ë‚¨ë…€ê°€ 50:50ì´ë©´ "ë¶ˆìˆœí•œ" ê·¸ë£¹ì´ë‹¤ â€” ëœë¤ìœ¼ë¡œ ì°ì–´ë„ 50%ë°–ì— ëª» ë§ì¶˜ë‹¤. ë¶ˆìˆœë„ëŠ” ì´ "ë’¤ì„ì¸ ì •ë„"ë¥¼ ìˆ«ìë¡œ í‘œí˜„í•œ ê²ƒì´ë‹¤. ê²°ì • íŠ¸ë¦¬ëŠ” ë¶„í•  í›„ ë¶ˆìˆœë„ê°€ ìµœëŒ€í•œ ì¤„ì–´ë“œëŠ” ë°©í–¥ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë‚˜ëˆˆë‹¤.</p>

<h4>Gini ë¶ˆìˆœë„ (Gini Impurity)</h4>
<div class="eq">\[ \text{Gini}(S) = 1 - \sum_{k=1}^{K} p_k^2 \]</div>
<p class="ni">ì—¬ê¸°ì„œ \(p_k\)ëŠ” ê·¸ë£¹ \(S\) ì•ˆì—ì„œ í´ë˜ìŠ¤ \(k\)ì˜ ë¹„ìœ¨ì´ë‹¤. ì§ê´€ì  ì˜ë¯¸: "ì´ ê·¸ë£¹ì—ì„œ ëœë¤ìœ¼ë¡œ ìƒ˜í”Œ í•˜ë‚˜ë¥¼ ë½‘ê³ , ë‹¤ì‹œ ëœë¤ìœ¼ë¡œ í´ë˜ìŠ¤ë¥¼ ë°°ì •í–ˆì„ ë•Œ, í‹€ë¦´ í™•ë¥ "ì´ë‹¤.</p>

<div class="def">
<p class="ni"><strong>Gini ê³„ì‚° ì˜ˆì‹œ (ì´ì§„ ë¶„ë¥˜: ìƒìŠ¹/í•˜ë½)</strong></p>
<ul>
<li><strong>ì™„ì „ ìˆœìˆ˜:</strong> ìƒìŠ¹ 100%, í•˜ë½ 0% â†’ Gini = \(1 - (1.0^2 + 0.0^2) = 0\) â†’ ë¶ˆìˆœë„ 0 (ìµœì†Œ)</li>
<li><strong>ì™„ì „ ë¶ˆìˆœ:</strong> ìƒìŠ¹ 50%, í•˜ë½ 50% â†’ Gini = \(1 - (0.5^2 + 0.5^2) = 1 - 0.5 = 0.5\) â†’ ë¶ˆìˆœë„ ìµœëŒ€</li>
<li><strong>ì•½ê°„ ì¹˜ìš°ì¹¨:</strong> ìƒìŠ¹ 70%, í•˜ë½ 30% â†’ Gini = \(1 - (0.7^2 + 0.3^2) = 1 - 0.58 = 0.42\)</li>
<li><strong>ë§ì´ ì¹˜ìš°ì¹¨:</strong> ìƒìŠ¹ 90%, í•˜ë½ 10% â†’ Gini = \(1 - (0.9^2 + 0.1^2) = 1 - 0.82 = 0.18\)</li>
</ul>
<p class="ni">Gini ê°’ì´ 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìˆœìˆ˜í•˜ê³ , 0.5ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë’¤ì„ì—¬ ìˆë‹¤.</p>
</div>

<h4>Entropy (ì—”íŠ¸ë¡œí”¼)</h4>
<div class="eq">\[ \text{Entropy}(S) = -\sum_{k=1}^{K} p_k \log_2 p_k \]</div>
<p class="ni">EntropyëŠ” ì •ë³´ì´ë¡ (Information Theory)ì—ì„œ ì˜¨ ê°œë…ì´ë‹¤. "ì´ ê·¸ë£¹ì˜ í´ë˜ìŠ¤ë¥¼ ì•Œì•„ë‚´ë ¤ë©´ í‰ê· ì ìœ¼ë¡œ ëª‡ ë¹„íŠ¸(bit)ì˜ ì •ë³´ê°€ í•„ìš”í•œê°€?"ë¥¼ ì¸¡ì •í•œë‹¤. ëª¨ë“  ìƒ˜í”Œì´ ê°™ì€ í´ë˜ìŠ¤ë©´ ì •ë³´ê°€ í•„ìš” ì—†ìœ¼ë¯€ë¡œ Entropy = 0ì´ë‹¤. ë°˜ë°˜ì´ë©´ 1ë¹„íŠ¸ê°€ í•„ìš”í•˜ë¯€ë¡œ Entropy = 1ì´ë‹¤.</p>

<div class="def">
<p class="ni"><strong>Entropy ê³„ì‚° ì˜ˆì‹œ (ì´ì§„ ë¶„ë¥˜: ìƒìŠ¹/í•˜ë½)</strong></p>
<ul>
<li><strong>ì™„ì „ ìˆœìˆ˜:</strong> ìƒìŠ¹ 100% â†’ Entropy = \(-1.0 \cdot \log_2(1.0) = 0\) â†’ ë¶ˆí™•ì‹¤ì„± 0</li>
<li><strong>ì™„ì „ ë¶ˆìˆœ:</strong> ìƒìŠ¹ 50%, í•˜ë½ 50% â†’ Entropy = \(-0.5 \cdot \log_2(0.5) - 0.5 \cdot \log_2(0.5) = 1.0\) â†’ ë¶ˆí™•ì‹¤ì„± ìµœëŒ€</li>
<li><strong>ì•½ê°„ ì¹˜ìš°ì¹¨:</strong> ìƒìŠ¹ 70%, í•˜ë½ 30% â†’ Entropy = \(-0.7 \cdot \log_2(0.7) - 0.3 \cdot \log_2(0.3) \approx 0.88\)</li>
<li><strong>ë§ì´ ì¹˜ìš°ì¹¨:</strong> ìƒìŠ¹ 90%, í•˜ë½ 10% â†’ Entropy â‰ˆ 0.47</li>
</ul>
<p class="ni">Entropy ê°’ì´ 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìˆœìˆ˜í•˜ê³ , 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë’¤ì„ì—¬ ìˆë‹¤ (ì´ì§„ ë¶„ë¥˜ ê¸°ì¤€).</p>
</div>

<h4>Information Gain â€” ë¶„í• ì˜ "ì´ë“"</h4>
<p>íŠ¸ë¦¬ê°€ ì‹¤ì œë¡œ ë¶„í• ì„ ê²°ì •í•  ë•ŒëŠ” ë¶ˆìˆœë„ ìì²´ê°€ ì•„ë‹ˆë¼, ë¶„í•  ì „í›„ì˜ ë¶ˆìˆœë„ ê°ì†ŒëŸ‰ì„ ë³¸ë‹¤. ì´ê²ƒì„ Information Gainì´ë¼ í•œë‹¤:</p>

<div class="eq">\[ \text{IG}(S, A) = \text{Impurity}(S) - \sum_{v \in \text{values}(A)} \frac{|S_v|}{|S|} \cdot \text{Impurity}(S_v) \]</div>

<p class="ni">ì¦‰, "ë¶„í•  ì „ ë¶ˆìˆœë„ âˆ’ ë¶„í•  í›„ ê°€ì¤‘ í‰ê·  ë¶ˆìˆœë„ = ì •ë³´ ì´ë“". íŠ¸ë¦¬ëŠ” ëª¨ë“  í”¼ì²˜ì˜ ëª¨ë“  ë¶„í• ì ì— ëŒ€í•´ IGë¥¼ ê³„ì‚°í•˜ê³ , IGê°€ ê°€ì¥ í° ë¶„í• ì„ ì„ íƒí•œë‹¤.</p>

<div class="info">
<p class="ni"><strong>êµ¬ì²´ì  ì˜ˆì‹œ: RSI â‰¤ 30ìœ¼ë¡œ ë¶„í• </strong></p>
<p class="ni">ì „ì²´ ë…¸ë“œ: ìƒìŠ¹ 50%, í•˜ë½ 50% â†’ Gini = 0.50</p>
<p class="ni">ë¶„í•  í›„:</p>
<ul>
<li>ì™¼ìª½ (RSI â‰¤ 30, 20%): ìƒìŠ¹ 75%, í•˜ë½ 25% â†’ Gini = \(1 - 0.75^2 - 0.25^2 = 0.375\)</li>
<li>ì˜¤ë¥¸ìª½ (RSI > 30, 80%): ìƒìŠ¹ 44%, í•˜ë½ 56% â†’ Gini = \(1 - 0.44^2 - 0.56^2 = 0.493\)</li>
</ul>
<p class="ni">ê°€ì¤‘ í‰ê·  Gini = \(0.2 \times 0.375 + 0.8 \times 0.493 = 0.469\)</p>
<p class="ni">Information Gain = \(0.500 - 0.469 = 0.031\)</p>
<p class="ni">íŠ¸ë¦¬ëŠ” ì´ ê°’ì„ ë‹¤ë¥¸ ëª¨ë“  ë¶„í•  í›„ë³´(ì˜ˆ: ëª¨ë©˜í…€ > 0, ë³€ë™ì„± > 0.3 ë“±)ì˜ IGì™€ ë¹„êµí•˜ì—¬ ê°€ì¥ í° ê²ƒì„ ì„ íƒí•œë‹¤.</p>
</div>

<h4>Gini vs Entropy â€” ì–´ë–¤ ê²ƒì„ ì“¸ê¹Œ?</h4>

<table>
<caption class="tc">Gini vs Entropy ë¹„êµ</caption>
<thead><tr><th>í•­ëª©</th><th>Gini ë¶ˆìˆœë„</th><th>Entropy</th></tr></thead>
<tbody>
<tr><td>ë²”ìœ„ (ì´ì§„)</td><td>0 ~ 0.5</td><td>0 ~ 1.0</td></tr>
<tr><td>ê³„ì‚° ë¹„ìš©</td><td>ë¹ ë¦„ (ì œê³±ë§Œ)</td><td>ëŠë¦¼ (ë¡œê·¸ ê³„ì‚°)</td></tr>
<tr><td>sklearn ê¸°ë³¸ê°’</td><td>âœ… criterion="gini"</td><td>criterion="entropy"</td></tr>
<tr><td>ì„±ëŠ¥ ì°¨ì´</td><td colspan="2" style="text-align:center">ì‹¤ì „ì—ì„œ ê±°ì˜ ë™ì¼ (2% ë¯¸ë§Œ ì°¨ì´)</td></tr>
<tr><td>ì§ê´€</td><td>"ëœë¤ ë°°ì • ì‹œ í‹€ë¦´ í™•ë¥ "</td><td>"í´ë˜ìŠ¤ë¥¼ ì•Œë ¤ë©´ í•„ìš”í•œ ì •ë³´ëŸ‰"</td></tr>
<tr><td>ë¯¼ê°ë„</td><td>ë¹ˆë„ ë†’ì€ í´ë˜ìŠ¤ì— ë¯¼ê°</td><td>í´ë˜ìŠ¤ ë¶„í¬ ë³€í™”ì— ë” ë¯¼ê°</td></tr>
</tbody>
</table>

<p>ê²°ë¡ : ëŒ€ë¶€ë¶„ì˜ ê²½ìš° Ginië¥¼ ì“°ë©´ ëœë‹¤. Entropyë¥¼ ì¨ë„ ê²°ê³¼ëŠ” ê±°ì˜ ê°™ë‹¤. MLAT Ch.11ì—ì„œë„ "In practice, the choice between Gini and Entropy rarely makes a significant difference"ë¼ê³  ì–¸ê¸‰í•œë‹¤.</p>

<pre><code><span class="cm"># === Gini vs Entropy ì§ì ‘ ê³„ì‚°í•´ë³´ê¸° ===</span>
<span class="kw">import</span> numpy <span class="kw">as</span> np

<span class="kw">def</span> <span class="fn">gini</span>(p):
    <span class="st">"""Gini ë¶ˆìˆœë„: pëŠ” ì–‘ì„± í´ë˜ìŠ¤ ë¹„ìœ¨"""</span>
    <span class="kw">return</span> <span class="nu">1</span> - p**<span class="nu">2</span> - (<span class="nu">1</span>-p)**<span class="nu">2</span>

<span class="kw">def</span> <span class="fn">entropy</span>(p):
    <span class="st">"""Entropy: pëŠ” ì–‘ì„± í´ë˜ìŠ¤ ë¹„ìœ¨"""</span>
    <span class="kw">if</span> p == <span class="nu">0</span> <span class="kw">or</span> p == <span class="nu">1</span>:
        <span class="kw">return</span> <span class="nu">0</span>
    <span class="kw">return</span> -p * np.log2(p) - (<span class="nu">1</span>-p) * np.log2(<span class="nu">1</span>-p)

<span class="cm"># ë‹¤ì–‘í•œ ë¹„ìœ¨ì—ì„œ ë¹„êµ</span>
<span class="fn">print</span>(<span class="st">f"{'ë¹„ìœ¨(ìƒìŠ¹%)':>10s} | {'Gini':>6s} | {'Entropy':>8s}"</span>)
<span class="fn">print</span>(<span class="st">"-"</span> * <span class="nu">32</span>)
<span class="kw">for</span> p <span class="kw">in</span> [<span class="nu">0.0</span>, <span class="nu">0.1</span>, <span class="nu">0.3</span>, <span class="nu">0.5</span>, <span class="nu">0.7</span>, <span class="nu">0.9</span>, <span class="nu">1.0</span>]:
    <span class="fn">print</span>(<span class="st">f"</span>{p:>9.0%}<span class="st"> | </span>{gini(p):>6.3f}<span class="st"> | </span>{entropy(p):>8.3f}<span class="st">"</span>)

<span class="cm"># ì¶œë ¥:</span>
<span class="cm">#    ë¹„ìœ¨(ìƒìŠ¹%) |   Gini | Entropy</span>
<span class="cm"># --------------------------------</span>
<span class="cm">#          0% |  0.000 |    0.000  â† ì™„ì „ ìˆœìˆ˜</span>
<span class="cm">#         10% |  0.180 |    0.469</span>
<span class="cm">#         30% |  0.420 |    0.881</span>
<span class="cm">#         50% |  0.500 |    1.000  â† ìµœëŒ€ ë¶ˆìˆœ</span>
<span class="cm">#         70% |  0.420 |    0.881</span>
<span class="cm">#         90% |  0.180 |    0.469</span>
<span class="cm">#        100% |  0.000 |    0.000  â† ì™„ì „ ìˆœìˆ˜</span></code></pre>

<div class="warn">
<p class="ni"><strong>ê¸ˆìœµì—ì„œì˜ í•¨ì • â€” í´ë˜ìŠ¤ ë¶ˆê· í˜•:</strong> ì£¼ê°€ ë°©í–¥ ì˜ˆì¸¡ì—ì„œ ìƒìŠ¹/í•˜ë½ì´ ì •í™•íˆ 50:50ì¸ ê²½ìš°ëŠ” ë“œë¬¼ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ìƒìŠ¹ì¥ì—ì„œëŠ” ìƒìŠ¹ 60%, í•˜ë½ 40%ì¼ ìˆ˜ ìˆë‹¤. ì´ë•Œ íŠ¸ë¦¬ê°€ "ë¬´ì¡°ê±´ ìƒìŠ¹"ì´ë¼ê³  ì˜ˆì¸¡í•´ë„ Giniê°€ ë‚®ì•„ ë³´ì¼ ìˆ˜ ìˆë‹¤. ì´ëŸ° í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œëŠ” <code>class_weight="balanced"</code> ì˜µì…˜ìœ¼ë¡œ ì™„í™”í•  ìˆ˜ ìˆë‹¤.</p>
</div>

<h3>8.3 ê²°ì • íŠ¸ë¦¬ êµ¬í˜„ê³¼ ì‹œê°í™”</h3>

<pre><code><span class="cm"># === ê²°ì • íŠ¸ë¦¬ ë¶„ë¥˜ ===</span>
<span class="kw">from</span> sklearn.tree <span class="kw">import</span> DecisionTreeClassifier, plot_tree

<span class="cm"># ê¹Šì´ ì œí•œ ì—†ëŠ” íŠ¸ë¦¬ (ê³¼ì í•© ìœ„í—˜!)</span>
tree_full = DecisionTreeClassifier(random_state=<span class="nu">42</span>)
tree_full.fit(X_train_s, y_train_cls)

<span class="cm"># ê¹Šì´ ì œí•œ íŠ¸ë¦¬ (ì •ê·œí™”)</span>
tree_pruned = DecisionTreeClassifier(
    max_depth=<span class="nu">4</span>,
    min_samples_leaf=<span class="nu">50</span>,
    random_state=<span class="nu">42</span>
)
tree_pruned.fit(X_train_s, y_train_cls)

<span class="cm"># ì„±ëŠ¥ ë¹„êµ</span>
<span class="fn">print</span>(<span class="st">"=== ê²°ì • íŠ¸ë¦¬ ê³¼ì í•© ë¹„êµ ==="</span>)
<span class="kw">for</span> name, model <span class="kw">in</span> [(<span class="st">"ê¹Šì´ ë¬´ì œí•œ"</span>, tree_full), (<span class="st">"ê¹Šì´=4"</span>, tree_pruned)]:
    train_acc = model.score(X_train_s, y_train_cls)
    test_acc = model.score(X_test_s, y_test_cls)
    <span class="fn">print</span>(<span class="st">f"</span>{name:12s}<span class="st">: Train </span>{train_acc:.4f}<span class="st">, Test </span>{test_acc:.4f}<span class="st">, ì°¨ì´ </span>{train_acc - test_acc:.4f}<span class="st">"</span>)
<span class="cm"># â†’ ê¹Šì´ ë¬´ì œí•œ: Train â‰ˆ 1.0, Test â‰ˆ 0.50 (ì‹¬ê°í•œ ê³¼ì í•©!)</span>
<span class="cm"># â†’ ê¹Šì´=4:     Train â‰ˆ 0.55, Test â‰ˆ 0.53 (ì ì ˆí•œ ì í•©)</span>

<span class="cm"># íŠ¸ë¦¬ ì‹œê°í™”</span>
fig, ax = plt.subplots(figsize=(<span class="nu">20</span>, <span class="nu">8</span>))
plot_tree(tree_pruned, feature_names=feature_cols,
          class_names=[<span class="st">"í•˜ë½"</span>, <span class="st">"ìƒìŠ¹"</span>], filled=<span class="kw">True</span>,
          rounded=<span class="kw">True</span>, fontsize=<span class="nu">9</span>, ax=ax)
plt.title(<span class="st">"ê²°ì • íŠ¸ë¦¬ ì‹œê°í™” (max_depth=4)"</span>)
plt.tight_layout()
plt.show()</code></pre>

<div class="warn">
<p class="ni"><strong>ê²°ì • íŠ¸ë¦¬ì˜ ì¹˜ëª…ì  ì•½ì  â€” ê³¼ì í•©:</strong> MLAT Ch.11ì—ì„œ ê°•ì¡°í•˜ë“¯, ê¹Šì´ ì œí•œ ì—†ëŠ” ê²°ì • íŠ¸ë¦¬ëŠ” í•™ìŠµ ë°ì´í„°ë¥¼ 100% ì™¸ì›Œë²„ë¦°ë‹¤. ê° ë¦¬í”„ ë…¸ë“œì— ìƒ˜í”Œì´ 1ê°œë§Œ ë‚¨ì„ ë•Œê¹Œì§€ ë¶„í• í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ì´ê²ƒì€ ì‹œí—˜ ë¬¸ì œë¥¼ ì™¸ì›Œì„œ 100ì  ë§ëŠ” ê²ƒê³¼ ê°™ë‹¤ â€” ìƒˆë¡œìš´ ë¬¸ì œì—ëŠ” ì „í˜€ ëŒ€ì‘í•˜ì§€ ëª»í•œë‹¤. ë°˜ë“œì‹œ <code>max_depth</code>, <code>min_samples_leaf</code> ë“±ìœ¼ë¡œ ì •ê·œí™”í•´ì•¼ í•œë‹¤.</p>
</div>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- Ch9: Random Forest -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2 id="ch9">9. Random Forest â€” ë‚˜ë¬´ë¥¼ ëª¨ì•„ ìˆ²ì„ ë§Œë“ ë‹¤</h2>

<h3>9.1 ì•™ìƒë¸”ì˜ í•µì‹¬ ì•„ì´ë””ì–´</h3>
<p>ê²°ì • íŠ¸ë¦¬ í•˜ë‚˜ëŠ” ë¶ˆì•ˆì •í•˜ê³  ê³¼ì í•©ì— ì·¨ì•½í•˜ë‹¤. í•˜ì§€ë§Œ ìˆ˜ë°± ê°œì˜ íŠ¸ë¦¬ë¥¼ ë§Œë“¤ì–´ì„œ ë‹¤ìˆ˜ê²° íˆ¬í‘œë¥¼ í•˜ë©´? ê°œë³„ íŠ¸ë¦¬ì˜ ì•½ì ì´ ìƒì‡„ë˜ì–´ í›¨ì”¬ ì•ˆì •ì ì¸ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•˜ë‹¤. ì´ê²ƒì´ ì•™ìƒë¸”(ensemble)ì˜ í•µì‹¬ ì•„ì´ë””ì–´ë‹¤. MLAT Ch.11 "Why ensemble models perform better" ì„¹ì…˜ì—ì„œ ì´ ì›ë¦¬ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•œë‹¤.</p>

<div class="def">
<p class="ni"><strong>Random Forestì˜ ë‘ ê°€ì§€ ëœë¤ì„±</strong></p>
<ol>
<li><strong>Bootstrap Aggregation (Bagging):</strong> ê° íŠ¸ë¦¬ëŠ” ì›ë³¸ ë°ì´í„°ì—ì„œ ë³µì› ì¶”ì¶œ(bootstrap)í•œ ì„œë¡œ ë‹¤ë¥¸ ìƒ˜í”Œë¡œ í•™ìŠµí•œë‹¤. ë°ì´í„°ì˜ ì•½ 63%ê°€ ì„ íƒë˜ê³  37%ëŠ” ë¹ ì§„ë‹¤(OOB, Out-of-Bag).</li>
<li><strong>Random Feature Selection:</strong> ê° ë¶„í• (split)ì—ì„œ ì „ì²´ í”¼ì²˜ ì¤‘ ì¼ë¶€ë§Œ ëœë¤í•˜ê²Œ ì„ íƒí•˜ì—¬ ìµœì  ë¶„í• ì„ ì°¾ëŠ”ë‹¤. ë¶„ë¥˜ì—ì„œëŠ” ë³´í†µ \(\sqrt{p}\)ê°œ, íšŒê·€ì—ì„œëŠ” \(p/3\)ê°œë¥¼ ì‚¬ìš©í•œë‹¤.</li>
</ol>
<p class="ni">ì´ ë‘ ê°€ì§€ ëœë¤ì„±ì´ íŠ¸ë¦¬ ê°„ì˜ ìƒê´€ì„ ì¤„ì—¬ì„œ ì•™ìƒë¸”ì˜ ë¶„ì‚°ì„ ê°ì†Œì‹œí‚¨ë‹¤.</p>
</div>

<h3>9.2 Random Forest êµ¬í˜„</h3>

<pre><code><span class="cm"># === Random Forest ë¶„ë¥˜ ===</span>
<span class="kw">from</span> sklearn.ensemble <span class="kw">import</span> RandomForestClassifier

<span class="cm"># Random Forest í•™ìŠµ</span>
rf = RandomForestClassifier(
    n_estimators=<span class="nu">500</span>,       <span class="cm"># íŠ¸ë¦¬ 500ê°œ</span>
    max_depth=<span class="nu">6</span>,             <span class="cm"># ê° íŠ¸ë¦¬ ìµœëŒ€ ê¹Šì´</span>
    min_samples_leaf=<span class="nu">50</span>,     <span class="cm"># ë¦¬í”„ ë…¸ë“œ ìµœì†Œ ìƒ˜í”Œ</span>
    max_features=<span class="st">"sqrt"</span>,     <span class="cm"># ê° ë¶„í• ì—ì„œ âˆšpê°œ í”¼ì²˜ ì‚¬ìš©</span>
    n_jobs=-<span class="nu">1</span>,               <span class="cm"># ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©</span>
    random_state=<span class="nu">42</span>
)
rf.fit(X_train_s, y_train_cls)

<span class="cm"># ì„±ëŠ¥ í‰ê°€</span>
y_pred_rf = rf.predict(X_test_s)
y_prob_rf = rf.predict_proba(X_test_s)[:, <span class="nu">1</span>]

<span class="fn">print</span>(<span class="st">"=== Random Forest ì„±ëŠ¥ ==="</span>)
<span class="fn">print</span>(<span class="st">f"Train Accuracy: </span>{rf.score(X_train_s, y_train_cls):.4f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"Test Accuracy:  </span>{rf.score(X_test_s, y_test_cls):.4f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"Test AUC-ROC:   </span>{roc_auc_score(y_test_cls, y_prob_rf):.4f}<span class="st">"</span>)</code></pre>

<h3>9.3 í”¼ì²˜ ì¤‘ìš”ë„ (Feature Importance)</h3>
<p>Random Forestì˜ í° ì¥ì  ì¤‘ í•˜ë‚˜ëŠ” ê° í”¼ì²˜ê°€ ì˜ˆì¸¡ì— ì–¼ë§ˆë‚˜ ê¸°ì—¬í•˜ëŠ”ì§€ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°í•´ì¤€ë‹¤ëŠ” ê²ƒì´ë‹¤. MLAT Ch.11 "Feature importance for random forests"ì—ì„œ ì´ ê°œë…ì„ ë‹¤ë£¬ë‹¤.</p>

<pre><code><span class="cm"># í”¼ì²˜ ì¤‘ìš”ë„ ì‹œê°í™”</span>
importances = pd.Series(rf.feature_importances_, index=feature_cols)
importances = importances.sort_values(ascending=<span class="kw">True</span>)

fig, ax = plt.subplots(figsize=(<span class="nu">10</span>, <span class="nu">5</span>))
importances.plot(kind=<span class="st">"barh"</span>, ax=ax, color=<span class="st">"steelblue"</span>)
ax.set_xlabel(<span class="st">"Feature Importance (Gini)"</span>)
ax.set_title(<span class="st">"Random Forest â€” í”¼ì²˜ ì¤‘ìš”ë„"</span>)
ax.grid(<span class="kw">True</span>, alpha=<span class="nu">0.3</span>, axis=<span class="st">"x"</span>)
plt.tight_layout()
plt.show()

<span class="fn">print</span>(<span class="st">"=== í”¼ì²˜ ì¤‘ìš”ë„ ìˆœìœ„ ==="</span>)
<span class="kw">for</span> name, imp <span class="kw">in</span> importances[::-<span class="nu">1</span>].items():
    bar = <span class="st">"â–ˆ"</span> * <span class="nb">int</span>(imp * <span class="nu">100</span>)
    <span class="fn">print</span>(<span class="st">f"  </span>{name:12s}<span class="st">: </span>{imp:.4f}<span class="st"> </span>{bar}<span class="st">"</span>)</code></pre>

<div class="info">
<p class="ni"><strong>OOB Score â€” ê³µì§œ ê²€ì¦:</strong> Random ForestëŠ” ê° íŠ¸ë¦¬ê°€ í•™ìŠµì— ì‚¬ìš©í•˜ì§€ ì•Šì€ 37%ì˜ ë°ì´í„°(OOB)ë¡œ ìë™ ê²€ì¦í•  ìˆ˜ ìˆë‹¤. <code>oob_score=True</code>ë¡œ ì„¤ì •í•˜ë©´ ë³„ë„ì˜ ê²€ì¦ ì„¸íŠ¸ ì—†ì´ë„ ì¼ë°˜í™” ì„±ëŠ¥ì„ ì¶”ì •í•  ìˆ˜ ìˆë‹¤. MLAT Ch.11 "Out-of-bag testing" ì„¹ì…˜ì—ì„œ ì´ ê¸°ë²•ì„ ë‹¤ë£¬ë‹¤.</p>
</div>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- Ch10: Gradient Boosting -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2 id="ch10">10. Gradient Boosting â€” ì•½í•œ í•™ìŠµê¸°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ê°•í™”</h2>

<h3>10.1 Bagging vs Boosting</h3>
<p>Random ForestëŠ” ì—¬ëŸ¬ íŠ¸ë¦¬ë¥¼ ë³‘ë ¬ë¡œ(parallel) ë§Œë“¤ì–´ì„œ í‰ê· ì„ ë‚¸ë‹¤(Bagging). Gradient Boostingì€ ì ‘ê·¼ì´ ë‹¤ë¥´ë‹¤ â€” íŠ¸ë¦¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ(sequential) ë§Œë“¤ë˜, ì´ì „ íŠ¸ë¦¬ê°€ í‹€ë¦° ë¶€ë¶„ì„ ë‹¤ìŒ íŠ¸ë¦¬ê°€ ë³´ì •í•œë‹¤. MLAT Ch.12ì—ì„œ ì´ ì°¨ì´ë¥¼ ìƒì„¸íˆ ë‹¤ë£¬ë‹¤.</p>

<!-- Bagging vs Boosting ë¹„êµ ë‹¤ì´ì–´ê·¸ë¨ -->
<div style="margin:25px 0;padding:20px;background:#f8f9fa;border-radius:8px;border:1px solid #ddd">
<p class="ni" style="text-align:center;font-weight:bold;font-size:14px;margin-bottom:15px;color:#2c3e50">ğŸ”„ Bagging vs Boosting</p>
<div style="display:flex;gap:20px;justify-content:center;flex-wrap:wrap;font-size:12px">
<div style="flex:1;min-width:250px;background:#fff;padding:15px;border-radius:8px;border:2px solid #3498db">
<div style="font-weight:bold;color:#3498db;font-size:13px;margin-bottom:8px;text-align:center">Bagging (Random Forest)</div>
<div style="display:flex;gap:4px;justify-content:center;margin:8px 0">
<div style="background:#3498db;color:#fff;padding:4px 8px;border-radius:4px;font-size:10px">Tree 1</div>
<div style="background:#3498db;color:#fff;padding:4px 8px;border-radius:4px;font-size:10px">Tree 2</div>
<div style="background:#3498db;color:#fff;padding:4px 8px;border-radius:4px;font-size:10px">Tree 3</div>
</div>
<div style="text-align:center;color:#3498db;font-size:10px">â†“ ë³‘ë ¬ í•™ìŠµ â†“</div>
<div style="text-align:center;background:#e8f4f8;padding:6px;border-radius:4px;margin-top:4px;font-weight:bold">ë‹¤ìˆ˜ê²° íˆ¬í‘œ / í‰ê· </div>
<div style="margin-top:6px;color:#555;font-size:11px;text-align:center">ë¶„ì‚° ê°ì†Œ â†“ | í¸í–¥ ìœ ì§€</div>
</div>
<div style="flex:1;min-width:250px;background:#fff;padding:15px;border-radius:8px;border:2px solid #e74c3c">
<div style="font-weight:bold;color:#e74c3c;font-size:13px;margin-bottom:8px;text-align:center">Boosting (Gradient Boosting)</div>
<div style="display:flex;gap:4px;justify-content:center;align-items:center;margin:8px 0">
<div style="background:#e74c3c;color:#fff;padding:4px 8px;border-radius:4px;font-size:10px">Tree 1</div>
<div style="color:#e74c3c">â†’</div>
<div style="background:#e74c3c;color:#fff;padding:4px 8px;border-radius:4px;font-size:10px">Tree 2</div>
<div style="color:#e74c3c">â†’</div>
<div style="background:#e74c3c;color:#fff;padding:4px 8px;border-radius:4px;font-size:10px">Tree 3</div>
</div>
<div style="text-align:center;color:#e74c3c;font-size:10px">â†’ ìˆœì°¨ í•™ìŠµ (ì”ì°¨ ë³´ì •) â†’</div>
<div style="text-align:center;background:#fde8e8;padding:6px;border-radius:4px;margin-top:4px;font-weight:bold">ê°€ì¤‘ í•©ì‚°</div>
<div style="margin-top:6px;color:#555;font-size:11px;text-align:center">í¸í–¥ ê°ì†Œ â†“ | ê³¼ì í•© ì£¼ì˜</div>
</div>
</div>
</div>

<h3>10.2 Gradient Boostingì˜ ì‘ë™ ì›ë¦¬</h3>
<p>Gradient Boostingì€ ë‹¤ìŒê³¼ ê°™ì´ ì‘ë™í•œë‹¤:</p>
<ol>
<li>ì²« ë²ˆì§¸ íŠ¸ë¦¬ê°€ ì˜ˆì¸¡í•œë‹¤ â†’ ì”ì°¨(residual)ë¥¼ ê³„ì‚°í•œë‹¤</li>
<li>ë‘ ë²ˆì§¸ íŠ¸ë¦¬ê°€ ì”ì°¨ë¥¼ ì˜ˆì¸¡í•œë‹¤ â†’ ìƒˆë¡œìš´ ì”ì°¨ë¥¼ ê³„ì‚°í•œë‹¤</li>
<li>ì„¸ ë²ˆì§¸ íŠ¸ë¦¬ê°€ ìƒˆë¡œìš´ ì”ì°¨ë¥¼ ì˜ˆì¸¡í•œë‹¤ â†’ ...</li>
<li>ìµœì¢… ì˜ˆì¸¡ = ëª¨ë“  íŠ¸ë¦¬ì˜ ì˜ˆì¸¡ì„ í•©ì‚°í•œë‹¤</li>
</ol>

<div class="eq">\[ F_m(x) = F_{m-1}(x) + \eta \cdot h_m(x) \]</div>

<p>ì—¬ê¸°ì„œ \(\eta\)(í•™ìŠµë¥ , learning rate)ëŠ” ê° íŠ¸ë¦¬ì˜ ê¸°ì—¬ë„ë¥¼ ì¡°ì ˆí•œë‹¤. í•™ìŠµë¥ ì´ ì‘ì„ìˆ˜ë¡ ë” ë§ì€ íŠ¸ë¦¬ê°€ í•„ìš”í•˜ì§€ë§Œ, ê³¼ì í•© ìœ„í—˜ì´ ì¤„ì–´ë“ ë‹¤. ë³´í†µ 0.01~0.1 ì‚¬ì´ì˜ ê°’ì„ ì‚¬ìš©í•œë‹¤.</p>

<pre><code><span class="cm"># === Gradient Boosting ë¶„ë¥˜ ===</span>
<span class="kw">from</span> sklearn.ensemble <span class="kw">import</span> GradientBoostingClassifier

gb = GradientBoostingClassifier(
    n_estimators=<span class="nu">200</span>,
    learning_rate=<span class="nu">0.05</span>,
    max_depth=<span class="nu">3</span>,           <span class="cm"># ë¶€ìŠ¤íŒ…ì—ì„œëŠ” ì–•ì€ íŠ¸ë¦¬ ì‚¬ìš©</span>
    min_samples_leaf=<span class="nu">30</span>,
    subsample=<span class="nu">0.8</span>,         <span class="cm"># Stochastic GB: 80% ìƒ˜í”Œ ì‚¬ìš©</span>
    random_state=<span class="nu">42</span>
)
gb.fit(X_train_s, y_train_cls)

y_prob_gb = gb.predict_proba(X_test_s)[:, <span class="nu">1</span>]
<span class="fn">print</span>(<span class="st">"=== Gradient Boosting ì„±ëŠ¥ ==="</span>)
<span class="fn">print</span>(<span class="st">f"Train Accuracy: </span>{gb.score(X_train_s, y_train_cls):.4f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"Test Accuracy:  </span>{gb.score(X_test_s, y_test_cls):.4f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"Test AUC-ROC:   </span>{roc_auc_score(y_test_cls, y_prob_gb):.4f}<span class="st">"</span>)</code></pre>

<div class="info">
<p class="ni"><strong>êµì¬ ì—°ë™:</strong> MLAT Ch.12 "Boosting Your Trading Strategy"ì—ì„œ Gradient Boostingì˜ ìˆ˜í•™ì  ë°°ê²½ê³¼ ê¸ˆìœµ ì ìš©ì„ ìƒì„¸íˆ ë‹¤ë£¬ë‹¤. íŠ¹íˆ learning_rateì™€ n_estimatorsì˜ íŠ¸ë ˆì´ë“œì˜¤í”„, subsampleì„ ì‚¬ìš©í•œ Stochastic Gradient Boostingì˜ ì •ê·œí™” íš¨ê³¼ë¥¼ ì„¤ëª…í•œë‹¤. sklearnì˜ GradientBoostingClassifierëŠ” êµìœ¡ìš©ìœ¼ë¡œ ì¢‹ì§€ë§Œ, ì‹¤ì „ì—ì„œëŠ” ë‹¤ìŒ ì¥ì—ì„œ ë‹¤ë£° XGBoost/LightGBMì´ í›¨ì”¬ ë¹ ë¥´ê³  ê°•ë ¥í•˜ë‹¤.</p>
</div>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- Ch11: XGBoost / LightGBM -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2 id="ch11">11. XGBoost / LightGBM â€” ì‹¤ì „ ë¶€ìŠ¤íŒ…ì˜ ì–‘ëŒ€ ì‚°ë§¥</h2>

<h3>11.1 ì™œ sklearn Gradient Boostingìœ¼ë¡œëŠ” ë¶€ì¡±í•œê°€?</h3>
<p>ì• ì¥ì—ì„œ ë°°ìš´ sklearnì˜ GradientBoostingClassifierëŠ” ê°œë… ì´í•´ì—ëŠ” ì¢‹ì§€ë§Œ, ì‹¤ì „ì—ì„œëŠ” ì‹¬ê°í•œ í•œê³„ê°€ ìˆë‹¤:</p>

<table>
<caption class="tc">sklearn GB vs XGBoost/LightGBM ë¹„êµ</caption>
<thead><tr><th>í•­ëª©</th><th>sklearn GB</th><th>XGBoost</th><th>LightGBM</th></tr></thead>
<tbody>
<tr><td>í•™ìŠµ ì†ë„</td><td>ëŠë¦¼ (ë‹¨ì¼ ìŠ¤ë ˆë“œ)</td><td>ë¹ ë¦„ (ë³‘ë ¬ ì²˜ë¦¬)</td><td>ë§¤ìš° ë¹ ë¦„ (íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜)</td></tr>
<tr><td>ë©”ëª¨ë¦¬ ì‚¬ìš©</td><td>ë†’ìŒ</td><td>ì¤‘ê°„</td><td>ë‚®ìŒ</td></tr>
<tr><td>Early Stopping</td><td>ì œí•œì </td><td>ë‚´ì¥</td><td>ë‚´ì¥</td></tr>
<tr><td>ê²°ì¸¡ì¹˜ ì²˜ë¦¬</td><td>ë¶ˆê°€ (ì „ì²˜ë¦¬ í•„ìš”)</td><td>ìë™ ì²˜ë¦¬</td><td>ìë™ ì²˜ë¦¬</td></tr>
<tr><td>ë²”ì£¼í˜• í”¼ì²˜</td><td>ë¶ˆê°€</td><td>ì œí•œì </td><td>ë„¤ì´í‹°ë¸Œ ì§€ì›</td></tr>
<tr><td>GPU ì§€ì›</td><td>ì—†ìŒ</td><td>ìˆìŒ</td><td>ìˆìŒ</td></tr>
<tr><td>Kaggle/ì‹¤ì „ ì‚¬ìš©</td><td>ê±°ì˜ ì—†ìŒ</td><td>ë§¤ìš° ë§ìŒ</td><td>ë§¤ìš° ë§ìŒ</td></tr>
</tbody>
</table>

<p>MLAT Ch.12ì—ì„œ "XGBoost, LightGBM, and CatBoost have firmly established gradient boosting as the go-to solution for structured data"ë¼ê³  ê°•ì¡°í•˜ë“¯, ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì€ Kaggle ëŒ€íšŒì™€ ê¸ˆìœµ ì‹¤ë¬´ì—ì„œ ì••ë„ì ìœ¼ë¡œ ë§ì´ ì‚¬ìš©ëœë‹¤.</p>

<h3>11.2 XGBoost â€” eXtreme Gradient Boosting</h3>
<p>XGBoostëŠ” 2014ë…„ Tianqi Chenì´ ê°œë°œí•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, Gradient Boostingì„ ê·¹í•œê¹Œì§€ ìµœì í™”í–ˆë‹¤. MLAT Ch.12ì—ì„œ ì„¤ëª…í•˜ë“¯, XGBoostì˜ í•µì‹¬ í˜ì‹ ì€ ë‹¤ìŒê³¼ ê°™ë‹¤:</p>

<div class="def">
<p class="ni"><strong>XGBoostì˜ í•µì‹¬ í˜ì‹ </strong></p>
<ol>
<li><strong>2ì°¨ ê·¼ì‚¬ (Second-order approximation):</strong> ì†ì‹¤ í•¨ìˆ˜ì˜ 1ì°¨ ë¯¸ë¶„(gradient)ë¿ ì•„ë‹ˆë¼ 2ì°¨ ë¯¸ë¶„(Hessian)ë„ ì‚¬ìš©í•˜ì—¬ ë” ì •í™•í•œ ë¶„í• ì„ ì°¾ëŠ”ë‹¤.</li>
<li><strong>ì •ê·œí™” í•­ ë‚´ì¥:</strong> ëª©ì  í•¨ìˆ˜ì— L1/L2 ì •ê·œí™”ë¥¼ ì§ì ‘ í¬í•¨í•˜ì—¬ ê³¼ì í•©ì„ ì œì–´í•œë‹¤.</li>
<li><strong>ê·¼ì‚¬ ë¶„í•  íƒìƒ‰ (Approximate split-finding):</strong> ëª¨ë“  ë¶„í• ì ì„ íƒìƒ‰í•˜ëŠ” ëŒ€ì‹  quantile sketchë¡œ í›„ë³´ë¥¼ ì¤„ì—¬ ì†ë„ë¥¼ ë†’ì¸ë‹¤.</li>
<li><strong>ê²°ì¸¡ì¹˜ ìë™ ì²˜ë¦¬:</strong> ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ìƒ˜í”Œì„ ì™¼ìª½/ì˜¤ë¥¸ìª½ ì¤‘ ìµœì  ë°©í–¥ìœ¼ë¡œ ìë™ ë°°ì •í•œë‹¤.</li>
<li><strong>ë³‘ë ¬ ì²˜ë¦¬:</strong> í”¼ì²˜ë³„ ë¶„í•  íƒìƒ‰ì„ ë³‘ë ¬í™”í•˜ì—¬ ë©€í‹°ì½”ì–´ CPUë¥¼ í™œìš©í•œë‹¤.</li>
</ol>
</div>

<div class="eq">\[ \mathcal{L}^{(m)} = \sum_{i=1}^{n} \left[ g_i f_m(x_i) + \frac{1}{2} h_i f_m^2(x_i) \right] + \Omega(f_m) \]</div>
<p class="ni">ì—¬ê¸°ì„œ \(g_i = \partial_{\hat{y}} l(y_i, \hat{y}_i^{(m-1)})\)ëŠ” 1ì°¨ gradient, \(h_i = \partial^2_{\hat{y}} l(y_i, \hat{y}_i^{(m-1)})\)ëŠ” 2ì°¨ Hessian, \(\Omega(f_m) = \gamma T + \frac{1}{2}\lambda \|w\|^2\)ëŠ” ì •ê·œí™” í•­ì´ë‹¤. MLAT Ch.12 "How XGBoost speeds up computation"ì—ì„œ ì´ ìˆ˜ì‹ì˜ ìœ ë„ ê³¼ì •ì„ ìƒì„¸íˆ ë‹¤ë£¬ë‹¤.</p>

<pre><code><span class="cm"># === XGBoost ì„¤ì¹˜ ë° ê¸°ë³¸ ì‚¬ìš© ===</span>
<span class="cm"># pip install xgboost</span>
<span class="kw">import</span> xgboost <span class="kw">as</span> xgb

<span class="cm"># XGBoost ë¶„ë¥˜ê¸°</span>
xgb_clf = xgb.XGBClassifier(
    n_estimators=<span class="nu">500</span>,
    learning_rate=<span class="nu">0.05</span>,
    max_depth=<span class="nu">4</span>,
    min_child_weight=<span class="nu">30</span>,     <span class="cm"># ë¦¬í”„ ë…¸ë“œ ìµœì†Œ ê°€ì¤‘ì¹˜ í•©</span>
    subsample=<span class="nu">0.8</span>,            <span class="cm"># í–‰ ìƒ˜í”Œë§ ë¹„ìœ¨</span>
    colsample_bytree=<span class="nu">0.8</span>,    <span class="cm"># ì—´ ìƒ˜í”Œë§ ë¹„ìœ¨</span>
    reg_alpha=<span class="nu">0.1</span>,            <span class="cm"># L1 ì •ê·œí™”</span>
    reg_lambda=<span class="nu">1.0</span>,           <span class="cm"># L2 ì •ê·œí™”</span>
    eval_metric=<span class="st">"auc"</span>,
    random_state=<span class="nu">42</span>,
    n_jobs=-<span class="nu">1</span>
)

<span class="cm"># Early Stoppingìœ¼ë¡œ í•™ìŠµ</span>
xgb_clf.fit(
    X_train_s, y_train_cls,
    eval_set=[(X_test_s, y_test_cls)],
    verbose=<span class="nu">50</span>   <span class="cm"># 50ë¼ìš´ë“œë§ˆë‹¤ ì¶œë ¥</span>
)

<span class="cm"># ì„±ëŠ¥ í‰ê°€</span>
y_prob_xgb = xgb_clf.predict_proba(X_test_s)[:, <span class="nu">1</span>]
<span class="fn">print</span>(<span class="st">f"\n=== XGBoost ì„±ëŠ¥ ==="</span>)
<span class="fn">print</span>(<span class="st">f"Train Accuracy: </span>{xgb_clf.score(X_train_s, y_train_cls):.4f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"Test Accuracy:  </span>{xgb_clf.score(X_test_s, y_test_cls):.4f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"Test AUC-ROC:   </span>{roc_auc_score(y_test_cls, y_prob_xgb):.4f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"Best Iteration: </span>{xgb_clf.best_iteration}<span class="st">"</span>)</code></pre>

<h3>11.3 LightGBM â€” ë” ë¹ ë¥´ê³  ë” íš¨ìœ¨ì ì¸</h3>
<p>LightGBMì€ 2017ë…„ Microsoftê°€ ê°œë°œí•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, XGBoostë³´ë‹¤ ë” ë¹ ë¥¸ í•™ìŠµ ì†ë„ë¥¼ ëª©í‘œë¡œ ì„¤ê³„ë˜ì—ˆë‹¤. MLAT Ch.12ì—ì„œ ì„¤ëª…í•˜ëŠ” ë‘ ê°€ì§€ í•µì‹¬ í˜ì‹ :</p>

<div class="def">
<p class="ni"><strong>LightGBMì˜ í•µì‹¬ í˜ì‹ </strong></p>
<ol>
<li><strong>Gradient-based One-Side Sampling (GOSS):</strong> gradientê°€ í°(=í•™ìŠµì´ ëœ ëœ) ìƒ˜í”Œì€ ëª¨ë‘ ìœ ì§€í•˜ê³ , gradientê°€ ì‘ì€(=ì´ë¯¸ ì˜ í•™ìŠµëœ) ìƒ˜í”Œì€ ëœë¤ ìƒ˜í”Œë§í•œë‹¤. ì •ë³´ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ë©´ì„œ í•™ìŠµ ë°ì´í„°ë¥¼ ì¤„ì¸ë‹¤.</li>
<li><strong>Exclusive Feature Bundling (EFB):</strong> ë™ì‹œì— 0ì´ ì•„ë‹Œ ê°’ì„ ê°–ì§€ ì•ŠëŠ” í”¼ì²˜ë“¤ì„ í•˜ë‚˜ë¡œ ë¬¶ì–´ì„œ í”¼ì²˜ ìˆ˜ë¥¼ ì¤„ì¸ë‹¤. ì›-í•« ì¸ì½”ë”©ëœ í”¼ì²˜ì— íŠ¹íˆ íš¨ê³¼ì ì´ë‹¤.</li>
<li><strong>Leaf-wise ì„±ì¥:</strong> XGBoostì˜ level-wise(ì¸µë³„) ì„±ì¥ê³¼ ë‹¬ë¦¬, ê°€ì¥ ì†ì‹¤ ê°ì†Œê°€ í° ë¦¬í”„ë¥¼ ìš°ì„  ë¶„í• í•œë‹¤. ê°™ì€ ìˆ˜ì˜ ë¦¬í”„ì—ì„œ ë” ë‚®ì€ ì†ì‹¤ì„ ë‹¬ì„±í•˜ì§€ë§Œ, ê³¼ì í•© ìœ„í—˜ì´ ìˆì–´ <code>num_leaves</code> ì œí•œì´ ì¤‘ìš”í•˜ë‹¤.</li>
<li><strong>íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ë¶„í• :</strong> ì—°ì†í˜• í”¼ì²˜ë¥¼ 256ê°œ binìœ¼ë¡œ ì´ì‚°í™”í•˜ì—¬ ë¶„í•  íƒìƒ‰ ì†ë„ë¥¼ ê·¹ì ìœ¼ë¡œ ë†’ì¸ë‹¤.</li>
</ol>
</div>

<!-- XGBoost vs LightGBM íŠ¸ë¦¬ ì„±ì¥ ë°©ì‹ ë¹„êµ ë‹¤ì´ì–´ê·¸ë¨ -->
<div style="margin:25px 0;padding:20px;background:linear-gradient(135deg,#f0f4ff,#fff5f0);border-radius:10px;border:1px solid #ccc">
<p class="ni" style="text-align:center;font-weight:bold;font-size:14px;margin-bottom:15px;color:#2c3e50">ğŸŒ² íŠ¸ë¦¬ ì„±ì¥ ë°©ì‹ ë¹„êµ</p>
<div style="display:flex;gap:20px;justify-content:center;flex-wrap:wrap;font-size:11px">
<div style="flex:1;min-width:240px;background:#fff;padding:15px;border-radius:8px;border:2px solid #3498db">
<div style="font-weight:bold;color:#3498db;font-size:13px;margin-bottom:10px;text-align:center">Level-wise (XGBoost)</div>
<div style="text-align:center">
<div style="display:inline-block;background:#3498db;color:#fff;padding:4px 12px;border-radius:4px;margin:2px">Root</div><br>
<div style="display:inline-flex;gap:8px;margin:4px 0">
<div style="background:#5dade2;color:#fff;padding:3px 10px;border-radius:4px">L1</div>
<div style="background:#5dade2;color:#fff;padding:3px 10px;border-radius:4px">L2</div>
</div><br>
<div style="display:inline-flex;gap:4px;margin:4px 0">
<div style="background:#85c1e9;color:#fff;padding:3px 8px;border-radius:4px;font-size:10px">L3</div>
<div style="background:#85c1e9;color:#fff;padding:3px 8px;border-radius:4px;font-size:10px">L4</div>
<div style="background:#85c1e9;color:#fff;padding:3px 8px;border-radius:4px;font-size:10px">L5</div>
<div style="background:#85c1e9;color:#fff;padding:3px 8px;border-radius:4px;font-size:10px">L6</div>
</div>
</div>
<p class="ni" style="text-align:center;margin-top:8px;color:#555;font-size:10px">í•œ ì¸µì”© ê· ë“±í•˜ê²Œ ì„±ì¥<br>â†’ ê· í˜• ì¡íŒ íŠ¸ë¦¬</p>
</div>
<div style="flex:1;min-width:240px;background:#fff;padding:15px;border-radius:8px;border:2px solid #e67e22">
<div style="font-weight:bold;color:#e67e22;font-size:13px;margin-bottom:10px;text-align:center">Leaf-wise (LightGBM)</div>
<div style="text-align:center">
<div style="display:inline-block;background:#e67e22;color:#fff;padding:4px 12px;border-radius:4px;margin:2px">Root</div><br>
<div style="display:inline-flex;gap:8px;margin:4px 0">
<div style="background:#f39c12;color:#fff;padding:3px 10px;border-radius:4px">L1</div>
<div style="background:#d4d4d4;color:#888;padding:3px 10px;border-radius:4px">L2</div>
</div><br>
<div style="display:inline-flex;gap:4px;margin:4px 0">
<div style="background:#f5b041;color:#fff;padding:3px 8px;border-radius:4px;font-size:10px">L3</div>
<div style="background:#f5b041;color:#fff;padding:3px 8px;border-radius:4px;font-size:10px">L4</div>
<div style="background:#d4d4d4;color:#888;padding:3px 8px;border-radius:4px;font-size:10px">â€”</div>
<div style="background:#d4d4d4;color:#888;padding:3px 8px;border-radius:4px;font-size:10px">â€”</div>
</div>
</div>
<p class="ni" style="text-align:center;margin-top:8px;color:#555;font-size:10px">ì†ì‹¤ ìµœëŒ€ ê°ì†Œ ë¦¬í”„ ìš°ì„  ë¶„í• <br>â†’ ë¹„ëŒ€ì¹­ íŠ¸ë¦¬, ë” ë‚®ì€ ì†ì‹¤</p>
</div>
</div>
</div>

<pre><code><span class="cm"># === LightGBM ì„¤ì¹˜ ë° ê¸°ë³¸ ì‚¬ìš© ===</span>
<span class="cm"># pip install lightgbm</span>
<span class="kw">import</span> lightgbm <span class="kw">as</span> lgb

<span class="cm"># LightGBM ë¶„ë¥˜ê¸°</span>
lgb_clf = lgb.LGBMClassifier(
    n_estimators=<span class="nu">500</span>,
    learning_rate=<span class="nu">0.05</span>,
    num_leaves=<span class="nu">31</span>,            <span class="cm"># ë¦¬í”„ ë…¸ë“œ ìˆ˜ (2^5 - 1)</span>
    max_depth=-<span class="nu">1</span>,             <span class="cm"># ì œí•œ ì—†ìŒ (num_leavesë¡œ ì œì–´)</span>
    min_child_samples=<span class="nu">30</span>,    <span class="cm"># ë¦¬í”„ ìµœì†Œ ìƒ˜í”Œ ìˆ˜</span>
    subsample=<span class="nu">0.8</span>,
    colsample_bytree=<span class="nu">0.8</span>,
    reg_alpha=<span class="nu">0.1</span>,
    reg_lambda=<span class="nu">1.0</span>,
    random_state=<span class="nu">42</span>,
    n_jobs=-<span class="nu">1</span>,
    verbose=-<span class="nu">1</span>              <span class="cm"># ë¡œê·¸ ì¶œë ¥ ì–µì œ</span>
)

<span class="cm"># Early Stoppingìœ¼ë¡œ í•™ìŠµ</span>
lgb_clf.fit(
    X_train_s, y_train_cls,
    eval_set=[(X_test_s, y_test_cls)],
    callbacks=[lgb.log_evaluation(<span class="nu">50</span>)]
)

<span class="cm"># ì„±ëŠ¥ í‰ê°€</span>
y_prob_lgb = lgb_clf.predict_proba(X_test_s)[:, <span class="nu">1</span>]
<span class="fn">print</span>(<span class="st">f"\n=== LightGBM ì„±ëŠ¥ ==="</span>)
<span class="fn">print</span>(<span class="st">f"Train Accuracy: </span>{lgb_clf.score(X_train_s, y_train_cls):.4f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"Test Accuracy:  </span>{lgb_clf.score(X_test_s, y_test_cls):.4f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"Test AUC-ROC:   </span>{roc_auc_score(y_test_cls, y_prob_lgb):.4f}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"Best Iteration: </span>{lgb_clf.best_iteration_}<span class="st">"</span>)</code></pre>

<h3>11.4 í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ â€” GridSearchCV + TimeSeriesSplit</h3>
<p>ëª¨ë¸ì˜ ì„±ëŠ¥ì€ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ì— í¬ê²Œ ì¢Œìš°ëœë‹¤. MLAT Ch.12 "Hyperparameter tuning with LightGBM" ì„¹ì…˜ì—ì„œ ê°•ì¡°í•˜ë“¯, ì²´ê³„ì ì¸ íƒìƒ‰ì´ í•„ìˆ˜ë‹¤. ê¸ˆìœµ ë°ì´í„°ì—ì„œëŠ” ë°˜ë“œì‹œ TimeSeriesSplitì„ ì‚¬ìš©í•´ì•¼ ë¯¸ë˜ ì •ë³´ ëˆ„ì¶œì„ ë°©ì§€í•  ìˆ˜ ìˆë‹¤.</p>

<pre><code><span class="cm"># === í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (LightGBM + TimeSeriesSplit) ===</span>
<span class="kw">from</span> sklearn.model_selection <span class="kw">import</span> GridSearchCV, TimeSeriesSplit

<span class="cm"># íƒìƒ‰í•  í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ</span>
param_grid = {
    <span class="st">"n_estimators"</span>: [<span class="nu">200</span>, <span class="nu">500</span>],
    <span class="st">"learning_rate"</span>: [<span class="nu">0.01</span>, <span class="nu">0.05</span>, <span class="nu">0.1</span>],
    <span class="st">"num_leaves"</span>: [<span class="nu">15</span>, <span class="nu">31</span>, <span class="nu">63</span>],
    <span class="st">"min_child_samples"</span>: [<span class="nu">20</span>, <span class="nu">50</span>],
}

<span class="cm"># ì‹œê³„ì—´ êµì°¨ê²€ì¦ (5-Fold)</span>
tscv = TimeSeriesSplit(n_splits=<span class="nu">5</span>)

<span class="cm"># GridSearchCV ì‹¤í–‰</span>
grid_search = GridSearchCV(
    lgb.LGBMClassifier(
        subsample=<span class="nu">0.8</span>,
        colsample_bytree=<span class="nu">0.8</span>,
        reg_alpha=<span class="nu">0.1</span>,
        reg_lambda=<span class="nu">1.0</span>,
        random_state=<span class="nu">42</span>,
        n_jobs=-<span class="nu">1</span>,
        verbose=-<span class="nu">1</span>
    ),
    param_grid,
    cv=tscv,
    scoring=<span class="st">"roc_auc"</span>,
    n_jobs=-<span class="nu">1</span>,
    verbose=<span class="nu">1</span>
)
grid_search.fit(X_train_s, y_train_cls)

<span class="cm"># ìµœì  íŒŒë¼ë¯¸í„° ì¶œë ¥</span>
<span class="fn">print</span>(<span class="st">"=== GridSearchCV ê²°ê³¼ ==="</span>)
<span class="fn">print</span>(<span class="st">f"ìµœì  íŒŒë¼ë¯¸í„°: </span>{grid_search.best_params_}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"ìµœì  AUC-ROC:  </span>{grid_search.best_score_:.4f}<span class="st">"</span>)

<span class="cm"># ìµœì  ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸</span>
best_lgb = grid_search.best_estimator_
y_prob_best = best_lgb.predict_proba(X_test_s)[:, <span class="nu">1</span>]
<span class="fn">print</span>(<span class="st">f"Test AUC-ROC:  </span>{roc_auc_score(y_test_cls, y_prob_best):.4f}<span class="st">"</span>)</code></pre>

<div class="warn">
<p class="ni"><strong>ì£¼ì˜: íƒìƒ‰ ê³µê°„ì´ ë„ˆë¬´ í¬ë©´ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦°ë‹¤!</strong> ìœ„ ê·¸ë¦¬ë“œëŠ” 2Ã—3Ã—3Ã—2 = 36ê°œ ì¡°í•© Ã— 5 Fold = 180ë²ˆ í•™ìŠµì´ë‹¤. ì‹¤ì „ì—ì„œëŠ” RandomizedSearchCV(ëœë¤ íƒìƒ‰)ë‚˜ Optuna(ë² ì´ì§€ì•ˆ ìµœì í™”)ë¥¼ ì‚¬ìš©í•˜ë©´ ë” íš¨ìœ¨ì ì´ë‹¤. MLAT Ch.12ì—ì„œë„ "Parameter impact on test scores" ì„¹ì…˜ì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°„ ìƒí˜¸ì‘ìš©ì„ ë¶„ì„í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¬ë‹¤.</p>
</div>

<h3>11.5 XGBoost vs LightGBM â€” ì–´ë–¤ ê²ƒì„ ì„ íƒí• ê¹Œ?</h3>

<table>
<caption class="tc">XGBoost vs LightGBM ì‹¤ì „ ë¹„êµ</caption>
<thead><tr><th>ê¸°ì¤€</th><th>XGBoost</th><th>LightGBM</th><th>ì¶”ì²œ</th></tr></thead>
<tbody>
<tr><td>í•™ìŠµ ì†ë„</td><td>ë¹ ë¦„</td><td>ë” ë¹ ë¦„ (2~10ë°°)</td><td>LightGBM</td></tr>
<tr><td>ë©”ëª¨ë¦¬ íš¨ìœ¨</td><td>ë³´í†µ</td><td>ìš°ìˆ˜ (íˆìŠ¤í† ê·¸ë¨)</td><td>LightGBM</td></tr>
<tr><td>ì†Œê·œëª¨ ë°ì´í„° (&lt;10K)</td><td>ì•ˆì •ì </td><td>ê³¼ì í•© ìœ„í—˜</td><td>XGBoost</td></tr>
<tr><td>ëŒ€ê·œëª¨ ë°ì´í„° (&gt;100K)</td><td>ëŠë ¤ì§</td><td>ì—¬ì „íˆ ë¹ ë¦„</td><td>LightGBM</td></tr>
<tr><td>ë²”ì£¼í˜• í”¼ì²˜</td><td>ì›-í•« ì¸ì½”ë”© í•„ìš”</td><td>ë„¤ì´í‹°ë¸Œ ì§€ì›</td><td>LightGBM</td></tr>
<tr><td>ì»¤ë®¤ë‹ˆí‹°/ë¬¸ì„œ</td><td>ë§¤ìš° í’ë¶€</td><td>í’ë¶€</td><td>ë¹„ìŠ·</td></tr>
<tr><td>Kaggle ìš°ìŠ¹ ë¹„ìœ¨</td><td>ë†’ìŒ</td><td>ë†’ìŒ</td><td>ë¹„ìŠ·</td></tr>
<tr><td>ê¸ˆìœµ ì‹¤ë¬´</td><td>ë§ì´ ì‚¬ìš©</td><td>ë§ì´ ì‚¬ìš©</td><td>ë‘˜ ë‹¤ ì‹œë„</td></tr>
</tbody>
</table>

<div class="ok">
<p class="ni"><strong>ì‹¤ì „ íŒ:</strong> ì •ë‹µì€ "ë‘˜ ë‹¤ ì‹œë„í•˜ê³  ë¹„êµí•˜ë¼"ì´ë‹¤. ê¸ˆìœµ ë°ì´í„°ëŠ” ë…¸ì´ì¦ˆê°€ ë§ì•„ì„œ ì–´ë–¤ ëª¨ë¸ì´ ë” ì¢‹ì„ì§€ ì‚¬ì „ì— ì•Œ ìˆ˜ ì—†ë‹¤. ë³´í†µ LightGBMìœ¼ë¡œ ë¹ ë¥´ê²Œ í”„ë¡œí† íƒ€ì´í•‘í•˜ê³ , XGBoostë¡œ êµì°¨ ê²€ì¦í•˜ì—¬ ìµœì¢… ëª¨ë¸ì„ ì„ íƒí•œë‹¤. MLAT Ch.12ì—ì„œë„ ì—¬ëŸ¬ ë¶€ìŠ¤íŒ… êµ¬í˜„ì²´ë¥¼ ë¹„êµ ì‹¤í—˜í•˜ëŠ” ì ‘ê·¼ì„ ê¶Œì¥í•œë‹¤.</p>
</div>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- Ch12: ì‹¤ì „ íŒŒì´í”„ë¼ì¸ í†µí•© -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2 id="ch12">12. ì‹¤ì „: ì£¼ê°€ ë°©í–¥ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸</h2>

<h3>12.1 ì „ì²´ íŒŒì´í”„ë¼ì¸ ê°œìš”</h3>
<p>ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ëª¨ë“  ê²ƒì„ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ í†µí•©í•œë‹¤. ë°ì´í„° ìˆ˜ì§‘ë¶€í„° ëª¨ë¸ ë¹„êµ, ìˆ˜ìµë¥  ì‹œë®¬ë ˆì´ì…˜ê¹Œì§€ â€” ì´ê²ƒì´ ì‹¤ì œ í€€íŠ¸ê°€ ë§¤ì¼ í•˜ëŠ” ì‘ì—…ì˜ ì¶•ì†ŒíŒì´ë‹¤.</p>

<!-- ì „ì²´ íŒŒì´í”„ë¼ì¸ í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨ -->
<div style="margin:25px 0;padding:20px;background:linear-gradient(135deg,#f0f8ff,#f8f0ff);border-radius:10px;border:1px solid #ccc">
<p class="ni" style="text-align:center;font-weight:bold;font-size:14px;margin-bottom:15px;color:#2c3e50">ğŸ”„ ML íŠ¸ë ˆì´ë”© íŒŒì´í”„ë¼ì¸ ì „ì²´ íë¦„</p>
<div style="display:flex;flex-wrap:wrap;gap:8px;justify-content:center;align-items:center;font-size:11px">
<div style="background:#3498db;color:#fff;padding:8px 14px;border-radius:6px;text-align:center;font-weight:bold">1. ë°ì´í„° ìˆ˜ì§‘<br><span style="font-size:9px;opacity:0.8">yfinance API</span></div>
<div style="color:#7f8c8d;font-weight:bold">â†’</div>
<div style="background:#2ecc71;color:#fff;padding:8px 14px;border-radius:6px;text-align:center;font-weight:bold">2. í”¼ì²˜ ìƒì„±<br><span style="font-size:9px;opacity:0.8">ê¸°ìˆ ì  ì§€í‘œ</span></div>
<div style="color:#7f8c8d;font-weight:bold">â†’</div>
<div style="background:#e67e22;color:#fff;padding:8px 14px;border-radius:6px;text-align:center;font-weight:bold">3. íƒ€ê²Ÿ ì •ì˜<br><span style="font-size:9px;opacity:0.8">Nì¼ í›„ ë°©í–¥</span></div>
<div style="color:#7f8c8d;font-weight:bold">â†’</div>
<div style="background:#9b59b6;color:#fff;padding:8px 14px;border-radius:6px;text-align:center;font-weight:bold">4. ì‹œê³„ì—´ ë¶„í• <br><span style="font-size:9px;opacity:0.8">TimeSeriesSplit</span></div>
<div style="color:#7f8c8d;font-weight:bold">â†’</div>
<div style="background:#e74c3c;color:#fff;padding:8px 14px;border-radius:6px;text-align:center;font-weight:bold">5. ëª¨ë¸ í•™ìŠµ<br><span style="font-size:9px;opacity:0.8">9ê°œ ëª¨ë¸ ë¹„êµ</span></div>
<div style="color:#7f8c8d;font-weight:bold">â†’</div>
<div style="background:#1abc9c;color:#fff;padding:8px 14px;border-radius:6px;text-align:center;font-weight:bold">6. ìˆ˜ìµë¥  ì‹œë®¬<br><span style="font-size:9px;opacity:0.8">ëˆ„ì  ìˆ˜ìµë¥ </span></div>
</div>
</div>

<h3>12.2 í†µí•© ì½”ë“œ: ë°ì´í„° â†’ í”¼ì²˜ â†’ íƒ€ê²Ÿ</h3>

<pre><code><span class="cm"># ============================================</span>
<span class="cm"># ì‹¤ì „ íŒŒì´í”„ë¼ì¸: ì£¼ê°€ ë°©í–¥ ì˜ˆì¸¡</span>
<span class="cm"># Round 4ì—ì„œ ë°°ìš´ ëª¨ë“  ëª¨ë¸ì„ í†µí•© ë¹„êµ</span>
<span class="cm"># ============================================</span>

<span class="kw">import</span> numpy <span class="kw">as</span> np
<span class="kw">import</span> pandas <span class="kw">as</span> pd
<span class="kw">import</span> yfinance <span class="kw">as</span> yf
<span class="kw">import</span> matplotlib.pyplot <span class="kw">as</span> plt
<span class="kw">from</span> sklearn.preprocessing <span class="kw">import</span> StandardScaler
<span class="kw">from</span> sklearn.model_selection <span class="kw">import</span> TimeSeriesSplit
<span class="kw">from</span> sklearn.metrics <span class="kw">import</span> accuracy_score, roc_auc_score
<span class="kw">import</span> warnings
warnings.filterwarnings(<span class="st">"ignore"</span>)

<span class="cm"># --- Step 1: ë°ì´í„° ìˆ˜ì§‘ ---</span>
ticker = <span class="st">"SPY"</span>
df = yf.download(ticker, start=<span class="st">"2010-01-01"</span>, end=<span class="st">"2024-12-31"</span>)
df = df[[<span class="st">"Open"</span>, <span class="st">"High"</span>, <span class="st">"Low"</span>, <span class="st">"Close"</span>, <span class="st">"Volume"</span>]].copy()
df.columns = [<span class="st">"open"</span>, <span class="st">"high"</span>, <span class="st">"low"</span>, <span class="st">"close"</span>, <span class="st">"volume"</span>]

<span class="cm"># --- Step 2: í”¼ì²˜ ìƒì„± ---</span>
df[<span class="st">"ret_1d"</span>] = df[<span class="st">"close"</span>].pct_change()
df[<span class="st">"ret_5d"</span>] = df[<span class="st">"close"</span>].pct_change(<span class="nu">5</span>)
df[<span class="st">"ret_20d"</span>] = df[<span class="st">"close"</span>].pct_change(<span class="nu">20</span>)
df[<span class="st">"vol_20d"</span>] = df[<span class="st">"ret_1d"</span>].rolling(<span class="nu">20</span>).std()
df[<span class="st">"sma_ratio"</span>] = df[<span class="st">"close"</span>] / df[<span class="st">"close"</span>].rolling(<span class="nu">20</span>).mean()
df[<span class="st">"rsi"</span>] = <span class="nu">100</span> - <span class="nu">100</span> / (<span class="nu">1</span> + df[<span class="st">"ret_1d"</span>].clip(lower=<span class="nu">0</span>).rolling(<span class="nu">14</span>).mean() /
                              df[<span class="st">"ret_1d"</span>].clip(upper=<span class="nu">0</span>).abs().rolling(<span class="nu">14</span>).mean())
df[<span class="st">"vol_ratio"</span>] = df[<span class="st">"volume"</span>] / df[<span class="st">"volume"</span>].rolling(<span class="nu">20</span>).mean()

<span class="cm"># --- Step 3: íƒ€ê²Ÿ ì •ì˜ (5ì¼ í›„ ìƒìŠ¹=1, í•˜ë½=0) ---</span>
df[<span class="st">"target"</span>] = (df[<span class="st">"close"</span>].shift(-<span class="nu">5</span>) > df[<span class="st">"close"</span>]).astype(<span class="nb">int</span>)

<span class="cm"># ê²°ì¸¡ì¹˜ ì œê±°</span>
feature_cols = [<span class="st">"ret_1d"</span>, <span class="st">"ret_5d"</span>, <span class="st">"ret_20d"</span>, <span class="st">"vol_20d"</span>,
                <span class="st">"sma_ratio"</span>, <span class="st">"rsi"</span>, <span class="st">"vol_ratio"</span>]
df = df.dropna(subset=feature_cols + [<span class="st">"target"</span>])

<span class="fn">print</span>(<span class="st">f"ë°ì´í„° ê¸°ê°„: </span>{df.index[0].date()}<span class="st"> ~ </span>{df.index[-1].date()}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"ì´ ìƒ˜í”Œ ìˆ˜: </span>{len(df):,}<span class="st">"</span>)
<span class="fn">print</span>(<span class="st">f"íƒ€ê²Ÿ ë¶„í¬: ìƒìŠ¹ </span>{df['target'].mean():.1%}<span class="st"> / í•˜ë½ </span>{1-df['target'].mean():.1%}<span class="st">"</span>)</code></pre>

<h3>12.3 ëª¨ë¸ 9ì¢… ë¹„êµ ì‹¤í—˜</h3>

<pre><code><span class="cm"># --- Step 4: ì‹œê³„ì—´ ë¶„í•  ---</span>
<span class="cm"># ë§ˆì§€ë§‰ 2ë…„ì„ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ì‚¬ìš©</span>
split_date = <span class="st">"2023-01-01"</span>
train = df[df.index < split_date]
test = df[df.index >= split_date]

X_train, y_train = train[feature_cols], train[<span class="st">"target"</span>]
X_test, y_test = test[feature_cols], test[<span class="st">"target"</span>]

<span class="cm"># ìŠ¤ì¼€ì¼ë§</span>
scaler = StandardScaler()
X_train_s = scaler.fit_transform(X_train)
X_test_s = scaler.transform(X_test)

<span class="fn">print</span>(<span class="st">f"Train: </span>{len(train):,}<span class="st"> ìƒ˜í”Œ ({train.index[0].date()} ~ {train.index[-1].date()})"</span>)
<span class="fn">print</span>(<span class="st">f"Test:  </span>{len(test):,}<span class="st"> ìƒ˜í”Œ ({test.index[0].date()} ~ {test.index[-1].date()})"</span>)

<span class="cm"># --- Step 5: 9ê°œ ëª¨ë¸ ì •ì˜ ---</span>
<span class="kw">from</span> sklearn.linear_model <span class="kw">import</span> LinearRegression, Ridge, Lasso, LogisticRegression
<span class="kw">from</span> sklearn.tree <span class="kw">import</span> DecisionTreeClassifier
<span class="kw">from</span> sklearn.ensemble <span class="kw">import</span> RandomForestClassifier, GradientBoostingClassifier
<span class="kw">import</span> xgboost <span class="kw">as</span> xgb
<span class="kw">import</span> lightgbm <span class="kw">as</span> lgb

models = {
    <span class="st">"OLS (íšŒê·€â†’ë¶„ë¥˜)"</span>: LinearRegression(),
    <span class="st">"Ridge (íšŒê·€â†’ë¶„ë¥˜)"</span>: Ridge(alpha=<span class="nu">1.0</span>),
    <span class="st">"Lasso (íšŒê·€â†’ë¶„ë¥˜)"</span>: Lasso(alpha=<span class="nu">0.01</span>),
    <span class="st">"Logistic"</span>: LogisticRegression(C=<span class="nu">1.0</span>, max_iter=<span class="nu">1000</span>),
    <span class="st">"Decision Tree"</span>: DecisionTreeClassifier(max_depth=<span class="nu">4</span>, min_samples_leaf=<span class="nu">50</span>, random_state=<span class="nu">42</span>),
    <span class="st">"Random Forest"</span>: RandomForestClassifier(n_estimators=<span class="nu">300</span>, max_depth=<span class="nu">5</span>, min_samples_leaf=<span class="nu">50</span>, random_state=<span class="nu">42</span>, n_jobs=-<span class="nu">1</span>),
    <span class="st">"Gradient Boost"</span>: GradientBoostingClassifier(n_estimators=<span class="nu">200</span>, learning_rate=<span class="nu">0.05</span>, max_depth=<span class="nu">3</span>, random_state=<span class="nu">42</span>),
    <span class="st">"XGBoost"</span>: xgb.XGBClassifier(n_estimators=<span class="nu">300</span>, learning_rate=<span class="nu">0.05</span>, max_depth=<span class="nu">4</span>, eval_metric=<span class="st">"auc"</span>, random_state=<span class="nu">42</span>, n_jobs=-<span class="nu">1</span>, verbosity=<span class="nu">0</span>),
    <span class="st">"LightGBM"</span>: lgb.LGBMClassifier(n_estimators=<span class="nu">300</span>, learning_rate=<span class="nu">0.05</span>, num_leaves=<span class="nu">31</span>, random_state=<span class="nu">42</span>, n_jobs=-<span class="nu">1</span>, verbose=-<span class="nu">1</span>),
}

<span class="cm"># --- ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ---</span>
results = []

<span class="kw">for</span> name, model <span class="kw">in</span> models.items():
    <span class="cm"># íšŒê·€ ëª¨ë¸ì€ í™•ë¥ ë¡œ ë³€í™˜</span>
    is_regressor = name <span class="kw">in</span> [<span class="st">"OLS (íšŒê·€â†’ë¶„ë¥˜)"</span>, <span class="st">"Ridge (íšŒê·€â†’ë¶„ë¥˜)"</span>, <span class="st">"Lasso (íšŒê·€â†’ë¶„ë¥˜)"</span>]

    <span class="kw">if</span> is_regressor:
        model.fit(X_train_s, y_train)
        y_prob = model.predict(X_test_s)
        y_prob = np.clip(y_prob, <span class="nu">0</span>, <span class="nu">1</span>)  <span class="cm"># 0~1 ë²”ìœ„ë¡œ í´ë¦¬í•‘</span>
        y_pred = (y_prob > <span class="nu">0.5</span>).astype(<span class="nb">int</span>)
    <span class="kw">else</span>:
        model.fit(X_train_s, y_train)
        y_prob = model.predict_proba(X_test_s)[:, <span class="nu">1</span>]
        y_pred = model.predict(X_test_s)

    acc = accuracy_score(y_test, y_pred)
    <span class="kw">try</span>:
        auc = roc_auc_score(y_test, y_prob)
    <span class="kw">except</span>:
        auc = <span class="nu">0.5</span>

    results.append({<span class="st">"Model"</span>: name, <span class="st">"Accuracy"</span>: acc, <span class="st">"AUC-ROC"</span>: auc})
    <span class="fn">print</span>(<span class="st">f"</span>{name:20s}<span class="st"> | Acc: </span>{acc:.4f}<span class="st"> | AUC: </span>{auc:.4f}<span class="st">"</span>)

<span class="cm"># ê²°ê³¼ DataFrame</span>
results_df = pd.DataFrame(results).sort_values(<span class="st">"AUC-ROC"</span>, ascending=<span class="kw">False</span>)
<span class="fn">print</span>(<span class="st">"\n=== ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„ (AUC-ROC ê¸°ì¤€) ==="</span>)
<span class="fn">print</span>(results_df.to_string(index=<span class="kw">False</span>))</code></pre>

<h3>12.4 ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”</h3>

<pre><code><span class="cm"># ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸</span>
fig, axes = plt.subplots(<span class="nu">1</span>, <span class="nu">2</span>, figsize=(<span class="nu">14</span>, <span class="nu">5</span>))

<span class="cm"># Accuracy ë¹„êµ</span>
colors = [<span class="st">"#e74c3c"</span> <span class="kw">if</span> v == results_df[<span class="st">"Accuracy"</span>].max() <span class="kw">else</span> <span class="st">"#3498db"</span>
          <span class="kw">for</span> v <span class="kw">in</span> results_df[<span class="st">"Accuracy"</span>]]
axes[<span class="nu">0</span>].barh(results_df[<span class="st">"Model"</span>], results_df[<span class="st">"Accuracy"</span>], color=colors)
axes[<span class="nu">0</span>].set_xlabel(<span class="st">"Accuracy"</span>)
axes[<span class="nu">0</span>].set_title(<span class="st">"ëª¨ë¸ë³„ Accuracy ë¹„êµ"</span>)
axes[<span class="nu">0</span>].axvline(x=<span class="nu">0.5</span>, color=<span class="st">"gray"</span>, linestyle=<span class="st">"--"</span>, alpha=<span class="nu">0.5</span>, label=<span class="st">"ëœë¤ ê¸°ì¤€ì„ "</span>)
axes[<span class="nu">0</span>].legend()

<span class="cm"># AUC-ROC ë¹„êµ</span>
colors = [<span class="st">"#e74c3c"</span> <span class="kw">if</span> v == results_df[<span class="st">"AUC-ROC"</span>].max() <span class="kw">else</span> <span class="st">"#2ecc71"</span>
          <span class="kw">for</span> v <span class="kw">in</span> results_df[<span class="st">"AUC-ROC"</span>]]
axes[<span class="nu">1</span>].barh(results_df[<span class="st">"Model"</span>], results_df[<span class="st">"AUC-ROC"</span>], color=colors)
axes[<span class="nu">1</span>].set_xlabel(<span class="st">"AUC-ROC"</span>)
axes[<span class="nu">1</span>].set_title(<span class="st">"ëª¨ë¸ë³„ AUC-ROC ë¹„êµ"</span>)
axes[<span class="nu">1</span>].axvline(x=<span class="nu">0.5</span>, color=<span class="st">"gray"</span>, linestyle=<span class="st">"--"</span>, alpha=<span class="nu">0.5</span>, label=<span class="st">"ëœë¤ ê¸°ì¤€ì„ "</span>)
axes[<span class="nu">1</span>].legend()

plt.tight_layout()
plt.show()</code></pre>

<h3>12.5 ìˆ˜ìµë¥  ì‹œë®¬ë ˆì´ì…˜ â€” ëª¨ë¸ ì‹ í˜¸ ê¸°ë°˜ íŠ¸ë ˆì´ë”©</h3>
<p>ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ì‹¤ì œ íŠ¸ë ˆì´ë”© ì‹ í˜¸ë¡œ ë³€í™˜í•˜ì—¬ ìˆ˜ìµë¥ ì„ ì‹œë®¬ë ˆì´ì…˜í•œë‹¤. "ìƒìŠ¹ ì˜ˆì¸¡ â†’ ë§¤ìˆ˜(Long)", "í•˜ë½ ì˜ˆì¸¡ â†’ í˜„ê¸ˆ ë³´ìœ (Flat)" ì „ëµì´ë‹¤. MLAT Ch.11-12ì—ì„œ ë‹¤ë£¨ëŠ” ë°±í…ŒìŠ¤íŠ¸ì˜ ê°„ì†Œí™” ë²„ì „ì´ë‹¤.</p>

<pre><code><span class="cm"># === ìˆ˜ìµë¥  ì‹œë®¬ë ˆì´ì…˜ ===</span>
<span class="cm"># ìµœì  ëª¨ë¸ 3ê°œë¡œ ì‹œë®¬ë ˆì´ì…˜</span>
top_models = results_df.head(<span class="nu">3</span>)[<span class="st">"Model"</span>].tolist()

<span class="cm"># í…ŒìŠ¤íŠ¸ ê¸°ê°„ ì¼ë³„ ìˆ˜ìµë¥ </span>
test_returns = test[<span class="st">"ret_1d"</span>].values

fig, ax = plt.subplots(figsize=(<span class="nu">12</span>, <span class="nu">6</span>))

<span class="cm"># Buy & Hold ë²¤ì¹˜ë§ˆí¬</span>
cumret_bh = np.cumprod(<span class="nu">1</span> + test_returns) - <span class="nu">1</span>
ax.plot(test.index, cumret_bh * <span class="nu">100</span>, <span class="st">"k--"</span>, alpha=<span class="nu">0.5</span>, linewidth=<span class="nu">1.5</span>, label=<span class="st">"Buy & Hold"</span>)

<span class="cm"># ê° ëª¨ë¸ì˜ ì „ëµ ìˆ˜ìµë¥ </span>
colors_line = [<span class="st">"#e74c3c"</span>, <span class="st">"#3498db"</span>, <span class="st">"#2ecc71"</span>]
<span class="kw">for</span> i, name <span class="kw">in</span> <span class="nb">enumerate</span>(top_models):
    model = models[name]
    is_regressor = <span class="st">"íšŒê·€"</span> <span class="kw">in</span> name
    <span class="kw">if</span> is_regressor:
        signals = (model.predict(X_test_s) > <span class="nu">0.5</span>).astype(<span class="nb">int</span>)
    <span class="kw">else</span>:
        signals = model.predict(X_test_s)

    <span class="cm"># ì‹ í˜¸ Ã— ìˆ˜ìµë¥  (ìƒìŠ¹ ì˜ˆì¸¡ ì‹œ ë§¤ìˆ˜, í•˜ë½ ì˜ˆì¸¡ ì‹œ í˜„ê¸ˆ)</span>
    strategy_returns = signals * test_returns
    cumret = np.cumprod(<span class="nu">1</span> + strategy_returns) - <span class="nu">1</span>
    ax.plot(test.index, cumret * <span class="nu">100</span>, color=colors_line[i], linewidth=<span class="nu">1.5</span>, label=name)

ax.set_xlabel(<span class="st">"Date"</span>)
ax.set_ylabel(<span class="st">"ëˆ„ì  ìˆ˜ìµë¥  (%)"</span>)
ax.set_title(<span class="st">"ML ëª¨ë¸ ê¸°ë°˜ íŠ¸ë ˆì´ë”© ì „ëµ vs Buy & Hold"</span>)
ax.legend(loc=<span class="st">"upper left"</span>)
ax.grid(<span class="kw">True</span>, alpha=<span class="nu">0.3</span>)
ax.axhline(y=<span class="nu">0</span>, color=<span class="st">"gray"</span>, linewidth=<span class="nu">0.5</span>)
plt.tight_layout()
plt.show()

<span class="cm"># ì „ëµ ì„±ê³¼ ìš”ì•½</span>
<span class="fn">print</span>(<span class="st">"=== ì „ëµ ì„±ê³¼ ìš”ì•½ ==="</span>)
<span class="fn">print</span>(<span class="st">f"{'ì „ëµ':20s} | {'ëˆ„ì ìˆ˜ìµë¥ ':>10s} | {'ì—°í™˜ì‚°':>8s} | {'ìƒ¤í”„ë¹„ìœ¨':>8s}"</span>)
<span class="fn">print</span>(<span class="st">"-"</span> * <span class="nu">55</span>)

<span class="kw">for</span> name <span class="kw">in</span> [<span class="st">"Buy & Hold"</span>] + top_models:
    <span class="kw">if</span> name == <span class="st">"Buy & Hold"</span>:
        strat_ret = test_returns
    <span class="kw">else</span>:
        model = models[name]
        is_regressor = <span class="st">"íšŒê·€"</span> <span class="kw">in</span> name
        <span class="kw">if</span> is_regressor:
            signals = (model.predict(X_test_s) > <span class="nu">0.5</span>).astype(<span class="nb">int</span>)
        <span class="kw">else</span>:
            signals = model.predict(X_test_s)
        strat_ret = signals * test_returns

    cum = (np.cumprod(<span class="nu">1</span> + strat_ret) - <span class="nu">1</span>)[-<span class="nu">1</span>]
    ann = (<span class="nu">1</span> + cum) ** (<span class="nu">252</span> / <span class="nb">len</span>(strat_ret)) - <span class="nu">1</span>
    sharpe = strat_ret.mean() / strat_ret.std() * np.sqrt(<span class="nu">252</span>) <span class="kw">if</span> strat_ret.std() > <span class="nu">0</span> <span class="kw">else</span> <span class="nu">0</span>
    <span class="fn">print</span>(<span class="st">f"</span>{name:20s}<span class="st"> | </span>{cum:>9.1%}<span class="st"> | </span>{ann:>7.1%}<span class="st"> | </span>{sharpe:>8.2f}<span class="st">"</span>)</code></pre>

<div class="warn">
<p class="ni"><strong>í˜„ì‹¤ ì£¼ì˜ì‚¬í•­ â€” ì´ ì‹œë®¬ë ˆì´ì…˜ì˜ í•œê³„:</strong></p>
<ol>
<li><strong>ê±°ë˜ ë¹„ìš© ë¯¸í¬í•¨:</strong> ì‹¤ì œë¡œëŠ” ë§¤ë§¤ ìˆ˜ìˆ˜ë£Œ, ìŠ¬ë¦¬í”¼ì§€(slippage)ê°€ ìˆ˜ìµì„ ê¹ì•„ë¨¹ëŠ”ë‹¤.</li>
<li><strong>Look-ahead bias ê°€ëŠ¥ì„±:</strong> í”¼ì²˜ ìƒì„± ì‹œ ë¯¸ë˜ ë°ì´í„°ê°€ ì„ì´ì§€ ì•Šì•˜ëŠ”ì§€ í•­ìƒ í™•ì¸í•´ì•¼ í•œë‹¤.</li>
<li><strong>ê³¼ìµœì í™” ìœ„í—˜:</strong> í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ì¢‹ì€ ëª¨ë¸ì„ "ì„ íƒ"í•˜ëŠ” ê²ƒ ìì²´ê°€ ê³¼ì í•©ì´ë‹¤. ì‹¤ì „ì—ì„œëŠ” ê²€ì¦ ì„¸íŠ¸(validation)ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ ë¶„ë¦¬í•´ì•¼ í•œë‹¤.</li>
<li><strong>ì‹œì¥ ë ˆì§ ë³€í™”:</strong> ê³¼ê±°ì— ì˜ ì‘ë™í•œ ëª¨ë¸ì´ ë¯¸ë˜ì—ë„ ì‘ë™í•œë‹¤ëŠ” ë³´ì¥ì´ ì—†ë‹¤.</li>
</ol>
<p class="ni">MLAT Ch.8 "The ML4T Workflow"ì—ì„œ ì´ëŸ¬í•œ ë°±í…ŒìŠ¤íŠ¸ í•¨ì •ì„ ìƒì„¸íˆ ë‹¤ë£¬ë‹¤. ë¼ìš´ë“œ 8ì—ì„œ Ziplineì„ ì‚¬ìš©í•œ ë³¸ê²©ì ì¸ ë°±í…ŒìŠ¤íŠ¸ë¥¼ ë°°ìš¸ ê²ƒì´ë‹¤.</p>
</div>

<div class="info">
<p class="ni"><strong>êµì¬ ì—°ë™:</strong> ì´ íŒŒì´í”„ë¼ì¸ì€ MLAT Ch.7 (ì„ í˜• ëª¨ë¸), Ch.11 (Random Forest), Ch.12 (Gradient Boosting)ì˜ ë‚´ìš©ì„ í†µí•©í•œ ê²ƒì´ë‹¤. MLATì—ì„œëŠ” ê° ëª¨ë¸ì„ ì¼ë³¸ ì£¼ì‹ ë°ì´í„°ì— ì ìš©í•˜ì—¬ Long-Short ì „ëµì„ êµ¬í˜„í•˜ê³  Ziplineìœ¼ë¡œ ë°±í…ŒìŠ¤íŠ¸í•œë‹¤. ìš°ë¦¬ëŠ” ì•„ì§ ê°„ì†Œí™” ë²„ì „ì´ì§€ë§Œ, í•µì‹¬ ì›Œí¬í”Œë¡œìš°ëŠ” ë™ì¼í•˜ë‹¤.</p>
</div>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- Ch13: Quiz + ë¯¸ë‹ˆ í”„ë¡œì íŠ¸ -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<h2 id="ch13">13. Quiz + ë¯¸ë‹ˆ í”„ë¡œì íŠ¸</h2>

<h3>13.1 í•µì‹¬ ê°œë… í€´ì¦ˆ (10ë¬¸ì œ)</h3>
<p>ë¼ìš´ë“œ 4ì—ì„œ ë°°ìš´ ë‚´ìš©ì„ ì ê²€í•˜ì. ë‹µì„ ë¨¼ì € ìƒê°í•œ í›„ í™•ì¸í•˜ë¼.</p>

<div class="def">
<p class="ni"><strong>Q1.</strong> ì§€ë„í•™ìŠµ(Supervised Learning)ì˜ ì •ì˜ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ë¼. ë¹„ì§€ë„í•™ìŠµê³¼ì˜ í•µì‹¬ ì°¨ì´ëŠ”?</p>
<p class="ni" style="color:#888;font-size:12px">íŒíŠ¸: íƒ€ê²Ÿ(label)ì˜ ìœ ë¬´</p>
</div>

<div class="def">
<p class="ni"><strong>Q2.</strong> íšŒê·€(Regression)ì™€ ë¶„ë¥˜(Classification)ì˜ ì°¨ì´ë¥¼ ê¸ˆìœµ ì˜ˆì‹œì™€ í•¨ê»˜ ì„¤ëª…í•˜ë¼.</p>
<p class="ni" style="color:#888;font-size:12px">íŒíŠ¸: ì—°ì†ê°’ vs ë²”ì£¼ê°’</p>
</div>

<div class="def">
<p class="ni"><strong>Q3.</strong> Ridge íšŒê·€ì™€ Lasso íšŒê·€ì˜ ì •ê·œí™” ë°©ì‹ ì°¨ì´ë¥¼ ìˆ˜ì‹ìœ¼ë¡œ ì“°ê³ , Lassoê°€ í”¼ì²˜ ì„ íƒ íš¨ê³¼ë¥¼ ê°–ëŠ” ì´ìœ ë¥¼ ì„¤ëª…í•˜ë¼.</p>
<p class="ni" style="color:#888;font-size:12px">íŒíŠ¸: L2 vs L1, ê³„ìˆ˜ë¥¼ ì •í™•íˆ 0ìœ¼ë¡œ</p>
</div>

<div class="def">
<p class="ni"><strong>Q4.</strong> ë¡œì§€ìŠ¤í‹± íšŒê·€ì—ì„œ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ì˜ ì—­í• ì€ ë¬´ì—‡ì¸ê°€? ì¶œë ¥ê°’ì˜ ë²”ìœ„ëŠ”?</p>
<p class="ni" style="color:#888;font-size:12px">íŒíŠ¸: ì„ í˜• ê²°í•© â†’ í™•ë¥  ë³€í™˜</p>
</div>

<div class="def">
<p class="ni"><strong>Q5.</strong> í˜¼ë™í–‰ë ¬(Confusion Matrix)ì—ì„œ Precisionê³¼ Recallì˜ ì°¨ì´ë¥¼ ì„¤ëª…í•˜ë¼. ê¸ˆìœµì—ì„œ ì–´ë–¤ ê²ƒì´ ë” ì¤‘ìš”í•œ ê²½ìš°ê°€ ìˆëŠ”ê°€?</p>
<p class="ni" style="color:#888;font-size:12px">íŒíŠ¸: "ìƒìŠ¹ ì˜ˆì¸¡ ì¤‘ ì‹¤ì œ ìƒìŠ¹ ë¹„ìœ¨" vs "ì‹¤ì œ ìƒìŠ¹ ì¤‘ ì˜ˆì¸¡ ì„±ê³µ ë¹„ìœ¨"</p>
</div>

<div class="def">
<p class="ni"><strong>Q6.</strong> ê¸ˆìœµ ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ì¼ë°˜ K-Fold CV ëŒ€ì‹  TimeSeriesSplitì„ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ì´ìœ ëŠ”?</p>
<p class="ni" style="color:#888;font-size:12px">íŒíŠ¸: ë¯¸ë˜ ì •ë³´ ëˆ„ì¶œ (look-ahead bias)</p>
</div>

<div class="def">
<p class="ni"><strong>Q7.</strong> ê²°ì • íŠ¸ë¦¬ì˜ ê³¼ì í•© ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²• 3ê°€ì§€ë¥¼ ë‚˜ì—´í•˜ë¼.</p>
<p class="ni" style="color:#888;font-size:12px">íŒíŠ¸: max_depth, min_samples_leaf, ê·¸ë¦¬ê³  ì•™ìƒë¸”</p>
</div>

<div class="def">
<p class="ni"><strong>Q8.</strong> Random Forestì˜ "ë‘ ê°€ì§€ ëœë¤ì„±"ì„ ì„¤ëª…í•˜ë¼. ì´ê²ƒì´ ì™œ ê³¼ì í•©ì„ ì¤„ì´ëŠ”ê°€?</p>
<p class="ni" style="color:#888;font-size:12px">íŒíŠ¸: Bootstrap + Random Feature Selection â†’ íŠ¸ë¦¬ ê°„ ìƒê´€ ê°ì†Œ</p>
</div>

<div class="def">
<p class="ni"><strong>Q9.</strong> Bagging(Random Forest)ê³¼ Boosting(Gradient Boosting)ì˜ í•µì‹¬ ì°¨ì´ë¥¼ "ë³‘ë ¬ vs ìˆœì°¨"ë¡œ ì„¤ëª…í•˜ë¼.</p>
<p class="ni" style="color:#888;font-size:12px">íŒíŠ¸: ë¶„ì‚° ê°ì†Œ vs í¸í–¥ ê°ì†Œ</p>
</div>

<div class="def">
<p class="ni"><strong>Q10.</strong> XGBoostê°€ sklearn GradientBoostingë³´ë‹¤ ë¹ ë¥¸ ì´ìœ  3ê°€ì§€ë¥¼ ì„¤ëª…í•˜ë¼.</p>
<p class="ni" style="color:#888;font-size:12px">íŒíŠ¸: 2ì°¨ ê·¼ì‚¬, ê·¼ì‚¬ ë¶„í•  íƒìƒ‰, ë³‘ë ¬ ì²˜ë¦¬</p>
</div>

<h3>13.2 ìê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸</h3>
<p>ì•„ë˜ í•­ëª©ì„ ëª¨ë‘ ì²´í¬í•  ìˆ˜ ìˆìœ¼ë©´ ë¼ìš´ë“œ 4ë¥¼ ì™„ë£Œí•œ ê²ƒì´ë‹¤:</p>

<table>
<thead><tr><th>âœ“</th><th>í•­ëª©</th><th>í™•ì¸</th></tr></thead>
<tbody>
<tr><td>â–¡</td><td>ì§€ë„í•™ìŠµì˜ 3ìœ í˜•(íšŒê·€/ë¶„ë¥˜/ë­í‚¹)ì„ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤</td><td></td></tr>
<tr><td>â–¡</td><td>OLS, Ridge, Lassoì˜ ì°¨ì´ë¥¼ ìˆ˜ì‹ê³¼ í•¨ê»˜ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤</td><td></td></tr>
<tr><td>â–¡</td><td>ë¡œì§€ìŠ¤í‹± íšŒê·€ë¡œ ì£¼ê°€ ë°©í–¥ ì˜ˆì¸¡ ì½”ë“œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆë‹¤</td><td></td></tr>
<tr><td>â–¡</td><td>í˜¼ë™í–‰ë ¬, AUC-ROCë¥¼ í•´ì„í•  ìˆ˜ ìˆë‹¤</td><td></td></tr>
<tr><td>â–¡</td><td>TimeSeriesSplitì˜ í•„ìš”ì„±ì„ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤</td><td></td></tr>
<tr><td>â–¡</td><td>ê²°ì • íŠ¸ë¦¬ì˜ ë¶„í•  ê¸°ì¤€(Gini/Entropy)ì„ ì´í•´í•œë‹¤</td><td></td></tr>
<tr><td>â–¡</td><td>Random Forestì˜ Bagging ì›ë¦¬ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤</td><td></td></tr>
<tr><td>â–¡</td><td>Gradient Boostingì˜ ìˆœì°¨ í•™ìŠµ ì›ë¦¬ë¥¼ ì´í•´í•œë‹¤</td><td></td></tr>
<tr><td>â–¡</td><td>XGBoost/LightGBMì„ ì„¤ì¹˜í•˜ê³  í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆë‹¤</td><td></td></tr>
<tr><td>â–¡</td><td>GridSearchCVë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ í•  ìˆ˜ ìˆë‹¤</td><td></td></tr>
<tr><td>â–¡</td><td>9ê°œ ëª¨ë¸ì„ ë¹„êµí•˜ëŠ” íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•  ìˆ˜ ìˆë‹¤</td><td></td></tr>
</tbody>
</table>

<h3>13.3 ë¯¸ë‹ˆ í”„ë¡œì íŠ¸: XGBoostë¡œ ë‚´ì¼ ì£¼ê°€ ë°©í–¥ ì˜ˆì¸¡</h3>

<div class="ok">
<p class="ni"><strong>í”„ë¡œì íŠ¸ ê³¼ì œ</strong></p>
<p class="ni">ì•„ë˜ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ëŠ” ì½”ë“œë¥¼ ì§ì ‘ ì‘ì„±í•˜ë¼:</p>
<ol>
<li><strong>ì¢…ëª© ì„ íƒ:</strong> ê´€ì‹¬ ìˆëŠ” ì¢…ëª© 1ê°œë¥¼ ì„ íƒí•œë‹¤ (ì˜ˆ: AAPL, TSLA, 005930.KS ë“±)</li>
<li><strong>í”¼ì²˜ í™•ì¥:</strong> ë³¸ë¬¸ì˜ 7ê°œ í”¼ì²˜ ì™¸ì— ìµœì†Œ 3ê°œì˜ ìƒˆë¡œìš´ í”¼ì²˜ë¥¼ ì¶”ê°€í•œë‹¤
<ul>
<li>ì˜ˆ: MACD, Bollinger Band ìœ„ì¹˜, ATR, ê±°ë˜ëŸ‰ ë³€í™”ìœ¨, ìš”ì¼ ë”ë¯¸ ë“±</li>
</ul>
</li>
<li><strong>íƒ€ê²Ÿ ë³€ê²½:</strong> 5ì¼ í›„ ëŒ€ì‹  1ì¼ í›„ ë°©í–¥ì„ ì˜ˆì¸¡í•´ë³¸ë‹¤. ì„±ëŠ¥ì´ ì–´ë–»ê²Œ ë‹¬ë¼ì§€ëŠ”ê°€?</li>
<li><strong>ëª¨ë¸ íŠœë‹:</strong> XGBoostì— GridSearchCV(TimeSeriesSplit)ë¥¼ ì ìš©í•˜ì—¬ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ëŠ”ë‹¤</li>
<li><strong>ê²°ê³¼ ë¶„ì„:</strong>
<ul>
<li>ìµœì  íŒŒë¼ë¯¸í„°ì™€ CV AUC-ROC ì ìˆ˜ë¥¼ ì¶œë ¥í•œë‹¤</li>
<li>í”¼ì²˜ ì¤‘ìš”ë„ ìƒìœ„ 5ê°œë¥¼ ì‹œê°í™”í•œë‹¤</li>
<li>í…ŒìŠ¤íŠ¸ ê¸°ê°„ ëˆ„ì  ìˆ˜ìµë¥ ì„ Buy &amp; Holdì™€ ë¹„êµí•œë‹¤</li>
</ul>
</li>
</ol>
<p class="ni" style="margin-top:10px"><strong>ì œì¶œ í˜•ì‹:</strong> Jupyter Notebook (.ipynb) ë˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ (.py)</p>
</div>

<h3>13.4 ë‹¤ìŒ ë¼ìš´ë“œ ì˜ˆê³ : Round 5 â€” ë¹„ì§€ë„í•™ìŠµê³¼ ì°¨ì› ì¶•ì†Œ</h3>

<!-- ë‹¤ìŒ ë¼ìš´ë“œ ì˜ˆê³  ë‹¤ì´ì–´ê·¸ë¨ -->
<div style="margin:25px 0;padding:20px;background:linear-gradient(135deg,#fff8e1,#e8f5e9);border-radius:10px;border:2px solid #f9a825">
<p class="ni" style="text-align:center;font-weight:bold;font-size:15px;margin-bottom:12px;color:#e65100">ğŸ”® Round 5 Preview â€” ë¹„ì§€ë„í•™ìŠµ &amp; ì°¨ì› ì¶•ì†Œ</p>
<div style="display:flex;flex-wrap:wrap;gap:10px;justify-content:center;font-size:12px">
<div style="background:#fff;padding:10px 16px;border-radius:8px;border:1px solid #ddd;text-align:center;min-width:120px">
<div style="font-size:20px;margin-bottom:4px">ğŸ“Š</div>
<div style="font-weight:bold;color:#2c3e50">PCA</div>
<div style="color:#777;font-size:10px">ì£¼ì„±ë¶„ ë¶„ì„</div>
</div>
<div style="background:#fff;padding:10px 16px;border-radius:8px;border:1px solid #ddd;text-align:center;min-width:120px">
<div style="font-size:20px;margin-bottom:4px">ğŸ¯</div>
<div style="font-weight:bold;color:#2c3e50">K-Means</div>
<div style="color:#777;font-size:10px">í´ëŸ¬ìŠ¤í„°ë§</div>
</div>
<div style="background:#fff;padding:10px 16px;border-radius:8px;border:1px solid #ddd;text-align:center;min-width:120px">
<div style="font-size:20px;margin-bottom:4px">ğŸŒ</div>
<div style="font-weight:bold;color:#2c3e50">t-SNE</div>
<div style="color:#777;font-size:10px">ì‹œê°í™”</div>
</div>
<div style="background:#fff;padding:10px 16px;border-radius:8px;border:1px solid #ddd;text-align:center;min-width:120px">
<div style="font-size:20px;margin-bottom:4px">ğŸ“ˆ</div>
<div style="font-weight:bold;color:#2c3e50">ì‹œì¥ ë ˆì§</div>
<div style="color:#777;font-size:10px">HMM ê¸°ì´ˆ</div>
</div>
<div style="background:#fff;padding:10px 16px;border-radius:8px;border:1px solid #ddd;text-align:center;min-width:120px">
<div style="font-size:20px;margin-bottom:4px">ğŸ—ï¸</div>
<div style="font-weight:bold;color:#2c3e50">ì˜¤í† ì¸ì½”ë”</div>
<div style="color:#777;font-size:10px">ë¹„ì„ í˜• ì°¨ì› ì¶•ì†Œ</div>
</div>
</div>
<p class="ni" style="text-align:center;margin-top:12px;color:#555;font-size:12px">
ë¼ìš´ë“œ 4ì—ì„œ "ì •ë‹µì´ ìˆëŠ”" ì§€ë„í•™ìŠµì„ ë°°ì› ë‹¤ë©´, ë¼ìš´ë“œ 5ì—ì„œëŠ” "ì •ë‹µ ì—†ì´" ë°ì´í„°ì˜ ìˆ¨ê²¨ì§„ êµ¬ì¡°ë¥¼ ë°œê²¬í•˜ëŠ” ë¹„ì§€ë„í•™ìŠµì„ ë°°ìš´ë‹¤.<br>
PCAë¡œ ìˆ˜ì‹­ ê°œì˜ í”¼ì²˜ë¥¼ ì••ì¶•í•˜ê³ , K-Meansë¡œ ì¢…ëª©ì„ êµ°ì§‘í™”í•˜ê³ , HMMìœ¼ë¡œ ì‹œì¥ ë ˆì§(ìƒìŠ¹ì¥/í•˜ë½ì¥/íš¡ë³´ì¥)ì„ ìë™ íƒì§€í•œë‹¤.
</p>
</div>

<div class="info">
<p class="ni"><strong>êµì¬ ì—°ë™ (Round 5 ë¯¸ë¦¬ë³´ê¸°):</strong> MLAT Ch.13 "Data-Driven Risk Factors and Asset Allocation with Unsupervised Learning"ì—ì„œ PCA, K-Means, ê³„ì¸µì  í´ëŸ¬ìŠ¤í„°ë§ì„ ê¸ˆìœµ ë°ì´í„°ì— ì ìš©í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¬ë‹¤. ë‘ì‡ì•Œê³ ì—ì„œëŠ” ê¸°ë³¸ ì•Œê³ ë¦¬ì¦˜ êµ¬ì¡°ë¥¼, íŒŒë¼í™œì—ì„œëŠ” sklearnì˜ ë¹„ì§€ë„í•™ìŠµ APIë¥¼ ì°¸ê³ í•œë‹¤.</p>
</div>

</div><!-- paper-content -->
</div><!-- container -->
</div><!-- main-wrapper -->

</body>
</html>
